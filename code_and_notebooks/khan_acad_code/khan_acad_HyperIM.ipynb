{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "khan_acad_HyperIM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR9av2JU3kf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "321dc364-6763-44bc-f195-81e37c5bf22f"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da-zaZJUGMFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "677ca5bf-4e8d-46b8-85c9-64dd8dcb7e1c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX0gtX5MlBjD"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/Information_retrieval_project/khan_acad/train_khan_acad.csv\" /content\n",
        "!cp \"/content/drive/MyDrive/Information_retrieval_project/khan_acad/test_khan_acad.csv\" /content\n",
        "!cp \"/content/drive/MyDrive/Information_retrieval_project/khan_acad/val_khan_acad.csv\" /content\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzKeqoCs3kgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e7274e-c6ff-46f3-b9cf-6d8794dba452"
      },
      "source": [
        "!pip install transformers==3.2.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3.2.0 in /usr/local/lib/python3.7/dist-packages (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (20.9)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (0.8.1rc2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (0.1.95)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2.0) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.2.0) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2.0) (2020.12.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2.0) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZFv4UU8sLTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d4f4014-9c4d-4570-93d7-2cec894cda6f"
      },
      "source": [
        "!pip install git+https://github.com/geoopt/geoopt.git\n",
        "! pip install git+https://github.com/ferrine/hyrnn.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/geoopt/geoopt.git\n",
            "  Cloning https://github.com/geoopt/geoopt.git to /tmp/pip-req-build-1zebr962\n",
            "  Running command git clone -q https://github.com/geoopt/geoopt.git /tmp/pip-req-build-1zebr962\n",
            "Requirement already satisfied (use --upgrade to upgrade): geoopt==0.3.1 from git+https://github.com/geoopt/geoopt.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from geoopt==0.3.1) (1.8.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from geoopt==0.3.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->geoopt==0.3.1) (3.7.4.3)\n",
            "Building wheels for collected packages: geoopt\n",
            "  Building wheel for geoopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for geoopt: filename=geoopt-0.3.1-cp37-none-any.whl size=76168 sha256=77a2628e178e909b4dc26aa375f749ab9606243f84ccdcfac1b0923625df723e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1wk0pqdr/wheels/10/df/30/e0d857f034c142ca5f38af048b62aae3da773b272553e5dd21\n",
            "Successfully built geoopt\n",
            "Collecting git+https://github.com/ferrine/hyrnn.git\n",
            "  Cloning https://github.com/ferrine/hyrnn.git to /tmp/pip-req-build-pdqsjfaz\n",
            "  Running command git clone -q https://github.com/ferrine/hyrnn.git /tmp/pip-req-build-pdqsjfaz\n",
            "Requirement already satisfied (use --upgrade to upgrade): hyrnn==0.0.0 from git+https://github.com/ferrine/hyrnn.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from hyrnn==0.0.0) (1.8.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyrnn==0.0.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->hyrnn==0.0.0) (3.7.4.3)\n",
            "Building wheels for collected packages: hyrnn\n",
            "  Building wheel for hyrnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hyrnn: filename=hyrnn-0.0.0-cp37-none-any.whl size=13955 sha256=32f84dc379d93592452a0be7d1e4ed094e974f18cfb4997204b087d7a4403109\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d9d4wc1f/wheels/24/c3/64/cc0e9d25d466081dc154a2a8843157f54d845b916b4ba66418\n",
            "Successfully built hyrnn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsADhaO93kgD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "9f51d55d-50b2-41a2-a365-4c57c75c56e3"
      },
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"train_khan_acad.csv\")\n",
        "val_data = pd.read_csv(\"val_khan_acad.csv\")\n",
        "test_data = pd.read_csv(\"test_khan_acad.csv\")\n",
        "\n",
        "train_data\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_transcripts</th>\n",
              "      <th>hierarchy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the last couple of videos we saw that we c...</td>\n",
              "      <td>math&gt;&gt;multivariable-calculus&gt;&gt;multivariable-de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-  What we're going to do in this video is gi...</td>\n",
              "      <td>science&gt;&gt;ap-biology&gt;&gt;natural-selection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>So once again, we have three equal, or we say...</td>\n",
              "      <td>math&gt;&gt;pre-algebra&gt;&gt;pre-algebra-equations-expre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-  Liz's math test included a survey question...</td>\n",
              "      <td>math&gt;&gt;engageny-alg-1&gt;&gt;alg1-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>- The following two equations form a linear s...</td>\n",
              "      <td>math&gt;&gt;algebra-home&gt;&gt;alg-system-of-equations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4183</th>\n",
              "      <td>-  Hello everyone. So this is what I might ca...</td>\n",
              "      <td>math&gt;&gt;multivariable-calculus&gt;&gt;multivariable-de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4184</th>\n",
              "      <td>-  Let's try now to subtract some two-digit n...</td>\n",
              "      <td>math&gt;&gt;early-math&gt;&gt;cc-early-math-add-sub-100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4185</th>\n",
              "      <td>- Let's say that I have a circle. My best att...</td>\n",
              "      <td>math&gt;&gt;engageny-geo&gt;&gt;geo-5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4186</th>\n",
              "      <td>- So let's look at the female reproductive cy...</td>\n",
              "      <td>science&gt;&gt;health-and-medicine&gt;&gt;human-anatomy-an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4187</th>\n",
              "      <td>-  We're now in the home stretch. We just hav...</td>\n",
              "      <td>math&gt;&gt;multivariable-calculus&gt;&gt;greens-theorem-a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4188 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      video_transcripts                                          hierarchy\n",
              "0      In the last couple of videos we saw that we c...  math>>multivariable-calculus>>multivariable-de...\n",
              "1      -  What we're going to do in this video is gi...             science>>ap-biology>>natural-selection\n",
              "2      So once again, we have three equal, or we say...  math>>pre-algebra>>pre-algebra-equations-expre...\n",
              "3      -  Liz's math test included a survey question...                       math>>engageny-alg-1>>alg1-2\n",
              "4      - The following two equations form a linear s...        math>>algebra-home>>alg-system-of-equations\n",
              "...                                                 ...                                                ...\n",
              "4183   -  Hello everyone. So this is what I might ca...  math>>multivariable-calculus>>multivariable-de...\n",
              "4184   -  Let's try now to subtract some two-digit n...        math>>early-math>>cc-early-math-add-sub-100\n",
              "4185   - Let's say that I have a circle. My best att...                          math>>engageny-geo>>geo-5\n",
              "4186   - So let's look at the female reproductive cy...  science>>health-and-medicine>>human-anatomy-an...\n",
              "4187   -  We're now in the home stretch. We just hav...  math>>multivariable-calculus>>greens-theorem-a...\n",
              "\n",
              "[4188 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQhO6qqt6lge"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD4IAgG1XQGp"
      },
      "source": [
        "import re\n",
        "def clean_sentence(question):\n",
        "  # print(question)\n",
        "  question = re.sub('<[^>]*>', ' ',question)\n",
        "  question = re.sub(' +', ' ', question)\n",
        "  question = re.sub('\\xa0','',question)\n",
        "  question = question.rstrip()\n",
        "  question = re.sub('nan','',question)\n",
        "  question = re.sub(u'\\u2004','',question)\n",
        "  question = re.sub(u'\\u2009','',question)\n",
        "\n",
        "  # question = question.decode(\"utf-8\")\n",
        "  # question = question.replace(u'\\u200\\d*','').encode(\"utf-8\")\n",
        "  question = re.sub('&nbsp','',question)\n",
        "  question = re.sub('&ndash','',question)\n",
        "  question = re.sub('\\r','',question)\n",
        "  question = re.sub('\\t','',question)\n",
        "  question = re.sub('\\n',' ',question)\n",
        "\n",
        "  question = re.sub('MathType@.*','',question)\n",
        "  question = re.sub('&thinsp','',question)\n",
        "  question = re.sub('&times','',question)\n",
        "  question = re.sub('\\u200b','',question)\n",
        "  question = re.sub('&rarr;;;','',question)\n",
        "\n",
        "  return question"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EyNZ9Tcc0Sg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab59641-a842-4eaf-d708-1925ecd11b41"
      },
      "source": [
        "!cp -r \"/content/drive/My Drive/Information_retrieval_project/model_hyperIM_khan_acad/\" /content/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/drive/My Drive/Information_retrieval_project/model_hyperIM_khan_acad/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIrS5sxE3kgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e6dc524-d2c9-481b-b1d0-f22ef11762ec"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mgc72PQYV1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f273e80-107d-4bd7-c179-41d6fac63023"
      },
      "source": [
        "train_data[\"hierarchy\"].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "science>>health-and-medicine>>circulatory-system-diseases     99\n",
              "science>>health-and-medicine>>human-anatomy-and-physiology    65\n",
              "science>>health-and-medicine>>respiratory-system-diseases     55\n",
              "science>>health-and-medicine>>circulatory-system              54\n",
              "science>>health-and-medicine>>infectious-diseases             52\n",
              "                                                              ..\n",
              "math>>5th-engage-ny>>engage-5th-module-1                       1\n",
              "math>>engageny-geo>>geo-3                                      1\n",
              "math>>in-in-grade-12-ncert>>in-in-relations-functions          1\n",
              "math>>precalculus>>x9e81a4f98389efdf:vectors                   1\n",
              "math>>cc-fourth-grade-math>>4th-multiply-fractions             1\n",
              "Name: hierarchy, Length: 569, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owuvwWJORK8W",
        "outputId": "a9286d56-c194-42d2-bc14-c8478c306910"
      },
      "source": [
        "test_data[\"hierarchy\"].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "science>>health-and-medicine>>human-anatomy-and-physiology                         24\n",
              "science>>health-and-medicine>>circulatory-system-diseases                          22\n",
              "science>>health-and-medicine>>circulatory-system                                   17\n",
              "science>>electrical-engineering>>robots                                            11\n",
              "science>>health-and-medicine>>infectious-diseases                                  11\n",
              "                                                                                   ..\n",
              "math>>8th-engage-ny>>engage-8th-module-2                                            1\n",
              "math>>in-in-class-5th-math-cbse>>x91a8f6d2871c8046:imp-place-value-and-decimals     1\n",
              "science>>biology>>photosynthesis-in-plants                                          1\n",
              "math>>algebra>>x2f8bb11595b61c86:quadratics-multiplying-factoring                   1\n",
              "math>>differential-equations>>first-order-differential-equations                    1\n",
              "Name: hierarchy, Length: 416, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3lYOb2K3kgy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "c00b2e69-f149-48ec-eca2-949009979426"
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "LE = LabelEncoder()\n",
        "LE.fit_transform(pd.concat([train_data['hierarchy'],test_data['hierarchy']]))\n",
        "train_data['label'] = LE.transform(train_data['hierarchy'])\n",
        "train_data.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_transcripts</th>\n",
              "      <th>hierarchy</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the last couple of videos we saw that we c...</td>\n",
              "      <td>math&gt;&gt;multivariable-calculus&gt;&gt;multivariable-de...</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-  What we're going to do in this video is gi...</td>\n",
              "      <td>science&gt;&gt;ap-biology&gt;&gt;natural-selection</td>\n",
              "      <td>422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>So once again, we have three equal, or we say...</td>\n",
              "      <td>math&gt;&gt;pre-algebra&gt;&gt;pre-algebra-equations-expre...</td>\n",
              "      <td>384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-  Liz's math test included a survey question...</td>\n",
              "      <td>math&gt;&gt;engageny-alg-1&gt;&gt;alg1-2</td>\n",
              "      <td>231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>- The following two equations form a linear s...</td>\n",
              "      <td>math&gt;&gt;algebra-home&gt;&gt;alg-system-of-equations</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   video_transcripts  ... label\n",
              "0   In the last couple of videos we saw that we c...  ...   354\n",
              "1   -  What we're going to do in this video is gi...  ...   422\n",
              "2   So once again, we have three equal, or we say...  ...   384\n",
              "3   -  Liz's math test included a survey question...  ...   231\n",
              "4   - The following two equations form a linear s...  ...    99\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsPRsySiz_ax",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "f2970ebc-3ab4-4884-fe07-9709597873de"
      },
      "source": [
        "test_data['label'] = LE.transform(test_data['hierarchy'])\n",
        "test_data.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_transcripts</th>\n",
              "      <th>hierarchy</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-  What I hope to do in this video is get fam...</td>\n",
              "      <td>math&gt;&gt;math1&gt;&gt;x89d82521517266d4:functions</td>\n",
              "      <td>335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the last video we were able to set up this...</td>\n",
              "      <td>math&gt;&gt;old-ap-calculus-ab&gt;&gt;ab-applications-defi...</td>\n",
              "      <td>357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-  In previous videos we talk about GDP as th...</td>\n",
              "      <td>economics-finance-domain&gt;&gt;ap-macroeconomics&gt;&gt;e...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-  So what we're gonna do in this video is se...</td>\n",
              "      <td>math&gt;&gt;old-integral-calculus&gt;&gt;definite-integral...</td>\n",
              "      <td>378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-  So I've said that if you have a vector fie...</td>\n",
              "      <td>math&gt;&gt;multivariable-calculus&gt;&gt;multivariable-de...</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   video_transcripts  ... label\n",
              "0   -  What I hope to do in this video is get fam...  ...   335\n",
              "1   In the last video we were able to set up this...  ...   357\n",
              "2   -  In previous videos we talk about GDP as th...  ...     3\n",
              "3   -  So what we're gonna do in this video is se...  ...   378\n",
              "4   -  So I've said that if you have a vector fie...  ...   354\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7Cvydgc-oAe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "76831e24-beec-48d7-ffce-30862cd71cb1"
      },
      "source": [
        "val_data['label'] = LE.transform(val_data['hierarchy'])\n",
        "val_data.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_transcripts</th>\n",
              "      <th>hierarchy</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Find the probability of rolling doubles on tw...</td>\n",
              "      <td>math&gt;&gt;precalculus&gt;&gt;x9e81a4f98389efdf:prob-comb</td>\n",
              "      <td>395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>After the food is swallowed, it leaves the m...</td>\n",
              "      <td>science&gt;&gt;health-and-medicine&gt;&gt;human-anatomy-an...</td>\n",
              "      <td>497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Let's now talk about what is easily one of th...</td>\n",
              "      <td>math&gt;&gt;geometry&gt;&gt;hs-geo-trig</td>\n",
              "      <td>256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The goal in this video is to essentially prov...</td>\n",
              "      <td>science&gt;&gt;chemistry&gt;&gt;thermodynamics-chemistry</td>\n",
              "      <td>472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A line goes through the points (-1, 6) and (5...</td>\n",
              "      <td>math&gt;&gt;in-in-grade-11-ncert&gt;&gt;in-in-class11-stra...</td>\n",
              "      <td>304</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   video_transcripts  ... label\n",
              "0   Find the probability of rolling doubles on tw...  ...   395\n",
              "1    After the food is swallowed, it leaves the m...  ...   497\n",
              "2   Let's now talk about what is easily one of th...  ...   256\n",
              "3   The goal in this video is to essentially prov...  ...   472\n",
              "4   A line goes through the points (-1, 6) and (5...  ...   304\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp64MkNB3kg1"
      },
      "source": [
        "def get_labels(prediction):\n",
        "    predicted_label =  LE.inverse_transform([prediction])\n",
        "    return predicted_label[0]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7diSzvlewx7a",
        "outputId": "ebd6b67e-0642-4a46-b347-e35869f52fe6"
      },
      "source": [
        "get_labels(571)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'science>>physics>>work-and-energy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPgTmJPS3kg4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7e1de3f-27d3-4906-a974-ef0771d1c3af"
      },
      "source": [
        "get_labels(204)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'math>>cc-seventh-grade-math>>cc-7th-fractions-decimals'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_UpqLMG3kg9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a476f22-e76f-4210-b879-6e38f9e3e718"
      },
      "source": [
        "train_data.iloc[14,1]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'economics-finance-domain>>macroeconomics>>monetary-system-topic'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5a3P7jSZZ6B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "5a9931ec-9f32-4552-e16b-7dd8def3ec84"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_transcripts</th>\n",
              "      <th>hierarchy</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the last couple of videos we saw that we c...</td>\n",
              "      <td>math&gt;&gt;multivariable-calculus&gt;&gt;multivariable-de...</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-  What we're going to do in this video is gi...</td>\n",
              "      <td>science&gt;&gt;ap-biology&gt;&gt;natural-selection</td>\n",
              "      <td>422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>So once again, we have three equal, or we say...</td>\n",
              "      <td>math&gt;&gt;pre-algebra&gt;&gt;pre-algebra-equations-expre...</td>\n",
              "      <td>384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-  Liz's math test included a survey question...</td>\n",
              "      <td>math&gt;&gt;engageny-alg-1&gt;&gt;alg1-2</td>\n",
              "      <td>231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>- The following two equations form a linear s...</td>\n",
              "      <td>math&gt;&gt;algebra-home&gt;&gt;alg-system-of-equations</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4183</th>\n",
              "      <td>-  Hello everyone. So this is what I might ca...</td>\n",
              "      <td>math&gt;&gt;multivariable-calculus&gt;&gt;multivariable-de...</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4184</th>\n",
              "      <td>-  Let's try now to subtract some two-digit n...</td>\n",
              "      <td>math&gt;&gt;early-math&gt;&gt;cc-early-math-add-sub-100</td>\n",
              "      <td>226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4185</th>\n",
              "      <td>- Let's say that I have a circle. My best att...</td>\n",
              "      <td>math&gt;&gt;engageny-geo&gt;&gt;geo-5</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4186</th>\n",
              "      <td>- So let's look at the female reproductive cy...</td>\n",
              "      <td>science&gt;&gt;health-and-medicine&gt;&gt;human-anatomy-an...</td>\n",
              "      <td>497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4187</th>\n",
              "      <td>-  We're now in the home stretch. We just hav...</td>\n",
              "      <td>math&gt;&gt;multivariable-calculus&gt;&gt;greens-theorem-a...</td>\n",
              "      <td>352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4188 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      video_transcripts  ... label\n",
              "0      In the last couple of videos we saw that we c...  ...   354\n",
              "1      -  What we're going to do in this video is gi...  ...   422\n",
              "2      So once again, we have three equal, or we say...  ...   384\n",
              "3      -  Liz's math test included a survey question...  ...   231\n",
              "4      - The following two equations form a linear s...  ...    99\n",
              "...                                                 ...  ...   ...\n",
              "4183   -  Hello everyone. So this is what I might ca...  ...   354\n",
              "4184   -  Let's try now to subtract some two-digit n...  ...   226\n",
              "4185   - Let's say that I have a circle. My best att...  ...   240\n",
              "4186   - So let's look at the female reproductive cy...  ...   497\n",
              "4187   -  We're now in the home stretch. We just hav...  ...   352\n",
              "\n",
              "[4188 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqTUkuPo3khA"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_features, test_features, train_labels, test_labels = train_data[\"video_transcripts\"],test_data[\"video_transcripts\"],train_data[\"label\"],test_data[\"label\"]\n",
        "val_features,val_labels = val_data[\"video_transcripts\"], val_data[\"label\"]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prM_km_83khD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512163a6-f7ea-4a1e-b834-b30cde5d66ee"
      },
      "source": [
        "train_labels.value_counts()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "489    99\n",
              "497    65\n",
              "505    55\n",
              "488    54\n",
              "498    52\n",
              "       ..\n",
              "382     1\n",
              "359     1\n",
              "195     1\n",
              "471     1\n",
              "216     1\n",
              "Name: label, Length: 569, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfhPstXJ03oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f5e7bd-3ac5-437c-9157-b258bc0471d1"
      },
      "source": [
        "test_labels.value_counts()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "497    24\n",
              "489    22\n",
              "488    17\n",
              "93     11\n",
              "485    11\n",
              "       ..\n",
              "192     1\n",
              "191     1\n",
              "398     1\n",
              "187     1\n",
              "291     1\n",
              "Name: label, Length: 416, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkyM7gqv3khI"
      },
      "source": [
        "question_answer = train_features.values\n",
        "categories = train_labels.values"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFkS_H_83khL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11739a4c-26e2-428f-fce3-414ba49550d6"
      },
      "source": [
        "question_answer"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\" In the last couple of videos we saw that we can describe a curves by a position vector-valued function. And in very general terms, it would be the x position as a function of time times the unit vector in the horizontal direction. Plus the y position as a function of time times the unit victor in the vertical direction. And this will essentially describe this-- though, if you can imagine a particle and let's say the parameter t represents time. It'll describe where the particle is at any given time. And if we wanted a particular curve we can say, well, this only applies for some curve-- we're dealing, it's r of t. And it's only applicable between t being greater than a and less than b. And you know, that would describe some curve in two dimensions. Just me just draw it here. This is all a review of really, the last two videos. So this curve, it might look something like that where this is where t is equal to a. That's where t is equal to b. And so r of a will be this vector right here that ends at that point. And then as t or if you can imagine the parameter being time, it doesn't have to be time, but that's a convenient one to visualize. Each corresponding as t gets larger and larger, we're just going to different-- we're specifying different points on the path. We saw that two videos ago. And in the last video we thought about, well, what does it mean to take the derivative of a vector-valued function? And we came up with this idea that-- and it wasn't an idea, we actually showed it to be true. We came up with a definition really. That the derivative-- I could call it r prime of t-- and it's going to be a vector. The derivative of a vector-valued function is once again going to be a derivative. But it was equal to-- the way we defined it-- x prime of t times i plus y prime of t times j. Or another way to write that and I'll just write all the different ways just so you get familiar with-- dr/dt is equal to dx/dt. This is just a standard derivative. x of t is a scalar function. So this is a standard derivative times i plus dy/dt times j. And if we wanted to think about the differential, one thing that we can think about-- and whenever I do the math for the differential it's a little bit hand wavy. I'm not being very rigorous. But if you imagine multiplying both sides of the equation by a very small dt or this exact dt, you would get dr is equal to-- I'll just leave it like this. dx/dt times dt. I could make these cancel out, but I'll just write it like this first. Times the unit vector i plus dy/dt times dt. Times the unit vector j. Or we could rewrite this. And I'm just rewriting it in all of the different ways that one can rewrite it. You could also write this as dr is equal to x prime of t dt times the unit vector i. So this was x prime of t dt. This is x prime of t right there times the unit vector i. Plus y prime of t. That's just that right there. Times dt. Times the unit vector j. And just to, I guess, complete the trifecta, the other way that we could write this is that dr is equal to-- if we just allowed these to cancel out, then we get is equal to dx times i plus dy times dy y times j. And that actually makes a lot of intuitive sense. That if I look at any dr, so let's say I look at the change between this vector and this vector. Let's say the super small change right there, that is our dr, and it's made up of-- it's our dx, our change in x is that right there. You can imagine it's that right there times-- but we're vectorizing it by multiplying it by the unit vector in the horizontal direction. Plus dy times the unit vector in the vertical direction. So when you multiply this distance times the unit vector, you're essentially getting this vector. And when you multiply this guy-- and actually our change in y here is negative-- you're going to get this vector right here. So when you add those together you'll get your change in your actual position vector. So that was all a little bit of background. And this might be somewhat useful-- a future video from now. Actually, I'm going to leave it there because really I just wanted to introduce this notation and get you familiar with it. In the next video, what I'm going to do is give you a little bit more intuition for what exactly does this thing mean? And how does it change depending on different parameterizations. And I'll do it with two different parameterizations for the same curve.\",\n",
              "       \" -  What we're going to do in this video is give ourselves a little bit of a tour of eukaryotic cells. And the first place to start is just to remind ourselves what it means for a cell to be eukaryotic. It means that inside the cell, there are membrane-bound organelles. Now, what does that mean? Well, you could view it as sub-compartments within the cell. Membrane-bound organelles. And in this video in particular, we're going to highlight some of these membrane-bound organelles that make the cells eukaryotic. So let's just start with some of the ingredients that we know is true of all cells. So you'll have your cellular membrane here. I drew it big, so that we have a lot of space to draw things in. So this is our cellular membrane. I'll do some nice shading so you appreciate that it'll actually be three-dimensional. We see so many slices of cells that sometimes we forget that they are more spherical, or that they have three-dimensional shape to them. They're not all spherical. They can have different shapes. Now all cells, and there are some exceptions that we've talked about in previous videos. I should say, most cells will have some genetic information in them in the form of DNA. So that is our DNA, right over there. Now, one of the key characteristics of a eukaryotic cell is that the genetic information is going to be inside a membrane-bound organelle. And that membrane-bound organelle, or the membrane that surrounds the DNA here, that is the nuclear membrane. So let me draw the nuclear membrane right over here, and I'll put some shading in to appreciate that that also is going to be in three dimensions, around the DNA. So that is the first membrane-bound organelle that we're gonna discuss, the nucleus. Now the nucleus, it turns out, is connected to another membrane-bound organelle. And we're gonna study this in future videos, but right here I'm drawing holes or pores in the nuclear membrane. And those pores connect to something, it's a very fancy word called the endoplasmic reticulum. And the endoplasmic reticulum is essentially these layers of these membranes. So I'm gonna do my best job at trying to draw an endoplasmic reticulum. Imagine extending from these pores, going into a space that has really these layered membranes that have a lot of surface area. And I'm not gonna go all the way around this nucleus, but in many cells it will go around, all the way around the nucleus. And this right over here, and this is just a rough diagram. That is our endoplasmic, endoplasmic... Not blasmic, endoplasmic... Endoplasmic reticulum, which I've mentioned in previous videos would be an excellent name for a band. And what goes on in the endoplasmic reticulum is when you are in the process of taking that genetic information from DNA, and as we talk about in other videos it gets transcribed into mRNA. So that mRNA is now containing that information. That mRNA will make its way out of that nuclear membrane through one of these pores, and then make its way to a ribosome that is attached to the membrane of the endoplasmic reticulum. And so that's a ribosome there. I'm gonna do a bunch of ribosomes. And so as we've talked about in previous videos, ribosomes are really where you take that genetic information from that mRNA, and then you translate it into a protein. So the ribosomes are the protein synthesis, so let me label that. So this right over here is a ribosome. And some ribosomes might be attached to the endoplasmic reticulum. Some of them might just be floating out here in the cytoplasm, so that would be a free ribosome. Free ribosome. And even from the point of view of the endoplasmic reticulum, the parts of the endoplasmic reticulum where you have ribosomes attached, this is known as rough endoplasmic reticulum. It's the ribosomes that are making them rough. It looks that way in a microscope. So I'll just say rough ER, for endoplasmic reticulum for short. And then you also have parts of the endoplasmic reticulum where you do not have ribosomes attached. And because that looks smooth through our microscope, it has been called, you can imagine, smooth endoplasmic reticulum. There are things known as golgi bodies. Once again, another fascinating name. You gotta love these names in biology. That look kind of like an endoplasmic reticulum, but detached from the nuclear membrane. So let's say it's something like that. That's my best drawing there. That's a golgi body. And these are really good at packaging molecules, even proteins that might've just been produced, and packaging them so that they can be used outside of the cell, for example. And we'll go into detail in other videos, where a protein might go to the golgi body, get a little envelope around it, get some little processing going on, and then make its way outside of a cell. Now another, and this is maybe one of the most famous membrane-bound organelles outside of the nucleus, is what's known as the powerhouse of the cell, and that is the mitochondria. So I'll draw this mitochondria in magenta, because that's a nice powerful color. So mitochondria. And I love mitochondria because it's fascinating how they even came to be. Mitochondria actually have their own DNA, and all of your mitochondrial DNA comes from your mother. So that's actually very interesting for tracing maternal lineage. But mitochondria, this is where your, I'm gonna say let's see what we could see inside of this. This is where you ATP is produced. This is your mitochondria. It's really the powerhouse of the cell. What's interesting about mitochondria is evolutionary biologists believe that the ancestors of mitochondria, because mitochondria have their own DNA, they might've been independent organisms, independent cells. And at some point in our evolutionary past, they started living in symbiosis inside of what would be the ancestors of our cells. And over time, they became so codependent that they started to replicate together. And mitochondria, in fact, became part of these eukaryotic cells. Now if this eukaryotic cell was a plant cell or maybe an algae cell, you would have something called chloroplasts there. We don't have them because we don't have photosynthesis, but this is a chloroplast. And if you could see inside, you could see the little thylakoid stacks right over here. You could see the thylakoids if you could see inside. And so this right over here is a chloroplast. Chloroplast. And this would be plants and algae. Animals do not have these. And these are where you have your photosynthesis take place. Photosynthesis. Now there's also some membrane-bound organelles that are maybe less famous than the mitochondria or the chloroplast, or for sure the nucleus, and that might be something like a vacuole. And in plants, vacuoles tend to be very big. I could draw it, this is three-dimensional so I'll draw it on top of something that I've drawn before. So if a vacuole right over here, this is a... And in a plant it could be a fairly significant compartment inside. And in fact, it can even give structure to the plant itself because it is so big. And it contains water and enzymes. It's viewed as kind of a storage compartment. But it can also contain enzymes that help digest things, that help break things down so that they can be used in some way. So that is a vacuole. And they don't just exist in plants. They can also exist in animal cells. But in plant cells, they can be very, very, very visible. Now, something that is somewhat related to some of the function that a vacuole plays, that are most associated with animal cells but now there's evidence that they also exist in plant cells, is the idea of a lysosome. So a lysosome right over here, that also is a compartment. And it's going to contain a whole series of enzymes in it that is useful for lysing, you could say, that is useful for breaking down either waste products as the cell lives, or even foreign substances that might not be helpful for the cells. So it's gonna contain a bunch of enzymes, and it helps break down things. Now, I'll leave you there. These aren't all of the structures in eukaryotic cells, but these are enough of the structures so that you can appreciate that there are a lot of membrane-bound organelles in eukaryotic cells. And to be clear, even if I were to show all of the membrane-bound structures, that's not all the complexity of the cell. The big thing to appreciate is that cells are incredibly complex. There's all sorts of structures in here that help transport things and move things around. If you could shrink yourself down and look inside of a cell, it would look more complex than the most complex cities. There's all sorts of activities, things being moved around, shuttled around. The cell itself is replicating and copying things. And so this is just the beginning. We're just starting to scratch the surface of the complexity of the most basic unit of life.\",\n",
              "       \" So once again, we have three equal, or we say three identical objects. They all have the same mass, but we don't know what the mass is of each of them. But what we do know is that if you total up their mass, it's the same exact mass as these nine objects right over here. And each of these nine objects have a mass of 1 kilograms. So in total, you have 9 kilograms on this side. And over here, you have three objects. They all have the same mass. And we don't know what it is. We're just calling that mass x. And what I want to do here is try to tackle this a little bit more symbolically. In the last video, we said, hey, why don't we just multiply 1/3 of this and multiply 1/3 of this? And then, essentially, we're going to keep things balanced, because we're taking 1/3 of the same mass. This total is the same as this total. That's why the scale is balanced. Now, let's think about how we can represent this symbolically. So the first thing I want you to think about is, can we set up an equation that expresses that we have these three things of mass x, and that in total, their mass is equal to the total mass over here? Can we express that as an equation? And I'll give you a few seconds to do it. Well, let's think about it. Over here, we have three things with mass x. So their total mass, we could write as-- we could write their total mass as x plus x plus x. And over here, we have nine things with mass of 1 kilogram. I guess we could write 1 plus 1 plus 1. That's 3. Plus 1 plus 1 plus 1 plus 1. How many is that? 1, 2, 3, 4, 5, 6, 7, 8, 9. And actually, this is a mathematical representation. If we set it up as an equation, it's an algebraic representation. It's not the simplest possible way we can do it, but it is a reasonable way to do it. If we want, we can say, well, if I have an x plus another x plus another x, I have three x's. So I could rewrite this as 3x. And 3x will be equal to? Well, if I sum up all of these 1's right over here-- 1 plus 1 plus 1. We're doing that. We have 9 of them, so we get 3x is equal to 9. And let me make sure I did that. 1, 2, 3, 4, 5, 6, 7, 8, 9. So that's how we would set it up. And so the next question is, what would we do? What can we do mathematically? Actually, to either one of these equations, but we'll focus on this one right now. What can we do mathematically in order to essentially solve for the x? In order to figure out what that mystery mass actually is? And I'll give you another second or two to think about it. Well, when we did it the last time with just the scales we said, OK, we've got three of these x's here. We want to have just one x here. So we can say, whatever this x is, if the scale stays balanced, it's going to be the same as whatever we have there. There might be a temptation to subtract two of the x's maybe from this side, but that won't help us. And we can even see it mathematically over here. If we subtract two x's from both sides, on the left-hand side you're going to have 3x minus 2x. And on the right-hand side, you're going to have 9 minus 2x. And you're just going to be left with 3 of something minus 2 something is just 1 of something. So you will just have an x there if you get rid of two of them. But on the right-hand side, you're going to get 9 minus 2 x's. So the x's still didn't help you out. You still have a mystery mass on the right-hand side. So that doesn't help. So instead, what we say is-- and we did this the last time. We said, well, what if we took 1/3 of these things? If we take 1/3 of these things and take 1/3 of these things, we should still get the same mass on both sides because the original things had the same mass. And the equivalent of doing that mathematically is to say, why don't we multiply both sides by 1/3? Or another way to say it is we could divide both sides by 3. Multiplying by 1/3 is the same thing as dividing by 3. So we're going to multiply both sides by 1/3. When you multiply both sides by 1/3-- visually over here, if you had three x's, you multiply it by 1/3, you're only going to have one x left. If you have nine of these one-kilogram boxes, you multiply it by 1/3, you're only going to have three left. And over here, you can even visually-- if you divide by 3, which is the same thing as multiplying by 1/3, you divide by 3. So you divide by 3. You have an x is equal to a 1 plus 1 plus 1. An x is equal to 3. Or you see here, an x is equal to 3. Over here you do the math. 1/3 times 3 is 1. You're left with 1x. So you're left with x is equal to 9 times 1/3. Or you could even view it as 9 divided by 3, which is equal to 3.\",\n",
              "       ...,\n",
              "       ' - Let\\'s say that I have a circle. My best attempt to draw a reasonably perfect circle. So, there you go, not too bad, it\\'s a little bit of a hairy circle but you get the idea. So, this is a circle, this is the center of the circle, and let\\'s say that I have an arc along this circle. So, I\\'ll do the arc in green. So, I have an arc that is part of the circle, and it subtends an angle, so that\\'s my arc. Right over there, and it subtends an angle, and the angle that it subtends, so what I mean subtends, you take each of the endpoints of the arc, go to the center of the circle, go to the center of the circle just like this, and so it subtends angle theta, right over here, so it subtends angle theta, and let\\'s say that we know that angle theta is equal to two radians. So my question to you is what fraction of the entire circumference is this green arc? What fraction of the entire circumference is this green arc? And like always, pause the video, and give it a go. (laughs) All right, so let\\'s think through it a little bit. So, you might say well how do I know that, I don\\'t know what the radius of this thing is, I don\\'t, how do I think through this? And we just have to remind ourselves what radians mean, what radians mean. If an arc subtends the angle of two radians, that means that the arc itself is two \"radiuseseses\" long. (laughs) So, this right over here, let me make this a little clearer, so this, if the radius is r, if this radius is, I already used that color, if this radius... I have trouble switching colors (laughs) all right. If this radius is length r, then the length, if this angle is two radians, then the arc that subtends it is going to be two radiuses long, so this length right over here, is two radiuses. Now, what fraction of the entire circumference is that? Well, the entire circumference, we know, we know this from basic geometry, the entire circumference is two pi times the radius, or you can say it\\'s two pi radii, two pi \"radiuseses\", (laughs) two pi radii is the correct way to say it. So, what fraction is it? It\\'s two radii, it\\'s two radii, over two pi radii, over two pi radii, twos cancel out, rs cancel out, and so it is one \"pith\", (laughs) I guess you could say, it is one over pi of the total circumference.',\n",
              "       \" - So let's look at the female reproductive cycle. The female reproductive cycle refers to the maturation of eggs within the ovaries. The ovaries initially created these eggs during gestation. In other words, when a baby girl is in her mother's womb, the baby girl's entire egg supply will be created but will remain in an inactive state. This process of egg creation is called oogenesis. Then, once she grows up a bit and reaches puberty, her reproductive cycle will start, and one egg in that egg supply in her ovaries will mature or become activated each month, and that allows it to be fertilized by sperm. By the way, another word for egg is oocyte. After an egg matures, it's pushed out of the ovary in a process called ovulation. The other major function of the ovaries is to secrete the female sex hormones, estrogen, progesterone, and one called inhibin, and we'll talk about their functions a little bit later on. So let's first discuss how the eggs are made in the ovary in the first place. So early in uteral development, precursor germ cells, which are called oogonia, and those are homologous to spermatagonia in males, these oogonia undergo a ton of mitotic divisions to make more of themselves. And then, at about the 7th month of development, these divisions stop, and all of the ones that have been produced, which is actually about two to four million, are all she'll have for the rest of her life, and that turns out to be about one to two million per ovary. So while she's still in fetal development, all of these oogonia that have been produced, they all develop into the next stage, which is a primary oocyte. And just remember that the two oo's refers to egg, and the cyte, C-Y-T-E, refers to cell. So this just means egg cell, in case you were wondering. And let me also just mention, on a chromosomal level these oogonia, the germ cells, they're 2n, which means they have two copies of each chromosome, and the primary oocytes are the same. They're also 2n. And then these primary oocytes, they begin meiosis 1, and meiosis is what our germ cells use to reduce our chromosome copy number, and by that, I just mean the number of copies of DNA that we have. So they start this process of meiosis 1, but they don't actually finish it. They just kind of get about halfway through, and then they stop. So they're stuck as these big cells. So they're still primary oocytes, but they're said to be in meiotic arrest. So when the female who's been developing in her mom's womb, when she's born, her primary oocytes are in meiotic arrest. So the question is, do they stay like this? And the answer is, some do and some don't. Let's zoom in on this reproductive system to try to explain. So this is just a closeup of the major parts of the female reproductive system, and I've cut away parts of the uterus and the uterine tubes and the ovaries so you can see sort of the inside and the outsides of both structures. And this is our key organ here. This is the ovary. So the question was, do these primary oocytes that are stuck in meiotic arrest, do they stay like that? So the answer is that the ones that are sort of destined to be ovulated, that is, to be pushed out of the ovary right about here and then to be picked up by the fimbriae and then travel along the uterine tube here, those ones get past meiotic arrest. But most of them sort of die off while they're still stuck in that meiotic arrest phase as a primary oocyte. So I've mentioned the ones that sort of get out of the meiotic arrest phase and move on to develop into secondary oocytes that are able to then fuse with sperm, but when exactly does that happen? Well, it starts at puberty. So they actually stay in this phase as primary oocytes up here, in meiotic arrest for like 12 to 13 years, give or take, and only then do they start moving forward with development by finishing off that first part of meiosis that they started and splitting into two secondary oocytes. And actually, that's not exactly true, even though that's what we'd expect. What actually happens is one primary occyte it attempts to split into two secondary oocytes, but that's not exactly what happens. What does happen is that one of the developing daughter cells develops beautifully into a normal secondary oocyte from the primary oocyte, but it turns out that when they do complete the first part of meiosis, something really interesting happens. One of these cells receives basically all the cytoplasm. So the chromosome copy number is halved, but basically all the cytoplasm is kept in one cell. So this little guy over here that didn't get much cytoplasm, it still has a full complement of chromosomes, but it still ends up being pretty small and not really very functional. So it kind of withers away and dies, and it's called a polar body. So you end up with this really large secondary oocyte, and this is what ends up getting ovulated. And so now you might be thinking, well, meiosis is two steps, right? When does the second step happen? And that's a good question. So again, ovulation happens roughly here with the secondary oocyte coming out, and this secondary oocyte sort of just hangs out in the uterine tubes, and a sperm comes along and fertilizes the egg. So let's look at that down here. So you have your uterine tube here, and you have your egg. That's a secondary oocyte now. And then a sperm is coming along, and the sperm fuses with the egg after fertilizing it. And so the sperm fertilizes the egg and fuses with it. And so, let's just zoom in on what's happening there. So here you have your big secondary oocyte, and then you have your sperm that sort of, let's say that the nucleus of the sperm is right here. It's inside the egg already. This is the nucleus of the sperm. And here's the nucleus of the secondary oocyte. Well this is when meiosis 2 happens, so the second half of meiosis. So as this sperm nucleus is traveling toward the egg nucleus to create a joint nucleus, meiosis 2 occurs, and the oocyte reduces its chromosome copy number by creating another polar body, so a second polar body that kind of divides off the cell. So the oocyte cuts its chromosome copy number in half again, and so this little bit of DNA here that's just an extra copy of the DNA the egg already has, it divides off the cell in the form of another polar body that doesn't really have that much cytoplasm, just like the first one. So again, it leaves its nutrient-rich cytoplasm behind for the sperm and the egg. And by the way, the egg has changed its name now from a secondary oocyte to an ovum, but it won't be an ovum for long. Once the sperm nucleus fuses with the egg nucleus, then it becomes a zygote. So let me just clarify that if the egg doesn't get fertilized by a sperm that comes along, then it doesn't complete that second meiotic division that it did right here, and it just gets discharged from the body in menstruation as a secondary oocyte and not as an ovum, because the name ovum is reserved for the oocyte only once it's been fertilized. So those are the basic concepts behind what goes on with egg development.\",\n",
              "       \" -  We're now in the home stretch. We just have to evaluate the curl of f and then this dot product and then evaluate this double integral. So let's work on the curl of F. So the curl of f is going to be equal to, and I just remember it as the determit, so we have our i, j, k components, and it's really you could imagine it's the del operator crossed with the actual vector. So the del operator, I'll write this in a different color just to ease the monotony, so this is partial with respect to x, partial with respect to y, partial with respect to z, and then our vector field, I copied and pasted it right over here. It is just equal to negative y squared, is our i component, x is our j component, and Z squared is our k component. And so this is going to be equal to, this is going to be equal to i, is going to be equal to i times the partial of Z squared with respect to y. Well, there's the Z squared is just a constant with respect to y so the partial of Z squared with respect to y is just going to be zero, so this is going to be zero. Minus the partial of x with respect to z. Well, once again this is just a constant when you think in terms of z, so that's just going to be zero. So that's nice simplification, and then we're gonna have minus j, we need our little checkerboard patterns, we put a negative in front of the j, minus j and so we'll have the partial of x, the partial of z squared with respect to x, that's zero again, and then minus the partial of negative y squared with respect to z, well that's zero again, and then finally we have our k component, k, so plus, plus k, and k, we're gonna have the partial of x with respect to x, well that actually gives us a value that's just gonna be one minus the partial of negative y squared with respect to y. So the partial of negative y squared with respect to y is negative two y and we're subtracting that, so it's going to be plus, plus, two y. So curl of f simplifies to just, all of this is just zero up here, is just one plus two y times k or k times one plus two y. And so if we go back to this right up here, if we go back up to that, we're going to get let me re-write the integral so zero to one and that's our r, our r parameter is gonna go from zero to one, theta is gonna go from zero to two pi. And now curl of f has simplified to, and I won't skip any steps although it's tempting, it's one plus two y, and actually instead of writing two y, let me write it in terms of the parameters. We saw it up here, y was r sine theta, if I remember correctly, right, y was r sine theta. So let me write y that way. Two times r sine theta k. And we're gonna dot this, we're gonna take the dot product of that with this right over here, with r times j plus r times k, d theto d r. And so we take the dot product, this thing only has a k component, the j component is zero, so when you take the dot product with this j component you're gonna get zero. And neither of them you actually even have an i component. And so the inside is just going to simplify to this piece right over here is going to simplify to, we're just gonna have to think about the k components, cause everything else is zero, so it's gonna be r times this and we're done! So it's gonna be r plus two r squared sine theta, d theta d r, d theta d r and, once again, theta goes from zero to two pi and r goes from zero to one. And now this is just a straight-up double integral. We just have to evaluate this thing. And so, first we take the antiderivative with respect to theta, so the antiderivative with respect to theta is going to give us, so this is going to be giving, so we're going to focus on theta first, so the antiderivative of r with respect to theta is just r theta, you can just do r as a constant, and then the antiderivative of this, antiderivative of sine of theta is negative cosine of theta. So this is gonna be negative two r squared cosine of theta. And we're gonna evaluate it from zero to two pi. And then we have the outside integral, which I will, I'll re-color in yellow, re-color in yellow, so we'll still have to integrate with respect to r and r's gonna go from zero to one. But inside right over here, if we evaluate all of this business right over here at two pi, we get two pi r, two pi r, that's that right over there, minus... Cosine of two pi is just one. So it's minus two r squared and then from that, we're going to subtract from that, we're gonna subtract this evaluated zero. Well r times zero is just zero, and then cosine of zero is one. So it's just minus two r squared, or negative two r squared, negative two r squared. And at this negative and this negative, you get a positive, and but then you have a negative two r squared and then a plus two r squared it's just going to cancel out, that and that cancel out, and so this whole thing has simplified quite nicely to a simple definite integral, zero to one of two pi, two pi r dr, and the antiderivative of this is just going to be pi r squared, so we're just gonna evaluate pi r squared from zero to one, when you evaluate it at one, you get pi; when you evaluate it at zero, you just get zero, so you get pi minus zero, which is equal to, and now we deserve a drumroll 'cause we've been doing a lot of work over many videos, this is equal to pi. So just to remind ourselves what we've done over the last few videos, we had this line integral that we were trying to figure out, and instead of directly evaluating the line integral, which we could do and I encourage you to do so, and if I have time, I might do it in the next video, instead of directly evaluating that line integral, we used Stokes theorem to say, oh we could actually instead say that that's the same thing as a surface integral over a piecewise-smooth boundary over piecewise-smooth surface that this path is the boundary of, and so we evaluated this surface intergal and eventually, with a good bit of, little bit of calculation, we got to evaluating it to be equal to pi.\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ian7gSDE3khR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce09059c-95e7-42a4-8579-6f1dc18cf68e"
      },
      "source": [
        "categories"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([354, 422, 384, ..., 240, 497, 352])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gNnga-onGn9"
      },
      "source": [
        "# this method can be used to project from euclidean space to hyperbolic space\n",
        "def exponential_map(vector):\n",
        "        norm_v = np.linalg.norm(vector, axis=1)\n",
        "        coef = np.tanh(norm_v) / norm_v\n",
        "        second_term = vector * coef[:, None]\n",
        "        return second_term"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwNdG6eFaEMB"
      },
      "source": [
        "# this method can be used to project from euclidean space to hyperbolic space\n",
        "def tensor_exponential_map(vector):\n",
        "      vector_norm = vector.norm(dim=-1, p=2, keepdim=True).clamp_min(1e-15)\n",
        "      gamma_1 = torch.nn.functional.tanh(vector_norm) * (vector / vector_norm)\n",
        "      return gamma_1"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zryRR25JlYC0"
      },
      "source": [
        "def tensor_log_map(vector):\n",
        "      vector_norm = vector.norm(dim=-1, p=2, keepdim=True).clamp_min(1e-15)\n",
        "      gamma_1 = torch.atanh(vector_norm) * (vector / vector_norm)\n",
        "      return gamma_1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN1zRXMOXwLK"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "from bokeh.io import output_file, output_notebook, show\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.transform import linear_cmap\n",
        "from bokeh.util.hex import hexbin\n",
        "from bokeh.models import HoverTool\n",
        "from bokeh import colors\n",
        "\n",
        "from gzip import open as gopen\n",
        "\n",
        "import gensim.models.poincare as poincare\n",
        "poincare_model = poincare.PoincareModel.load(\"taxonomy_khan_acad_embedding_20.pkl\")\n",
        "def get_poincare_embeddings_data(taxonomy):\n",
        "  cleaned_taxonomy = []\n",
        "  for value in taxonomy:\n",
        "      value = value.split(\">>\")\n",
        "      cleaned_taxonomy.append( list(tok.lower() for tok in value) )\n",
        "  return cleaned_taxonomy"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPAl0TNuX6mx"
      },
      "source": [
        "\n",
        "# course_taxonomy\n",
        "\n",
        "\n",
        "# course_taxonomy\n",
        "\n",
        "poincare_emb_data_train = get_poincare_embeddings_data(train_data[\"hierarchy\"].values)\n",
        "poincare_emb_data_val = get_poincare_embeddings_data(val_data[\"hierarchy\"].values)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq2G2XIrYjy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fe26c6-6c8d-4352-f22d-a56dcece4be7"
      },
      "source": [
        "poincare_embedding_train =  [exponential_map(np.expand_dims( np.hstack(  [ poincare_model.kv.get_vector(str(x)) for x in taxonomy ] ),axis=0)) for taxonomy in poincare_emb_data_train ]\n",
        "np.linalg.norm(poincare_embedding_train[1000])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.899765215781272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hza4bbKKbGgC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f6dba5-2488-4533-c95b-2c3f5317b85a"
      },
      "source": [
        "poincare_embedding_val=  [exponential_map(np.expand_dims( np.hstack(  [ poincare_model.kv.get_vector(str(x)) for x in taxonomy ] ),axis=0)) for taxonomy in poincare_emb_data_val ]\n",
        "np.linalg.norm(poincare_embedding_val[100])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8857759138716806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbl7uFDmEdHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0361bb8-bbe0-41a6-8521-3489002bc4de"
      },
      "source": [
        "max_val_train = 0\n",
        "max_emb =None\n",
        "for embedding in poincare_embedding_train:\n",
        "  val = embedding.shape[1]\n",
        "  if val >max_val_train:\n",
        "    max_val_train=val\n",
        "    max_emb =embedding\n",
        "max_val_train\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BTbk9fua7yO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7b7e65a-3c81-424c-8a34-ea90ce951d3f"
      },
      "source": [
        "max_val_val = 0\n",
        "max_emb =None\n",
        "for embedding in poincare_embedding_val:\n",
        "  val = embedding.shape[1]\n",
        "  if val >max_val_train:\n",
        "    max_val_val=val\n",
        "    max_emb =embedding\n",
        "max_val_val\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfxg_6FYfv6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eacb5be0-5967-462e-dc96-b067801698c4"
      },
      "source": [
        "len(set(categories))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "569"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0RXfn5xEf5t"
      },
      "source": [
        "def get_concat_embedding(poincare_embedding,max_val):\n",
        "  concatenated_embedding = []\n",
        "  for embedding in poincare_embedding:\n",
        "    if embedding.shape[1] < max_val:\n",
        "      new_embedding = np.append(embedding, np.expand_dims(np.zeros(max_val-embedding.shape[1]),axis=0),axis=1)\n",
        "    else:\n",
        "      new_embedding = embedding\n",
        "    concatenated_embedding.append(np.squeeze(new_embedding,axis=0))\n",
        "  return concatenated_embedding\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svuJZqfpLu_6"
      },
      "source": [
        "concat_embedding_train = get_concat_embedding(poincare_embedding_train,max_val_train)\n",
        "concat_embedding_val = get_concat_embedding(poincare_embedding_val,max_val_train)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCQswt5pMBRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ee60a3-7892-49b0-c29e-241ee6b08e78"
      },
      "source": [
        "poincare_embeddings_final_train = np.stack(concat_embedding_train, axis=0)\n",
        "poincare_embeddings_final_train.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4188, 60)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0THx2wVJ4xF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90b2d9bd-84e8-46f2-c8e1-7fea0060fc2d"
      },
      "source": [
        "poincare_embeddings_final_val = np.stack(concat_embedding_val, axis=0)\n",
        "poincare_embeddings_final_val.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(924, 60)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_ZeuHc63khU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef5898b7-0edc-41a6-aba5-4d5d1411fd51"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in question_answer:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', question_answer[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:   In the last couple of videos we saw that we can describe a curves by a position vector-valued function. And in very general terms, it would be the x position as a function of time times the unit vector in the horizontal direction. Plus the y position as a function of time times the unit victor in the vertical direction. And this will essentially describe this-- though, if you can imagine a particle and let's say the parameter t represents time. It'll describe where the particle is at any given time. And if we wanted a particular curve we can say, well, this only applies for some curve-- we're dealing, it's r of t. And it's only applicable between t being greater than a and less than b. And you know, that would describe some curve in two dimensions. Just me just draw it here. This is all a review of really, the last two videos. So this curve, it might look something like that where this is where t is equal to a. That's where t is equal to b. And so r of a will be this vector right here that ends at that point. And then as t or if you can imagine the parameter being time, it doesn't have to be time, but that's a convenient one to visualize. Each corresponding as t gets larger and larger, we're just going to different-- we're specifying different points on the path. We saw that two videos ago. And in the last video we thought about, well, what does it mean to take the derivative of a vector-valued function? And we came up with this idea that-- and it wasn't an idea, we actually showed it to be true. We came up with a definition really. That the derivative-- I could call it r prime of t-- and it's going to be a vector. The derivative of a vector-valued function is once again going to be a derivative. But it was equal to-- the way we defined it-- x prime of t times i plus y prime of t times j. Or another way to write that and I'll just write all the different ways just so you get familiar with-- dr/dt is equal to dx/dt. This is just a standard derivative. x of t is a scalar function. So this is a standard derivative times i plus dy/dt times j. And if we wanted to think about the differential, one thing that we can think about-- and whenever I do the math for the differential it's a little bit hand wavy. I'm not being very rigorous. But if you imagine multiplying both sides of the equation by a very small dt or this exact dt, you would get dr is equal to-- I'll just leave it like this. dx/dt times dt. I could make these cancel out, but I'll just write it like this first. Times the unit vector i plus dy/dt times dt. Times the unit vector j. Or we could rewrite this. And I'm just rewriting it in all of the different ways that one can rewrite it. You could also write this as dr is equal to x prime of t dt times the unit vector i. So this was x prime of t dt. This is x prime of t right there times the unit vector i. Plus y prime of t. That's just that right there. Times dt. Times the unit vector j. And just to, I guess, complete the trifecta, the other way that we could write this is that dr is equal to-- if we just allowed these to cancel out, then we get is equal to dx times i plus dy times dy y times j. And that actually makes a lot of intuitive sense. That if I look at any dr, so let's say I look at the change between this vector and this vector. Let's say the super small change right there, that is our dr, and it's made up of-- it's our dx, our change in x is that right there. You can imagine it's that right there times-- but we're vectorizing it by multiplying it by the unit vector in the horizontal direction. Plus dy times the unit vector in the vertical direction. So when you multiply this distance times the unit vector, you're essentially getting this vector. And when you multiply this guy-- and actually our change in y here is negative-- you're going to get this vector right here. So when you add those together you'll get your change in your actual position vector. So that was all a little bit of background. And this might be somewhat useful-- a future video from now. Actually, I'm going to leave it there because really I just wanted to introduce this notation and get you familiar with it. In the next video, what I'm going to do is give you a little bit more intuition for what exactly does this thing mean? And how does it change depending on different parameterizations. And I'll do it with two different parameterizations for the same curve.\n",
            "Token IDs: tensor([  101,  1999,  1996,  2197,  3232,  1997,  6876,  2057,  2387,  2008,\n",
            "         2057,  2064,  6235,  1037, 10543,  2011,  1037,  2597,  9207,  1011,\n",
            "        11126,  3853,  1012,  1998,  1999,  2200,  2236,  3408,  1010,  2009,\n",
            "         2052,  2022,  1996,  1060,  2597,  2004,  1037,  3853,  1997,  2051,\n",
            "         2335,  1996,  3131,  9207,  1999,  1996,  9876,  3257,  1012,  4606,\n",
            "         1996,  1061,  2597,  2004,  1037,  3853,  1997,  2051,  2335,  1996,\n",
            "         3131,  5125,  1999,  1996,  7471,  3257,  1012,  1998,  2023,  2097,\n",
            "         7687,  6235,  2023,  1011,  1011,  2295,  1010,  2065,  2017,  2064,\n",
            "         5674,  1037, 10811,  1998,  2292,  1005,  1055,  2360,  1996, 16381,\n",
            "         1056,  5836,  2051,  1012,  2009,  1005,  2222,  6235,  2073,  1996,\n",
            "        10811,  2003,  2012,  2151,  2445,  2051,  1012,  1998,  2065,  2057,\n",
            "         2359,  1037,  3327,  7774,  2057,  2064,  2360,  1010,  2092,  1010,\n",
            "         2023,  2069, 12033,  2005,  2070,  7774,  1011,   102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVGvVZb13kha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc75134-3627-4311-c397-632b1efc34e5"
      },
      "source": [
        "input_ids_val = []\n",
        "attention_masks_val = []\n",
        "\n",
        "for sent in val_features:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids_val.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks_val.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
        "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', question_answer[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:   In the last couple of videos we saw that we can describe a curves by a position vector-valued function. And in very general terms, it would be the x position as a function of time times the unit vector in the horizontal direction. Plus the y position as a function of time times the unit victor in the vertical direction. And this will essentially describe this-- though, if you can imagine a particle and let's say the parameter t represents time. It'll describe where the particle is at any given time. And if we wanted a particular curve we can say, well, this only applies for some curve-- we're dealing, it's r of t. And it's only applicable between t being greater than a and less than b. And you know, that would describe some curve in two dimensions. Just me just draw it here. This is all a review of really, the last two videos. So this curve, it might look something like that where this is where t is equal to a. That's where t is equal to b. And so r of a will be this vector right here that ends at that point. And then as t or if you can imagine the parameter being time, it doesn't have to be time, but that's a convenient one to visualize. Each corresponding as t gets larger and larger, we're just going to different-- we're specifying different points on the path. We saw that two videos ago. And in the last video we thought about, well, what does it mean to take the derivative of a vector-valued function? And we came up with this idea that-- and it wasn't an idea, we actually showed it to be true. We came up with a definition really. That the derivative-- I could call it r prime of t-- and it's going to be a vector. The derivative of a vector-valued function is once again going to be a derivative. But it was equal to-- the way we defined it-- x prime of t times i plus y prime of t times j. Or another way to write that and I'll just write all the different ways just so you get familiar with-- dr/dt is equal to dx/dt. This is just a standard derivative. x of t is a scalar function. So this is a standard derivative times i plus dy/dt times j. And if we wanted to think about the differential, one thing that we can think about-- and whenever I do the math for the differential it's a little bit hand wavy. I'm not being very rigorous. But if you imagine multiplying both sides of the equation by a very small dt or this exact dt, you would get dr is equal to-- I'll just leave it like this. dx/dt times dt. I could make these cancel out, but I'll just write it like this first. Times the unit vector i plus dy/dt times dt. Times the unit vector j. Or we could rewrite this. And I'm just rewriting it in all of the different ways that one can rewrite it. You could also write this as dr is equal to x prime of t dt times the unit vector i. So this was x prime of t dt. This is x prime of t right there times the unit vector i. Plus y prime of t. That's just that right there. Times dt. Times the unit vector j. And just to, I guess, complete the trifecta, the other way that we could write this is that dr is equal to-- if we just allowed these to cancel out, then we get is equal to dx times i plus dy times dy y times j. And that actually makes a lot of intuitive sense. That if I look at any dr, so let's say I look at the change between this vector and this vector. Let's say the super small change right there, that is our dr, and it's made up of-- it's our dx, our change in x is that right there. You can imagine it's that right there times-- but we're vectorizing it by multiplying it by the unit vector in the horizontal direction. Plus dy times the unit vector in the vertical direction. So when you multiply this distance times the unit vector, you're essentially getting this vector. And when you multiply this guy-- and actually our change in y here is negative-- you're going to get this vector right here. So when you add those together you'll get your change in your actual position vector. So that was all a little bit of background. And this might be somewhat useful-- a future video from now. Actually, I'm going to leave it there because really I just wanted to introduce this notation and get you familiar with it. In the next video, what I'm going to do is give you a little bit more intuition for what exactly does this thing mean? And how does it change depending on different parameterizations. And I'll do it with two different parameterizations for the same curve.\n",
            "Token IDs: tensor([  101,  1999,  1996,  2197,  3232,  1997,  6876,  2057,  2387,  2008,\n",
            "         2057,  2064,  6235,  1037, 10543,  2011,  1037,  2597,  9207,  1011,\n",
            "        11126,  3853,  1012,  1998,  1999,  2200,  2236,  3408,  1010,  2009,\n",
            "         2052,  2022,  1996,  1060,  2597,  2004,  1037,  3853,  1997,  2051,\n",
            "         2335,  1996,  3131,  9207,  1999,  1996,  9876,  3257,  1012,  4606,\n",
            "         1996,  1061,  2597,  2004,  1037,  3853,  1997,  2051,  2335,  1996,\n",
            "         3131,  5125,  1999,  1996,  7471,  3257,  1012,  1998,  2023,  2097,\n",
            "         7687,  6235,  2023,  1011,  1011,  2295,  1010,  2065,  2017,  2064,\n",
            "         5674,  1037, 10811,  1998,  2292,  1005,  1055,  2360,  1996, 16381,\n",
            "         1056,  5836,  2051,  1012,  2009,  1005,  2222,  6235,  2073,  1996,\n",
            "        10811,  2003,  2012,  2151,  2445,  2051,  1012,  1998,  2065,  2057,\n",
            "         2359,  1037,  3327,  7774,  2057,  2064,  2360,  1010,  2092,  1010,\n",
            "         2023,  2069, 12033,  2005,  2070,  7774,  1011,   102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNDW74Ny3khj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dba085a-3d90-4810-c14a-1720ea9f13eb"
      },
      "source": [
        "num_classes = len(list(set(categories)))\n",
        "num_classes"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "569"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFzUkh0OAagZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227c56da-f09a-4e4b-f2f0-b28b98d6ffae"
      },
      "source": [
        "num_classes"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "569"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmaLk5Ab3khl"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# train_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n",
        "train_poincare_tensor = torch.tensor(poincare_embeddings_final_train,dtype=torch.float)\n",
        "val_poincare_tensor = torch.tensor(poincare_embeddings_final_val, dtype=torch.float)\n",
        "train_labels = torch.tensor(categories)\n",
        "val_labels = torch.tensor(val_labels.values)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids, attention_masks,train_poincare_tensor, train_labels)\n",
        "val_dataset = TensorDataset(input_ids_val,attention_masks_val,val_poincare_tensor,val_labels)\n",
        "# Create a 80-20train-validation split.\n",
        "\n",
        "# # Calculate the number of samples to include in each set.\n",
        "# train_size = int(0.90 * len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "\n",
        "# # Divide the dataset by randomly selecting samples.\n",
        "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# print('{:>5,} training samples'.format(train_size))\n",
        "# print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_lTinod3kho"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vduf9fOMviK"
      },
      "source": [
        "import numpy as np\n",
        "from torch.autograd import Function\n",
        "class Distance(Function):\n",
        "    @staticmethod\n",
        "    def grad(x, v, sqnormx, sqnormv, sqdist, eps):\n",
        "        alpha = (1 - sqnormx)\n",
        "        beta = (1 - sqnormv)\n",
        "        z = 1 + 2 * sqdist / (alpha * beta)\n",
        "        a = ((sqnormv - 2 * torch.sum(x * v, dim=-1) + 1) / torch.pow(alpha, 2))\\\n",
        "            .unsqueeze(-1).expand_as(x)\n",
        "        a = a * x - v / alpha.unsqueeze(-1).expand_as(v)\n",
        "        z = torch.sqrt(torch.pow(z, 2) - 1)\n",
        "        z = torch.clamp(z * beta, min=eps).unsqueeze(-1)\n",
        "        return 4 * a / z.expand_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, u, v, eps):\n",
        "        squnorm = torch.clamp(torch.sum(u * u, dim=-1), 0, 1 - eps)\n",
        "        sqvnorm = torch.clamp(torch.sum(v * v, dim=-1), 0, 1 - eps)\n",
        "        sqdist = torch.sum(torch.pow(u - v, 2), dim=-1)\n",
        "        ctx.eps = eps\n",
        "        ctx.save_for_backward(u, v, squnorm, sqvnorm, sqdist)\n",
        "        x = sqdist / ((1 - squnorm) * (1 - sqvnorm)) * 2 + 1\n",
        "        # arcosh\n",
        "        z = torch.sqrt(torch.pow(x, 2) - 1)\n",
        "        return torch.log(x + z)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, g):\n",
        "        u, v, squnorm, sqvnorm, sqdist = ctx.saved_tensors\n",
        "        g = g.unsqueeze(-1)\n",
        "        gu = Distance.grad(u, v, squnorm, sqvnorm, sqdist, ctx.eps)\n",
        "        gv = Distance.grad(v, u, sqvnorm, squnorm, sqdist, ctx.eps)\n",
        "        return g.expand_as(gu) * gu, g.expand_as(gv) * gv, None\n",
        "def distanceTo(vector1,vector2):\n",
        "        return Distance.apply(vector1,vector2,1e-5)\n",
        "        # vector1 = vector1.detach().cpu().numpy()\n",
        "        # vector2 = vector2.detach().cpu().numpy()\n",
        "        # euclidean_dists = np.linalg.norm(vector1 - vector2)  \n",
        "        # gamma = 1 + 2 * ((euclidean_dists ** 2) / ((1-(np.linalg.norm(vector1))) * (1-np.linalg.norm(vector2))))  # (1 + neg_size, batch_size)\n",
        "        # poincare_dists = np.arccosh(gamma) \n",
        "        # return torch.tensor(poincare_dists,dtype=torch.float)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN6jdKp0uhO3"
      },
      "source": [
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.nn.modules.loss import HingeEmbeddingLoss\n",
        "from random import randint\n",
        "import geoopt.manifolds.stereographic.math as pm\n",
        "import geoopt.optim.rsgd as rsgd_\n",
        "import geoopt.optim.radam as radam_\n",
        "# from hyrnn.nets import MobiusLinear\n",
        "from geoopt.tensor import ManifoldParameter\n",
        "from geoopt.manifolds.stereographic import PoincareBall\n",
        "from tqdm import tqdm\n",
        "import geoopt\n",
        "import time\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.nn.modules.loss import HingeEmbeddingLoss\n",
        "from random import randint\n",
        "import geoopt.optim.rsgd as rsgd_\n",
        "import geoopt.optim.radam as radam_\n",
        "# from hyrnn.nets import MobiusLinear\n",
        "from geoopt.tensor import ManifoldParameter\n",
        "import time\n",
        "import argparse\n",
        "cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "\n",
        "def create_ball(ball=None, c=None):\n",
        "    \"\"\"\n",
        "    Helper to create a PoincareBall.\n",
        "    Sometimes you may want to share a manifold across layers, e.g. you are using scaled PoincareBall.\n",
        "    In this case you will require same curvature parameters for different layers or end up with nans.\n",
        "    Parameters\n",
        "    ----------\n",
        "    ball : geoopt.PoincareBall\n",
        "    c : float\n",
        "    Returns\n",
        "    -------\n",
        "    geoopt.PoincareBall\n",
        "    \"\"\"\n",
        "    if ball is None:\n",
        "        assert c is not None, \"curvature of the ball should be explicitly specified\"\n",
        "        ball = geoopt.PoincareBall(c)\n",
        "    # else trust input\n",
        "    return ball\n",
        "\n",
        "\n",
        "class MobiusLinear(torch.nn.Linear):\n",
        "    def __init__(self, *args, nonlin=None, ball=None, c=1.0, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        # for manifolds that have parameters like Poincare Ball\n",
        "        # we have to attach them to the closure Module.\n",
        "        # It is hard to implement device allocation for manifolds in other case.\n",
        "        self.ball = create_ball(ball, c)\n",
        "        if self.bias is not None:\n",
        "            self.bias = geoopt.ManifoldParameter(self.bias, manifold=self.ball)\n",
        "        self.nonlin = nonlin\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return mobius_linear(\n",
        "            input,\n",
        "            weight=self.weight,\n",
        "            bias=self.bias,\n",
        "            nonlin=self.nonlin,\n",
        "            ball=self.ball,\n",
        "        )\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.eye_(self.weight)\n",
        "        self.weight.add_(torch.rand_like(self.weight).mul_(1e-3))\n",
        "        if self.bias is not None:\n",
        "            self.bias.zero_()\n",
        "\n",
        "\n",
        "# package.nn.functional.py\n",
        "def mobius_linear(input, weight, bias=None, nonlin=None, *, ball: geoopt.PoincareBall):\n",
        "    output = ball.mobius_matvec(weight, input)\n",
        "    if bias is not None:\n",
        "        output = ball.mobius_add(output, bias)\n",
        "    if nonlin is not None:\n",
        "        output = ball.logmap0(output)\n",
        "        output = nonlin(output)\n",
        "        output = ball.expmap0(output)\n",
        "    return output\n",
        "# Neural Classifierwork\n",
        "class MulticlassClassifier(nn.Module):\n",
        "    def __init__(self,bert_model_path):\n",
        "        super(MulticlassClassifier,self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=False)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc1 = MobiusLinear(768, 384)\n",
        "        self.fc2 = MobiusLinear(384, 60)\n",
        "\n",
        "    def forward(self,tokens,masks):\n",
        "        _, pooled_output,hidden = self.bert(tokens, attention_mask=masks)\n",
        "        hyerbolic_transform = tensor_exponential_map(hidden[12])\n",
        "        x = self.fc1(hyerbolic_transform)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class MyHingeLoss(torch.nn.Module):\n",
        "    def __init__(self, margin):\n",
        "        super(MyHingeLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        loss = 0\n",
        "        for i in range(len(output)):\n",
        "            text_emb = output[i]\n",
        "            t_label = target[i]\n",
        "            j = randint(0, len(output)-1)\n",
        "            while j == i:\n",
        "                j = randint(0, len(output)-1)\n",
        "            t_j = target[j]\n",
        "            loss += torch.relu( self.margin + \\\n",
        "                            distanceTo(t_label, text_emb) - distanceTo(t_j, text_emb) )\n",
        "        return loss / len(output)\n",
        "\n",
        "class MyHingeLoss_cos(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, margin):\n",
        "        super(MyHingeLoss_cos, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        loss = 0\n",
        "        for i in range(len(output)):\n",
        "            text_emb = output[i]\n",
        "            t_label = target[i]\n",
        "            j = randint(0, len(output)-1)\n",
        "            while j == i:\n",
        "                j = randint(0, len(output)-1)\n",
        "            t_j = target[j]\n",
        "            loss += torch.relu( self.margin - cos(t_label, text_emb) + cos(t_j, text_emb) )\n",
        "        return loss / len(output)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H5aJb4-gIYb"
      },
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFAjMBMqF-QB"
      },
      "source": [
        "def dist_without_grad( u, v):\n",
        "  sqdist = torch.sum((u - v) ** 2, dim=-1)\n",
        "  squnorm = torch.sum(u ** 2, dim=-1)\n",
        "  sqvnorm = torch.sum(v ** 2, dim=-1)\n",
        "  x = 1 + 2 * sqdist / ((1 - squnorm) * (1 - sqvnorm)) + 1e-7\n",
        "  z = torch.sqrt(x ** 2 - 1)\n",
        "  return torch.log(x + z)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKxvydZIXrBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e8c199-184f-4857-9d4f-1720ef8c5253"
      },
      "source": [
        "class FinalClassifier(nn.Module):\n",
        "    def __init__(self,bert_model_path):\n",
        "        super(FinalClassifier,self).__init__()\n",
        "        self.model2 = MulticlassClassifier(bert_model_path)\n",
        "        # self.model2.load_state_dict(torch.load('model_hyperbolic_round_2/model_weights'))\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.i =0\n",
        "        for param in self.model2.parameters():\n",
        "            param.requires_grad = True\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(896 , 400),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),            \n",
        "            nn.Linear(400, 572))\n",
        "\n",
        "    def forward(self,tokens,masks,poincare_tensor):\n",
        "        output = self.model2.bert(tokens,masks)\n",
        "        hierarch_output = self.model2(tokens,masks)\n",
        "        similarity_vector = 1/(1+dist_without_grad(hierarch_output,poincare_tensor.unsqueeze(axis=1)))\n",
        "        # if self.i ==0:\n",
        "        #   print(\"similarity_vector\",similarity_vector.shape)\n",
        "\n",
        "        concat_output = torch.cat((output[1],similarity_vector),dim=1)\n",
        "        # output_1 = tensor_log_map(output)\n",
        "        # word_emb = output[2][-1]\n",
        "        # word_embeddings = \n",
        "        concat_out = self.dropout(concat_output)\n",
        "        x = self.mlp(concat_out)\n",
        "        return x\n",
        "model = FinalClassifier('bert-base-uncased')\n",
        "model.cuda()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FinalClassifier(\n",
              "  (model2): MulticlassClassifier(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (fc1): MobiusLinear(\n",
              "      in_features=768, out_features=384, bias=True\n",
              "      (ball): PoincareBall manifold\n",
              "    )\n",
              "    (fc2): MobiusLinear(\n",
              "      in_features=384, out_features=60, bias=True\n",
              "      (ball): PoincareBall manifold\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=896, out_features=400, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=400, out_features=572, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMfZRITZJCwa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0be2f20-b632-4fb9-c392-886b7f572eb7"
      },
      "source": [
        "torch.cat((model.model2.bert(input_ids[0:3].to(device),attention_masks[0:3].to(device))[1],1/(1+ dist_without_grad(model.model2(input_ids[0:3].to(device),attention_masks[0:3].to(device)),torch.tensor(poincare_embeddings_final_train[:3]).unsqueeze(axis=1).to(device)))), dim=1)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2034, -0.2628, -0.9288,  ...,  0.1841,  0.1956,  0.2161],\n",
              "        [-0.8679, -0.5666, -0.9891,  ...,  0.1885,  0.1804,  0.1782],\n",
              "        [-0.5717, -0.5244, -0.9764,  ...,  0.1830,  0.1922,  0.1883]],\n",
              "       device='cuda:0', dtype=torch.float64, grad_fn=<CatBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwdCulruVaaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc8e032b-09bc-4774-9645-77aa913a5030"
      },
      "source": [
        "dist_without_grad(model.model2(input_ids[0:3].to(device),attention_masks[0:3].to(device)),torch.tensor(poincare_embeddings_final_train[:3]).unsqueeze(axis=1).to(device)).shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouh9g_5kXx6F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32b9963-8cf1-4c7f-f18e-de26de78cfa3"
      },
      "source": [
        "model.model2(input_ids[0:3].to(device),attention_masks[0:3].to(device)).shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 128, 60])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2tmAMlw3khr"
      },
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n",
        "\n",
        "# # Loads BertModel, the pretrained BERT model with a single \n",
        "# model = MulticlassClassifier('bert-base-uncased')\n",
        "\n",
        "# # Tell pytorch to run this model on the GPU.\n",
        "# model.cuda()\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4paz_8iTZ9o"
      },
      "source": [
        "mobius_params = []\n",
        "bert_params = []\n",
        "\n",
        "def mobius_params():\n",
        "  for param in model.named_parameters():\n",
        "    if 'fc' in param[0]:\n",
        "      yield param[1]\n",
        "def bert_params():\n",
        "  for param in model.named_parameters():\n",
        "    if 'bert' in param[0]:\n",
        "      yield param[1]\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awQ2Y9Jb3kht"
      },
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "# optimizer_2 = radam_.RiemannianAdam(mobius_params(), lr=0.01, stabilize=10)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ys-M4-e3khv"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "epochs = 30\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrYqErOD3khx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b07510dc-6862-4716-f9c2-fc7d7da2ef78"
      },
      "source": [
        "len(train_dataloader) "
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWVSE9LM3kh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e764ac20-14e1-4d22-f943-2578ac92e92f"
      },
      "source": [
        "1935 * 32"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61920"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcvxVVi63kh3"
      },
      "source": [
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUw3zm6g3kh5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta6zfUTa3kh7"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFq9gd5kQSHb"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsInxVoqbsFW"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di68jXK5WaYr"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LhAy2hZ3kh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d0dae0-b514-4060-ebbd-e176c77c7866"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.metrics import f1_score\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "early_stopping = EarlyStopping(patience=4, verbose=True)\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "    total_train_accuracy=0\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_poincare = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        "\n",
        "\n",
        "        model.zero_grad() \n",
        "        optimizer.zero_grad()       \n",
        "        logits = model(b_input_ids, \n",
        "                             b_input_mask,b_poincare)\n",
        "        # if epoch_i==0:\n",
        "        #   print(logits)\n",
        "        \n",
        "        loss = criterion(logits,b_labels)\n",
        "\n",
        "  \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        total_train_accuracy += flat_accuracy(logits, label_ids)\n",
        "    avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n",
        "    print(\" Train Accuracy: {0:.2f}\".format(avg_train_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_f1 = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_poincare = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "\n",
        "          logits = model(b_input_ids, \n",
        "                              b_input_mask,b_poincare)\n",
        "          \n",
        "        loss = criterion(logits,b_labels)\n",
        "\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_f1 += flat_accuracy(logits,label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_f1 / len(validation_dataloader)\n",
        "    print(\"  validation accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    early_stopping(avg_val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break  \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    output_dir = 'model_hyperIM_khan_acad/'\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    print(\"Saving model to %s\" % output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n",
        "\n",
        "    !rm -rf \"/content/drive/My Drive/Information_retrieval_project/model_hyperIM_khan_acad\"\n",
        "    !mv model_hyperIM_khan_acad \"/content/drive/My Drive/Information_retrieval_project/\"\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 30 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    40  of    131.    Elapsed: 0:01:56.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:49.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:42.\n",
            " Train Accuracy: 0.02\n",
            "\n",
            "  Average training loss: 6.28\n",
            "  Training epcoh took: 0:06:14\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.02\n",
            "Validation loss decreased (inf --> 6.193237).  Saving model ...\n",
            "  Validation Loss: 6.19\n",
            "  Validation took: 0:00:31\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 2 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.03\n",
            "\n",
            "  Average training loss: 6.06\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.02\n",
            "Validation loss decreased (6.193237 --> 5.960955).  Saving model ...\n",
            "  Validation Loss: 5.96\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 3 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:53.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:46.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:39.\n",
            " Train Accuracy: 0.05\n",
            "\n",
            "  Average training loss: 5.78\n",
            "  Training epcoh took: 0:06:10\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.05\n",
            "Validation loss decreased (5.960955 --> 5.723654).  Saving model ...\n",
            "  Validation Loss: 5.72\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 4 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:48.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:41.\n",
            " Train Accuracy: 0.07\n",
            "\n",
            "  Average training loss: 5.51\n",
            "  Training epcoh took: 0:06:12\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.06\n",
            "Validation loss decreased (5.723654 --> 5.526569).  Saving model ...\n",
            "  Validation Loss: 5.53\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 5 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.09\n",
            "\n",
            "  Average training loss: 5.27\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.09\n",
            "Validation loss decreased (5.526569 --> 5.352100).  Saving model ...\n",
            "  Validation Loss: 5.35\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 6 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.11\n",
            "\n",
            "  Average training loss: 5.05\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.11\n",
            "Validation loss decreased (5.352100 --> 5.193408).  Saving model ...\n",
            "  Validation Loss: 5.19\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 7 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:41.\n",
            " Train Accuracy: 0.14\n",
            "\n",
            "  Average training loss: 4.84\n",
            "  Training epcoh took: 0:06:12\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.11\n",
            "Validation loss decreased (5.193408 --> 5.074805).  Saving model ...\n",
            "  Validation Loss: 5.07\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 8 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:48.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:41.\n",
            " Train Accuracy: 0.14\n",
            "\n",
            "  Average training loss: 4.66\n",
            "  Training epcoh took: 0:06:12\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.14\n",
            "Validation loss decreased (5.074805 --> 4.974657).  Saving model ...\n",
            "  Validation Loss: 4.97\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 9 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:48.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:42.\n",
            " Train Accuracy: 0.16\n",
            "\n",
            "  Average training loss: 4.49\n",
            "  Training epcoh took: 0:06:13\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.14\n",
            "Validation loss decreased (4.974657 --> 4.873824).  Saving model ...\n",
            "  Validation Loss: 4.87\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 10 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:48.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:41.\n",
            " Train Accuracy: 0.18\n",
            "\n",
            "  Average training loss: 4.33\n",
            "  Training epcoh took: 0:06:12\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.14\n",
            "Validation loss decreased (4.873824 --> 4.816396).  Saving model ...\n",
            "  Validation Loss: 4.82\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 11 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:41.\n",
            " Train Accuracy: 0.20\n",
            "\n",
            "  Average training loss: 4.19\n",
            "  Training epcoh took: 0:06:12\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.16\n",
            "Validation loss decreased (4.816396 --> 4.727751).  Saving model ...\n",
            "  Validation Loss: 4.73\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 12 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.21\n",
            "\n",
            "  Average training loss: 4.06\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.17\n",
            "Validation loss decreased (4.727751 --> 4.678831).  Saving model ...\n",
            "  Validation Loss: 4.68\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 13 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:53.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.22\n",
            "\n",
            "  Average training loss: 3.95\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.19\n",
            "Validation loss decreased (4.678831 --> 4.602328).  Saving model ...\n",
            "  Validation Loss: 4.60\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 14 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.23\n",
            "\n",
            "  Average training loss: 3.84\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.19\n",
            "Validation loss decreased (4.602328 --> 4.561334).  Saving model ...\n",
            "  Validation Loss: 4.56\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 15 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:53.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.25\n",
            "\n",
            "  Average training loss: 3.73\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.19\n",
            "Validation loss decreased (4.561334 --> 4.518666).  Saving model ...\n",
            "  Validation Loss: 4.52\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 16 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.26\n",
            "\n",
            "  Average training loss: 3.64\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.20\n",
            "Validation loss decreased (4.518666 --> 4.498028).  Saving model ...\n",
            "  Validation Loss: 4.50\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 17 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.28\n",
            "\n",
            "  Average training loss: 3.55\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.20\n",
            "Validation loss decreased (4.498028 --> 4.448018).  Saving model ...\n",
            "  Validation Loss: 4.45\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 18 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:53.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.29\n",
            "\n",
            "  Average training loss: 3.47\n",
            "  Training epcoh took: 0:06:10\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.20\n",
            "Validation loss decreased (4.448018 --> 4.426415).  Saving model ...\n",
            "  Validation Loss: 4.43\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 19 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.31\n",
            "\n",
            "  Average training loss: 3.39\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.21\n",
            "Validation loss decreased (4.426415 --> 4.389127).  Saving model ...\n",
            "  Validation Loss: 4.39\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 20 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:53.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.21\n",
            "Validation loss decreased (4.389127 --> 4.366515).  Saving model ...\n",
            "  Validation Loss: 4.37\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 21 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:53.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.34\n",
            "\n",
            "  Average training loss: 3.25\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.22\n",
            "Validation loss decreased (4.366515 --> 4.351936).  Saving model ...\n",
            "  Validation Loss: 4.35\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 22 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:53.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:46.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.35\n",
            "\n",
            "  Average training loss: 3.20\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.23\n",
            "Validation loss decreased (4.351936 --> 4.337277).  Saving model ...\n",
            "  Validation Loss: 4.34\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 23 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.36\n",
            "\n",
            "  Average training loss: 3.14\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.23\n",
            "Validation loss decreased (4.337277 --> 4.306361).  Saving model ...\n",
            "  Validation Loss: 4.31\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 24 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.38\n",
            "\n",
            "  Average training loss: 3.10\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.23\n",
            "Validation loss decreased (4.306361 --> 4.303951).  Saving model ...\n",
            "  Validation Loss: 4.30\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 25 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:53.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.39\n",
            "\n",
            "  Average training loss: 3.06\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.24\n",
            "Validation loss decreased (4.303951 --> 4.274636).  Saving model ...\n",
            "  Validation Loss: 4.27\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 26 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:53.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.40\n",
            "\n",
            "  Average training loss: 3.02\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.23\n",
            "Validation loss decreased (4.274636 --> 4.267286).  Saving model ...\n",
            "  Validation Loss: 4.27\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 27 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.40\n",
            "\n",
            "  Average training loss: 2.99\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.23\n",
            "EarlyStopping counter: 1 out of 4\n",
            "  Validation Loss: 4.27\n",
            "  Validation took: 0:00:28\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 28 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:53.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.41\n",
            "\n",
            "  Average training loss: 2.97\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.23\n",
            "Validation loss decreased (4.267286 --> 4.257873).  Saving model ...\n",
            "  Validation Loss: 4.26\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 29 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.42\n",
            "\n",
            "  Average training loss: 2.95\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.23\n",
            "Validation loss decreased (4.257873 --> 4.257099).  Saving model ...\n",
            "  Validation Loss: 4.26\n",
            "  Validation took: 0:00:30\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "======== Epoch 30 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    131.    Elapsed: 0:01:54.\n",
            "  Batch    80  of    131.    Elapsed: 0:03:47.\n",
            "  Batch   120  of    131.    Elapsed: 0:05:40.\n",
            " Train Accuracy: 0.42\n",
            "\n",
            "  Average training loss: 2.95\n",
            "  Training epcoh took: 0:06:11\n",
            "\n",
            "Running Validation...\n",
            "  validation accuracy: 0.24\n",
            "EarlyStopping counter: 1 out of 4\n",
            "  Validation Loss: 4.26\n",
            "  Validation took: 0:00:28\n",
            "Saving model to model_hyperIM_khan_acad/\n",
            "\n",
            "Training complete!\n",
            "Total training took 3:22:32 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RACcsko3kh_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "outputId": "771b826e-3943-4061-a372-892dd04f4229"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.28</td>\n",
              "      <td>6.19</td>\n",
              "      <td>0:06:14</td>\n",
              "      <td>0:00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.06</td>\n",
              "      <td>5.96</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.78</td>\n",
              "      <td>5.72</td>\n",
              "      <td>0:06:10</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.51</td>\n",
              "      <td>5.53</td>\n",
              "      <td>0:06:12</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.27</td>\n",
              "      <td>5.35</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5.05</td>\n",
              "      <td>5.19</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.84</td>\n",
              "      <td>5.07</td>\n",
              "      <td>0:06:12</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.66</td>\n",
              "      <td>4.97</td>\n",
              "      <td>0:06:12</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.49</td>\n",
              "      <td>4.87</td>\n",
              "      <td>0:06:13</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4.33</td>\n",
              "      <td>4.82</td>\n",
              "      <td>0:06:12</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.19</td>\n",
              "      <td>4.73</td>\n",
              "      <td>0:06:12</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.06</td>\n",
              "      <td>4.68</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.95</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3.84</td>\n",
              "      <td>4.56</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3.73</td>\n",
              "      <td>4.52</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.64</td>\n",
              "      <td>4.50</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3.55</td>\n",
              "      <td>4.45</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3.47</td>\n",
              "      <td>4.43</td>\n",
              "      <td>0:06:10</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3.39</td>\n",
              "      <td>4.39</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3.32</td>\n",
              "      <td>4.37</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3.25</td>\n",
              "      <td>4.35</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3.20</td>\n",
              "      <td>4.34</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>3.14</td>\n",
              "      <td>4.31</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>3.10</td>\n",
              "      <td>4.30</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3.06</td>\n",
              "      <td>4.27</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3.02</td>\n",
              "      <td>4.27</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2.99</td>\n",
              "      <td>4.27</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2.97</td>\n",
              "      <td>4.26</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2.95</td>\n",
              "      <td>4.26</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2.95</td>\n",
              "      <td>4.26</td>\n",
              "      <td>0:06:11</td>\n",
              "      <td>0:00:28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1               6.28         6.19       0:06:14         0:00:31\n",
              "2               6.06         5.96       0:06:11         0:00:30\n",
              "3               5.78         5.72       0:06:10         0:00:30\n",
              "4               5.51         5.53       0:06:12         0:00:30\n",
              "5               5.27         5.35       0:06:11         0:00:30\n",
              "6               5.05         5.19       0:06:11         0:00:30\n",
              "7               4.84         5.07       0:06:12         0:00:30\n",
              "8               4.66         4.97       0:06:12         0:00:30\n",
              "9               4.49         4.87       0:06:13         0:00:30\n",
              "10              4.33         4.82       0:06:12         0:00:30\n",
              "11              4.19         4.73       0:06:12         0:00:30\n",
              "12              4.06         4.68       0:06:11         0:00:30\n",
              "13              3.95         4.60       0:06:11         0:00:30\n",
              "14              3.84         4.56       0:06:11         0:00:30\n",
              "15              3.73         4.52       0:06:11         0:00:30\n",
              "16              3.64         4.50       0:06:11         0:00:30\n",
              "17              3.55         4.45       0:06:11         0:00:30\n",
              "18              3.47         4.43       0:06:10         0:00:30\n",
              "19              3.39         4.39       0:06:11         0:00:30\n",
              "20              3.32         4.37       0:06:11         0:00:30\n",
              "21              3.25         4.35       0:06:11         0:00:30\n",
              "22              3.20         4.34       0:06:11         0:00:30\n",
              "23              3.14         4.31       0:06:11         0:00:30\n",
              "24              3.10         4.30       0:06:11         0:00:30\n",
              "25              3.06         4.27       0:06:11         0:00:30\n",
              "26              3.02         4.27       0:06:11         0:00:30\n",
              "27              2.99         4.27       0:06:11         0:00:28\n",
              "28              2.97         4.26       0:06:11         0:00:30\n",
              "29              2.95         4.26       0:06:11         0:00:30\n",
              "30              2.95         4.26       0:06:11         0:00:28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5TicdiP3kiC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "8b4d864d-1434-4f54-d7b8-c58b53b884a2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbiTDpVv3kiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6070af-22de-44cb-f476-1323aec946b9"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "output_dir = 'model_hyperIM_khan_acad/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "\n",
        "# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "# model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to model_hyperIM_khan_acad/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model_hyperIM_khan_acad/vocab.txt',\n",
              " 'model_hyperIM_khan_acad/special_tokens_map.json',\n",
              " 'model_hyperIM_khan_acad/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U2UQ29a3kiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab1da11-282d-4db4-f96a-289d236d7c83"
      },
      "source": [
        "!pip install joblib\n",
        "import joblib\n",
        "joblib.dump(LE, \"label_encoder\")\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F5PxZm9vAOI"
      },
      "source": [
        "import json\n",
        "torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlb0IpVJO1XQ"
      },
      "source": [
        "# with open(os.path.join(output_dir, 'model_config.json'), 'w') as f:\n",
        "#     json.dump(model.config, f)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpGY8vSDI6u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4eded11-ce20-44cb-e7ce-ac810fa66ada"
      },
      "source": [
        "!zip -r model_hyperIM_khan_acad.zip model_hyperIM_khan_acad\n",
        "# files.download('model_hyperIM_QC.zip')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model_hyperIM_khan_acad/ (stored 0%)\n",
            "  adding: model_hyperIM_khan_acad/special_tokens_map.json (deflated 40%)\n",
            "  adding: model_hyperIM_khan_acad/vocab.txt (deflated 53%)\n",
            "  adding: model_hyperIM_khan_acad/tokenizer_config.json (stored 0%)\n",
            "  adding: model_hyperIM_khan_acad/model_weights  adding: model_hyperIM_khan_acad/ (stored 0%)\n",
            "  adding: model_hyperIM_khan_acad/special_tokens_map.json (deflated 40%)\n",
            "  adding: model_hyperIM_khan_acad/vocab.txt (deflated 53%)\n",
            "  adding: model_hyperIM_khan_acad/tokenizer_config.json (stored 0%)\n",
            "  adding: model_hyperIM_khan_acad/model_weights  adding: model_hyperIM_khan_acad/ (stored 0%)\n",
            "  adding: model_hyperIM_khan_acad/special_tokens_map.json (deflated 40%)\n",
            "  adding: model_hyperIM_khan_acad/vocab.txt (deflated 53%)\n",
            "  adding: model_hyperIM_khan_acad/tokenizer_config.json (stored 0%)\n",
            "  adding: model_hyperIM_khan_acad/model_weights  adding: model_hyperIM_khan_acad/ (stored 0%)\n",
            "  adding: model_hyperIM_khan_acad/special_tokens_map.json (deflated 40%)\n",
            "  adding: model_hyperIM_khan_acad/vocab.txt (deflated 53%)\n",
            "  adding: model_hyperIM_khan_acad/tokenizer_config.json (stored 0%)\n",
            "  adding: model_hyperIM_khan_acad/model_weights  adding: model_hyperIM_khan_acad/ (stored 0%)\n",
            "  adding: model_hyperIM_khan_acad/special_tokens_map.json (deflated 40%)\n",
            "  adding: model_hyperIM_khan_acad/vocab.txt (deflated 53%)\n",
            "  adding: model_hyperIM_khan_acad/tokenizer_config.json (stored 0%)\n",
            "  adding: model_hyperIM_khan_acad/model_weights (deflated 7%)\n",
            " (deflated 7%)\n",
            " (deflated 7%)\n",
            " (deflated 7%)\n",
            " (deflated 7%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvFDCDIxKDOf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5ad78df7-2445-41a9-f185-0e509831aac9"
      },
      "source": [
        "!zip -r label_encoder_hyperIM_khan_acad.zip label_encoder\n",
        "files.download('label_encoder_hyperIM_khan_acad.zip')\n",
        "!mv label_encoder_hyperIM_QC.zip \"/content/drive/My Drive/Information_retrieval_project/\"\n",
        "!mv model_hyperIM_QC.zip \"/content/drive/My Drive/Information_retrieval_project/\""
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: label_encoder (deflated 76%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_fddd91c3-28af-4293-8bb5-4a2221481de9\", \"label_encoder_hyperIM_khan_acad.zip\", 8668)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'model_hyperIM_QC.zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3RL23botmep"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}