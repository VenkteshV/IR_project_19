{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression_khan_acad_science.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pymFcnqBeeCp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim.models\n",
        "import seaborn as sb\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQB-HauvpojF",
        "outputId": "520f0f1e-bb59-4f01-c20d-94132565c230"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWKUb_gitsDP",
        "outputId": "d58030f8-0fa1-4412-d749-336a4b0700c8"
      },
      "source": [
        "!pip install tensorflow==1.13.1\n",
        "! pip install tensorflow-hub==0.7.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/29/6b4f1e02417c3a1ccc85380f093556ffd0b35dc354078074c5195c8447f2/tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6MB)\n",
            "\u001b[K     |████████████████████████████████| 92.6MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.12.4)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.32.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (54.1.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.1)\n",
            "Installing collected packages: tensorboard, mock, tensorflow-estimator, keras-applications, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n",
            "Collecting tensorflow-hub==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/0e/a91780d07592b1abf9c91344ce459472cc19db3b67fdf3a61dca6ebb2f5c/tensorflow_hub-0.7.0-py2.py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub==0.7.0) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub==0.7.0) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub==0.7.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.7.0) (54.1.2)\n",
            "Installing collected packages: tensorflow-hub\n",
            "  Found existing installation: tensorflow-hub 0.11.0\n",
            "    Uninstalling tensorflow-hub-0.11.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.11.0\n",
            "Successfully installed tensorflow-hub-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePmrRXJh12Zp",
        "outputId": "3418ba65-a9ce-4787-898d-67b6d71c4ad8"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "class UseSentenceEmbedding():\n",
        "    def __init__(self):\n",
        "        # g = tf.Graph()\n",
        "        with tf.device('/GPU:0'):\n",
        "        # We will be feeding 1D tensors of text into the graph.\n",
        "            self.text_input = tf.placeholder(dtype=tf.string, shape=[None])\n",
        "            \n",
        "            #kindly replace the location in hub.module with the url commented out below\n",
        "\n",
        "            # \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
        "            embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder-large/3\")\n",
        "            self.embedded_text = embed(self.text_input)\n",
        "            init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "        # g.finalize()\n",
        "\n",
        "        self.session = tf.Session(config=tf.ConfigProto( allow_soft_placement=True))\n",
        "        self.session.run(init_op)\n",
        "        print(\"init _____\")\n",
        "\n",
        "\n",
        "\n",
        "    def get_tokenized_sents_embeddings_USE(self, sents,expand=False):\n",
        "\n",
        "           \n",
        "        vectors_USE =  self.session.run(self.embedded_text, feed_dict={self.text_input: sents})\n",
        "\n",
        "        return vectors_USE\n",
        "\n",
        "use_embedding = UseSentenceEmbedding()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "init _____\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ_QTK0WfFKB"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/Information_retrieval_project/khan_acad/train_khan_acad.csv\" /content\n",
        "!cp \"/content/drive/MyDrive/Information_retrieval_project/khan_acad/test_khan_acad.csv\" /content\n",
        "!cp \"/content/drive/MyDrive/Information_retrieval_project/khan_acad/val_khan_acad.csv\" /content\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPjCWVNvnLCw"
      },
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"train_khan_acad.csv\")\n",
        "test_data = pd.read_csv(\"test_khan_acad.csv\")\n",
        "val_data = pd.read_csv(\"val_khan_acad.csv\")\n",
        "train_data\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1orLd3JonLIM"
      },
      "source": [
        "import re\n",
        "def clean_sentence(question):\n",
        "  # print(question)\n",
        "  question = re.sub('<[^>]*>', ' ',question)\n",
        "  question = re.sub(' +', ' ', question)\n",
        "  question = re.sub('\\xa0','',question)\n",
        "  question = question.rstrip()\n",
        "  question = re.sub('nan','',question)\n",
        "  question = re.sub(u'\\u2004','',question)\n",
        "  question = re.sub(u'\\u2009','',question)\n",
        "\n",
        "  # question = question.decode(\"utf-8\")\n",
        "  # question = question.replace(u'\\u200\\d*','').encode(\"utf-8\")\n",
        "  question = re.sub('&nbsp','',question)\n",
        "  question = re.sub('&ndash','',question)\n",
        "  question = re.sub('\\r','',question)\n",
        "  question = re.sub('\\t','',question)\n",
        "  question = re.sub('\\n',' ',question)\n",
        "\n",
        "  question = re.sub('MathType@.*','',question)\n",
        "  question = re.sub('&thinsp','',question)\n",
        "  question = re.sub('&times','',question)\n",
        "  question = re.sub('\\u200b','',question)\n",
        "  question = re.sub('&rarr;;;','',question)\n",
        "\n",
        "  return question"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "sodNGJXpnTU5",
        "outputId": "d5603e57-dee9-4c73-bc33-25091b0561eb"
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "LE = LabelEncoder()\n",
        "LE.fit_transform(pd.concat([train_data['hierarchy'],test_data['hierarchy']]))\n",
        "train_data['label'] = LE.transform(train_data['hierarchy'])\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_transcripts</th>\n",
              "      <th>hierarchy</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the last couple of videos we saw that we c...</td>\n",
              "      <td>math&gt;&gt;multivariable-calculus&gt;&gt;multivariable-de...</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-  What we're going to do in this video is gi...</td>\n",
              "      <td>science&gt;&gt;ap-biology&gt;&gt;natural-selection</td>\n",
              "      <td>422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>So once again, we have three equal, or we say...</td>\n",
              "      <td>math&gt;&gt;pre-algebra&gt;&gt;pre-algebra-equations-expre...</td>\n",
              "      <td>384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-  Liz's math test included a survey question...</td>\n",
              "      <td>math&gt;&gt;engageny-alg-1&gt;&gt;alg1-2</td>\n",
              "      <td>231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>- The following two equations form a linear s...</td>\n",
              "      <td>math&gt;&gt;algebra-home&gt;&gt;alg-system-of-equations</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   video_transcripts  ... label\n",
              "0   In the last couple of videos we saw that we c...  ...   354\n",
              "1   -  What we're going to do in this video is gi...  ...   422\n",
              "2   So once again, we have three equal, or we say...  ...   384\n",
              "3   -  Liz's math test included a survey question...  ...   231\n",
              "4   - The following two equations form a linear s...  ...    99\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjbIQ-0QnYM1"
      },
      "source": [
        "def get_labels(prediction):\n",
        "    predicted_label =  LE.inverse_transform([prediction])\n",
        "    return predicted_label[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "N0GNowxhndIV",
        "outputId": "b8f33260-befd-4917-8e76-1174b8d8f2b6"
      },
      "source": [
        "# LE_test = LabelEncoder()\n",
        "\n",
        "test_data['label'] = LE.transform(test_data['hierarchy'])\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_transcripts</th>\n",
              "      <th>hierarchy</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-  What I hope to do in this video is get fam...</td>\n",
              "      <td>math&gt;&gt;math1&gt;&gt;x89d82521517266d4:functions</td>\n",
              "      <td>335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the last video we were able to set up this...</td>\n",
              "      <td>math&gt;&gt;old-ap-calculus-ab&gt;&gt;ab-applications-defi...</td>\n",
              "      <td>357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-  In previous videos we talk about GDP as th...</td>\n",
              "      <td>economics-finance-domain&gt;&gt;ap-macroeconomics&gt;&gt;e...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-  So what we're gonna do in this video is se...</td>\n",
              "      <td>math&gt;&gt;old-integral-calculus&gt;&gt;definite-integral...</td>\n",
              "      <td>378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-  So I've said that if you have a vector fie...</td>\n",
              "      <td>math&gt;&gt;multivariable-calculus&gt;&gt;multivariable-de...</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   video_transcripts  ... label\n",
              "0   -  What I hope to do in this video is get fam...  ...   335\n",
              "1   In the last video we were able to set up this...  ...   357\n",
              "2   -  In previous videos we talk about GDP as th...  ...     3\n",
              "3   -  So what we're gonna do in this video is se...  ...   378\n",
              "4   -  So I've said that if you have a vector fie...  ...   354\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "wQSjXdjEndMu",
        "outputId": "934161d0-c901-458e-b371-bc52bcd71953"
      },
      "source": [
        "val_data['label'] = LE.transform(val_data['hierarchy'])\n",
        "val_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_transcripts</th>\n",
              "      <th>hierarchy</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Find the probability of rolling doubles on tw...</td>\n",
              "      <td>math&gt;&gt;precalculus&gt;&gt;x9e81a4f98389efdf:prob-comb</td>\n",
              "      <td>395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>After the food is swallowed, it leaves the m...</td>\n",
              "      <td>science&gt;&gt;health-and-medicine&gt;&gt;human-anatomy-an...</td>\n",
              "      <td>497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Let's now talk about what is easily one of th...</td>\n",
              "      <td>math&gt;&gt;geometry&gt;&gt;hs-geo-trig</td>\n",
              "      <td>256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The goal in this video is to essentially prov...</td>\n",
              "      <td>science&gt;&gt;chemistry&gt;&gt;thermodynamics-chemistry</td>\n",
              "      <td>472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A line goes through the points (-1, 6) and (5...</td>\n",
              "      <td>math&gt;&gt;in-in-grade-11-ncert&gt;&gt;in-in-class11-stra...</td>\n",
              "      <td>304</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   video_transcripts  ... label\n",
              "0   Find the probability of rolling doubles on tw...  ...   395\n",
              "1    After the food is swallowed, it leaves the m...  ...   497\n",
              "2   Let's now talk about what is easily one of th...  ...   256\n",
              "3   The goal in this video is to essentially prov...  ...   472\n",
              "4   A line goes through the points (-1, 6) and (5...  ...   304\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xybJvkdBoEUM"
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_data[\"video_transcripts\"].values,test_data[\"video_transcripts\"].values,train_data[\"label\"].values,test_data[\"label\"].values\n",
        "val_features,val_labels = val_data[\"video_transcripts\"].values, val_data[\"label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkQUzup2oPVz",
        "outputId": "78867e64-955c-4386-a2bd-15e7cf2ae5a1"
      },
      "source": [
        "train_features = use_embedding.get_tokenized_sents_embeddings_USE(train_features)\n",
        "test_features = use_embedding.get_tokenized_sents_embeddings_USE(test_features)\n",
        "print(train_features.shape,test_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4188, 512) (1047, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLUdX2tOSk_A",
        "outputId": "20ca5ab4-83da-466e-c080-6cb1c4d12fb5"
      },
      "source": [
        "import joblib\n",
        "joblib.dump(train_features,'train_features_log_khan_acad')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_features_log_khan_acad']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzcQWKw_SulP",
        "outputId": "7cdd91eb-d81d-4e4a-aaf2-ea972448c12e"
      },
      "source": [
        "joblib.dump(test_features,'test_features_log_khan_acad')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test_features_log_khan_acad']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJcLrH08Sxub"
      },
      "source": [
        "!mv test_features_log_khan_acad \"/content/drive/MyDrive/DL_project/\"\n",
        "!mv train_features_log_khan_acad \"/content/drive/MyDrive/DL_project/\""
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN4Grzq5S9zt"
      },
      "source": [
        "!mv  \"/content/drive/MyDrive/DL_project/test_features_log_khan_acad\" \"/content/drive/MyDrive/Information_retrieval_project/\"\n",
        "!mv  \"/content/drive/MyDrive/DL_project/train_features_log_khan_acad\" \"/content/drive/MyDrive/Information_retrieval_project/\""
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhcTwKyPgMYg"
      },
      "source": [
        "#parameters = {'solver':['newton-cg', 'lbfgs','sag', 'saga'], 'C':[0.01,0.1,1, 10]}\n",
        "log = LogisticRegression(max_iter=1000)\n",
        "#clf = GridSearchCV(log, parameters)\n",
        "log.fit(train_features, train_labels)\n",
        "#clf.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2qTHyXxjEQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9fc55d-dc3e-40aa-c413-bc53b26a3053"
      },
      "source": [
        "y_predict = log.predict_proba(test_features)\n",
        "print(y_predict.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1047, 569)\n",
            "(1047, 569)\n",
            "(1047, 569)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "P8x5VBelRAq6",
        "outputId": "9a731da5-36fc-4090-9f97-ac5f0f32ba77"
      },
      "source": [
        "get_labels(0)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'economics-finance-domain>>ap-macroeconomics>>ap-financial-sector'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u37rZnXA0Rwi"
      },
      "source": [
        "final_predictions =[]\n",
        "flat_predictions = y_predict\n",
        "for prediction in flat_predictions:\n",
        "  final_predictions.append(np.argsort(prediction.reshape(1,-1), axis=1)[:,-20:].squeeze())"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1Zzk2vZPE71",
        "outputId": "b82a8a0a-478e-4c7b-8259-f7d6827fae5e"
      },
      "source": [
        "final_predictions[1]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([137, 349, 173, 365, 222, 543,  96,  94, 179, 239, 174, 352, 100,\n",
              "       233, 360,  93, 350, 361,  87, 351])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjOMplkXSAQf",
        "outputId": "9c588eea-d1e8-4b28-f7e2-68c8f5f08519"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "precision_recall_fscore_support(test_labels, log.predict(test_features), average='weighted', zero_division=0)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.19197707736389685, 0.19197707736389685, 0.19197707736389685, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpZNr3RjK3Hi",
        "outputId": "2287aecb-4691-4951-f0a1-aa9b17f3bf01"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(test_labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 5)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 5)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 5)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session(config=tf.ConfigProto( allow_soft_placement=True)) as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(y_pred))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1047, 5) (1047,)\n",
            "update_recall:  0.11174785100286533\n",
            "recall 0.11174785100286533\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 117.0, 930.0, 0.0, 0.0]\n",
            "TMP_RANK:  [[173  93 233 476 327]\n",
            " [ 93 350 361  87 351]\n",
            " [  8  14   3   0  17]\n",
            " ...\n",
            " [350 320 327 321 352]\n",
            " [327 241 403 148 392]\n",
            " [493 495 499 417 494]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU5d7Y1T1HeF",
        "outputId": "74e67240-6493-40b5-e45b-cec240d76617"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(test_labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 10)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 10)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 10)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session(config=tf.ConfigProto( allow_soft_placement=True)) as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(y_pred))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1047, 10) (1047,)\n",
            "update_recall:  0.1766953199617956\n",
            "recall 0.1766953199617956\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 185.0, 862.0, 0.0, 0.0]\n",
            "TMP_RANK:  [[565 239  96 ... 233 476 327]\n",
            " [174 352 100 ... 361  87 351]\n",
            " [ 13  15  10 ...   3   0  17]\n",
            " ...\n",
            " [550 309 351 ... 327 321 352]\n",
            " [407 495 234 ... 403 148 392]\n",
            " [542 451 486 ... 499 417 494]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMBn7eG31Hgi",
        "outputId": "48cc0f2e-f731-4252-cfb6-d8b4eae16324"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(test_labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 15)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 15)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 15)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session(config=tf.ConfigProto( allow_soft_placement=True)) as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(y_pred))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1047, 15) (1047,)\n",
            "update_recall:  0.21967526265520534\n",
            "recall 0.21967526265520534\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 230.0, 817.0, 0.0, 0.0]\n",
            "TMP_RANK:  [[109 352 349 ... 233 476 327]\n",
            " [543  96  94 ... 361  87 351]\n",
            " [ 18  21   9 ...   3   0  17]\n",
            " ...\n",
            " [476 489 543 ... 327 321 352]\n",
            " [160 152 380 ... 403 148 392]\n",
            " [543 473 413 ... 499 417 494]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0IPxVPY1HlU",
        "outputId": "1b8146f3-cc9a-4ade-b7a9-c7a5178fa915"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(test_labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 20)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 20)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 20)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session(config=tf.ConfigProto( allow_soft_placement=True)) as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(y_pred))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1047, 20) (1047,)\n",
            "update_recall:  0.2588347659980898\n",
            "recall 0.2588347659980898\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 271.0, 776.0, 0.0, 0.0]\n",
            "TMP_RANK:  [[232 380 169 ... 233 476 327]\n",
            " [137 349 173 ... 361  87 351]\n",
            " [233  20 416 ...   3   0  17]\n",
            " ...\n",
            " [353 403 254 ... 327 321 352]\n",
            " [ 84 201 488 ... 403 148 392]\n",
            " [539 502 472 ... 499 417 494]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdHXaT9JLfzt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}