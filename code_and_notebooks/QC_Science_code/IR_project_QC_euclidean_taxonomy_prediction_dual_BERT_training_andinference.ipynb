{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "IR_project_QC_euclidean_taxonomy_prediction_dual_BERT_training_andinference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR9av2JU3kf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8387802c-c8b1-4f43-e412-0ce9d6ad6cd4"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da-zaZJUGMFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6bdf43a-bdee-48c8-bbcf-6c62f3e01a44"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKRu37yyrQ5D"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/Information_retrieval_project/QC_science/train_QC_data.csv\" /content\n",
        "!cp \"/content/drive/MyDrive/Information_retrieval_project/QC_science/test_QC_data.csv\" /content\n",
        "!cp \"/content/drive/MyDrive/Information_retrieval_project/QC_science/val_QC_data.csv\" /content\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzKeqoCs3kgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f9256f-7217-494b-d1f3-4b9c754d3be8"
      },
      "source": [
        "!pip install transformers==2.8.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.17.35)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.1.95)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.35 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (1.20.35)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (0.3.6)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.35->boto3->transformers==2.8.0) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf-OXnTs-ZhS"
      },
      "source": [
        "!cp -r \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_dual_bert_1_QC/\" /content/\n",
        "!cp -r \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_dual_bert_2_QC/\" /content/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZFv4UU8sLTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00db87e3-9129-485d-8c13-947777ad4206"
      },
      "source": [
        "!pip install git+https://github.com/geoopt/geoopt.git\n",
        "! pip install git+https://github.com/ferrine/hyrnn.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/geoopt/geoopt.git\n",
            "  Cloning https://github.com/geoopt/geoopt.git to /tmp/pip-req-build-c6hkjo_x\n",
            "  Running command git clone -q https://github.com/geoopt/geoopt.git /tmp/pip-req-build-c6hkjo_x\n",
            "Requirement already satisfied (use --upgrade to upgrade): geoopt==0.3.1 from git+https://github.com/geoopt/geoopt.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from geoopt==0.3.1) (1.8.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from geoopt==0.3.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->geoopt==0.3.1) (3.7.4.3)\n",
            "Building wheels for collected packages: geoopt\n",
            "  Building wheel for geoopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for geoopt: filename=geoopt-0.3.1-cp37-none-any.whl size=76168 sha256=12aa38769d2fabad239990a100be905bfacc2cad7a9c22e67682d1fb8ee90e1c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h1dm264l/wheels/10/df/30/e0d857f034c142ca5f38af048b62aae3da773b272553e5dd21\n",
            "Successfully built geoopt\n",
            "Collecting git+https://github.com/ferrine/hyrnn.git\n",
            "  Cloning https://github.com/ferrine/hyrnn.git to /tmp/pip-req-build-9ew5u_3z\n",
            "  Running command git clone -q https://github.com/ferrine/hyrnn.git /tmp/pip-req-build-9ew5u_3z\n",
            "Requirement already satisfied (use --upgrade to upgrade): hyrnn==0.0.0 from git+https://github.com/ferrine/hyrnn.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from hyrnn==0.0.0) (1.8.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyrnn==0.0.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->hyrnn==0.0.0) (3.7.4.3)\n",
            "Building wheels for collected packages: hyrnn\n",
            "  Building wheel for hyrnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hyrnn: filename=hyrnn-0.0.0-cp37-none-any.whl size=13955 sha256=c81d0f2fc180e87de53e904225bbdb5c2a51009ecc05c1b4f51b4b02cc6dfa3c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w4j7pzz5/wheels/24/c3/64/cc0e9d25d466081dc154a2a8843157f54d845b916b4ba66418\n",
            "Successfully built hyrnn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsADhaO93kgD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "outputId": "5dfa5c07-1dca-4e9a-8eac-02644190b47b"
      },
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"train_QC_data.csv\")\n",
        "val_data = pd.read_csv(\"val_QC_data.csv\")\n",
        "test_data = pd.read_csv(\"test_QC_data.csv\")\n",
        "\n",
        "train_data\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionID</th>\n",
              "      <th>originalQuestionID</th>\n",
              "      <th>totalPossiblePoint</th>\n",
              "      <th>AnswerKey</th>\n",
              "      <th>isMultipleChoiceQuestion</th>\n",
              "      <th>includesDiagram</th>\n",
              "      <th>examName</th>\n",
              "      <th>grade</th>\n",
              "      <th>year</th>\n",
              "      <th>QCLabel</th>\n",
              "      <th>Question</th>\n",
              "      <th>subject</th>\n",
              "      <th>category</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VASoL_2008_3_34</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Virginia Standards of Learning - Science</td>\n",
              "      <td>3</td>\n",
              "      <td>2008</td>\n",
              "      <td>matter_properties of objects_TEXT</td>\n",
              "      <td>A student is asked to bring something that fee...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MCAS_2015_8_6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>MCAS</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>celestial_FEATURES_STELLAR</td>\n",
              "      <td>Which of the following statements best describ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mercury_SC_417677</td>\n",
              "      <td>417677</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>4</td>\n",
              "      <td>2015</td>\n",
              "      <td>energy_LIGHT_REFLECT</td>\n",
              "      <td>A polished metal ball looks very shiny and bri...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mercury_7230423</td>\n",
              "      <td>7230423</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>9</td>\n",
              "      <td>2015</td>\n",
              "      <td>LIFE_EXTINCTION_MASSEX</td>\n",
              "      <td>Which was a main force driving extensive speci...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NYSEDREGENTS_2007_8_6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYSEDREGENTS</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>Life_functions_features and functions_CELLBIO_...</td>\n",
              "      <td>Compared to the amount of hereditary informati...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5592</th>\n",
              "      <td>Mercury_402502</td>\n",
              "      <td>402502</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>matter_chemistry_periodic table</td>\n",
              "      <td>According to the periodic table, argon is foun...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5593</th>\n",
              "      <td>MCAS_2006_9_20</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>MCAS</td>\n",
              "      <td>9</td>\n",
              "      <td>2006</td>\n",
              "      <td>FOR_MOMENTUM</td>\n",
              "      <td>Which of the following has the least momentum?...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5594</th>\n",
              "      <td>NYSEDREGENTS_2013_8_35</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYSEDREGENTS</td>\n",
              "      <td>8</td>\n",
              "      <td>2013</td>\n",
              "      <td>Life_functions_features and functions_PLANT_PH...</td>\n",
              "      <td>The amount of which greenhouse gas in the air ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5595</th>\n",
              "      <td>Mercury_7082670</td>\n",
              "      <td>7082670</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>energy_LIGHT_electromagnetic spectrum</td>\n",
              "      <td>The visible light spectrum can be subdivided a...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5596</th>\n",
              "      <td>Mercury_7004970</td>\n",
              "      <td>7004970</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>Life_reproduction_DNA inheritance_DOMRECESS</td>\n",
              "      <td>A scientist crosses a red-flowered plant with ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5597 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  questionID originalQuestionID  ...  category       fold\n",
              "0            VASoL_2008_3_34                 34  ...     Train       Easy\n",
              "1              MCAS_2015_8_6                  6  ...      Test       Easy\n",
              "2          Mercury_SC_417677             417677  ...      Test  Challenge\n",
              "3            Mercury_7230423            7230423  ...      Test       Easy\n",
              "4      NYSEDREGENTS_2007_8_6                  6  ...     Train  Challenge\n",
              "...                      ...                ...  ...       ...        ...\n",
              "5592          Mercury_402502             402502  ...      Test  Challenge\n",
              "5593          MCAS_2006_9_20                 20  ...     Train  Challenge\n",
              "5594  NYSEDREGENTS_2013_8_35                 35  ...      Test       Easy\n",
              "5595         Mercury_7082670            7082670  ...      Test       Easy\n",
              "5596         Mercury_7004970            7004970  ...     Train       Easy\n",
              "\n",
              "[5597 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z43kiCZHQ9WI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c1ea45a-4d59-412a-faaf-5ac6387fd0a6"
      },
      "source": [
        "test_data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionID</th>\n",
              "      <th>originalQuestionID</th>\n",
              "      <th>totalPossiblePoint</th>\n",
              "      <th>AnswerKey</th>\n",
              "      <th>isMultipleChoiceQuestion</th>\n",
              "      <th>includesDiagram</th>\n",
              "      <th>examName</th>\n",
              "      <th>grade</th>\n",
              "      <th>year</th>\n",
              "      <th>QCLabel</th>\n",
              "      <th>Question</th>\n",
              "      <th>subject</th>\n",
              "      <th>category</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mercury_409529</td>\n",
              "      <td>409529</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>science_INFERENCE_experiment design</td>\n",
              "      <td>Robert is a fisherman who wants to find a way ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dev</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mercury_7090790</td>\n",
              "      <td>7090790</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>matter_Change of state_EVAPoration</td>\n",
              "      <td>Which of these factors causes water to evapora...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TIMSS_2007_8_pg7</td>\n",
              "      <td>pg7</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>TIMSS</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>matter_chemistry_atomic</td>\n",
              "      <td>Which statement is true about the particles of...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mercury_7014455</td>\n",
              "      <td>7014455</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>energy_LIGHT_GENERICPROP</td>\n",
              "      <td>Which generates waves that are capable of trav...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dev</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NAEP_2000_8_S21+4</td>\n",
              "      <td>S21+4</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NAEP</td>\n",
              "      <td>8</td>\n",
              "      <td>2000</td>\n",
              "      <td>forces and friction</td>\n",
              "      <td>To keep a heavy box sliding across a carpeted ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>Mercury_SC_401827</td>\n",
              "      <td>401827</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>5</td>\n",
              "      <td>2015</td>\n",
              "      <td>matter_properties of material_ELECCOND</td>\n",
              "      <td>Metals that easily transfer electricity are ca...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>MDSA_2010_5_35</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Maryland School Assessment - Science</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>EARTH_human impacts_WHAT_air pollution</td>\n",
              "      <td>Many states require vehicles to be examined an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Mercury_7024483</td>\n",
              "      <td>7024483</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>Life_reproduction_DNA inheritance_inheritance</td>\n",
              "      <td>Which of these is not an inherited trait in hu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>NYSEDREGENTS_2008_4_17</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYSEDREGENTS</td>\n",
              "      <td>4</td>\n",
              "      <td>2008</td>\n",
              "      <td>Life_functions_FUNCT_animalESS</td>\n",
              "      <td>In order to survive, all animals need (A) heat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>MCAS_2001_8_13</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>MCAS</td>\n",
              "      <td>8</td>\n",
              "      <td>2001</td>\n",
              "      <td>EARTH_INNER_PLATE_CONTDRIFT</td>\n",
              "      <td>Scientists claim that the continents of South ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  questionID originalQuestionID  ...  category       fold\n",
              "0             Mercury_409529             409529  ...       Dev  Challenge\n",
              "1            Mercury_7090790            7090790  ...      Test  Challenge\n",
              "2           TIMSS_2007_8_pg7                pg7  ...     Train  Challenge\n",
              "3            Mercury_7014455            7014455  ...       Dev       Easy\n",
              "4          NAEP_2000_8_S21+4              S21+4  ...      Test  Challenge\n",
              "...                      ...                ...  ...       ...        ...\n",
              "1395       Mercury_SC_401827             401827  ...      Test       Easy\n",
              "1396          MDSA_2010_5_35                 35  ...     Train  Challenge\n",
              "1397         Mercury_7024483            7024483  ...     Train  Challenge\n",
              "1398  NYSEDREGENTS_2008_4_17                 17  ...      Test       Easy\n",
              "1399          MCAS_2001_8_13                 13  ...     Train  Challenge\n",
              "\n",
              "[1400 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_mbeDv5Q-lH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993
        },
        "outputId": "2f82e3eb-4ff4-4a95-b124-aef1505f58d0"
      },
      "source": [
        "val_data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionID</th>\n",
              "      <th>originalQuestionID</th>\n",
              "      <th>totalPossiblePoint</th>\n",
              "      <th>AnswerKey</th>\n",
              "      <th>isMultipleChoiceQuestion</th>\n",
              "      <th>includesDiagram</th>\n",
              "      <th>examName</th>\n",
              "      <th>grade</th>\n",
              "      <th>year</th>\n",
              "      <th>QCLabel</th>\n",
              "      <th>Question</th>\n",
              "      <th>subject</th>\n",
              "      <th>category</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MCAS_2006_9_30-v1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>MCAS</td>\n",
              "      <td>9</td>\n",
              "      <td>2006</td>\n",
              "      <td>matter_CHANGES_PHYSICAL</td>\n",
              "      <td>Which of the following changes occurs as a sol...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mercury_SC_401144</td>\n",
              "      <td>401144</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>5</td>\n",
              "      <td>2015</td>\n",
              "      <td>EARTH_WEATHER_CLOUDS</td>\n",
              "      <td>When water vapor rises and cools, the liquid w...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NCEOGA_2013_8_46</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>North Carolina READY End-of-Grade Assessment</td>\n",
              "      <td>8</td>\n",
              "      <td>2013</td>\n",
              "      <td>EARTH_GEO_FORMATIONS</td>\n",
              "      <td>Which best describes the characteristics of a ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dev</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mercury_417146</td>\n",
              "      <td>417146</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>Life_interdependence_ecological features</td>\n",
              "      <td>Most of the oxygen in the atmosphere is made b...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dev</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mercury_7283833</td>\n",
              "      <td>7283833</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>LIFE_HEALTH_DIESEASE_PANDEMICEPIDEMIC</td>\n",
              "      <td>Which aspect of modern Life_could most likely ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>773</th>\n",
              "      <td>Mercury_7128853</td>\n",
              "      <td>7128853</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>energy_SOUND_AMPLITUDE</td>\n",
              "      <td>As the loudness of a sound wave increases, whi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>774</th>\n",
              "      <td>Mercury_7245858</td>\n",
              "      <td>7245858</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>celestial_SPACEEX_HUMAN</td>\n",
              "      <td>In the initial stages of manned space explorat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>775</th>\n",
              "      <td>Mercury_417462</td>\n",
              "      <td>417462</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>Life_functions_features and functions_PLANT_RE...</td>\n",
              "      <td>During a walk in the woods, Mandy finds a plan...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>776</th>\n",
              "      <td>Mercury_7044065</td>\n",
              "      <td>7044065</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>EARTH_human impacts_WHAT_air pollution</td>\n",
              "      <td>What is the MAJOR cause of acid rain? (A) smel...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>Mercury_7094238</td>\n",
              "      <td>7094238</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>Which invention would a culture living above t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>778 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            questionID originalQuestionID  ...  category       fold\n",
              "0    MCAS_2006_9_30-v1                 30  ...     Train  Challenge\n",
              "1    Mercury_SC_401144             401144  ...     Train       Easy\n",
              "2     NCEOGA_2013_8_46                 46  ...       Dev       Easy\n",
              "3       Mercury_417146             417146  ...       Dev  Challenge\n",
              "4      Mercury_7283833            7283833  ...      Test  Challenge\n",
              "..                 ...                ...  ...       ...        ...\n",
              "773    Mercury_7128853            7128853  ...      Test       Easy\n",
              "774    Mercury_7245858            7245858  ...     Train       Easy\n",
              "775     Mercury_417462             417462  ...      Test       Easy\n",
              "776    Mercury_7044065            7044065  ...      Test       Easy\n",
              "777    Mercury_7094238            7094238  ...     Train  Challenge\n",
              "\n",
              "[778 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQhO6qqt6lge"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD4IAgG1XQGp"
      },
      "source": [
        "import re\n",
        "def clean_sentence(question):\n",
        "  # print(question)\n",
        "  question = re.sub('<[^>]*>', ' ',question)\n",
        "  question = re.sub(' +', ' ', question)\n",
        "  question = re.sub('\\xa0','',question)\n",
        "  question = question.rstrip()\n",
        "  question = re.sub('nan','',question)\n",
        "  question = re.sub(u'\\u2004','',question)\n",
        "  question = re.sub(u'\\u2009','',question)\n",
        "\n",
        "  # question = question.decode(\"utf-8\")\n",
        "  # question = question.replace(u'\\u200\\d*','').encode(\"utf-8\")\n",
        "  question = re.sub('&nbsp','',question)\n",
        "  question = re.sub('&ndash','',question)\n",
        "  question = re.sub('\\r','',question)\n",
        "  question = re.sub('\\t','',question)\n",
        "  question = re.sub('\\n',' ',question)\n",
        "\n",
        "  question = re.sub('MathType@.*','',question)\n",
        "  question = re.sub('&thinsp','',question)\n",
        "  question = re.sub('&times','',question)\n",
        "  question = re.sub('\\u200b','',question)\n",
        "  question = re.sub('&rarr;;;','',question)\n",
        "\n",
        "  return question"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNrGNk8f3kgh"
      },
      "source": [
        "# final_data_1 = final_data.loc[0:71003,:]\n",
        "# final_data_1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkJyRhquRKz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b95808c-2ea9-42a0-b0a1-d5bd7f4d598f"
      },
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIrS5sxE3kgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05244fca-f4e4-4fbd-e3b2-ae1d888a3f2c"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mgc72PQYV1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17582092-caf4-4328-c457-8c397e03a012"
      },
      "source": [
        "train_data[\"QCLabel\"].value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "celestial_cycles                                                106\n",
              "matter_chemistry_periodic table                                  85\n",
              "matter_chemistry_atomic                                          79\n",
              "matter_CHANGES_CHEMICAL                                          72\n",
              "science_INFERENCE_observation                                    69\n",
              "                                                               ... \n",
              "forces and friction and objects                                   1\n",
              "Life_functions_features and functions_CELLBIO_STRUCT_VACUOLE      1\n",
              "EARTH_GEO_HISTORY                                                 1\n",
              "Life_functions_features and functions_animal_nervous system       1\n",
              "celestial_FEATURES_BLACKHOLE                                      1\n",
              "Name: QCLabel, Length: 416, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owuvwWJORK8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a44dd6-570e-454e-f6ad-ad75cedd52b4"
      },
      "source": [
        "test_data[\"QCLabel\"].value_counts()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "celestial_cycles                                                     26\n",
              "Life_reproduction_DNA inheritance_inheritance                        26\n",
              "Life_functions_features and functions_PLANT_PHOTOSYNTH               22\n",
              "matter_chemistry_atomic                                              21\n",
              "science_INFERENCE_experiment design                                  19\n",
              "                                                                     ..\n",
              "science_INFERENCE_INFERENCE                                           1\n",
              "energy_FORMS_ELEC                                                     1\n",
              "force_newton_first                                                    1\n",
              "LIFE_environment and adaptation_animal adaptations_BEHAV_NESTBLDG     1\n",
              "energy_WAVES_GENERICPROP                                              1\n",
              "Name: QCLabel, Length: 352, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3lYOb2K3kgy"
      },
      "source": [
        "\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# LE = LabelEncoder()\n",
        "# final_data['label'] = LE.fit_transform(final_data['board_syllabus'])\n",
        "# final_data.head()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp64MkNB3kg1"
      },
      "source": [
        "# def get_labels(prediction):\n",
        "#     predicted_label =  LE.inverse_transform([prediction])\n",
        "#     return predicted_label[0]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPgTmJPS3kg4"
      },
      "source": [
        "# get_labels(330)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnHXROhbuXgO"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrQ1BBx0vWUQ"
      },
      "source": [
        "# train_data = pd.concat([train_data,val_data])\n",
        "# train_data"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijn1nIpByb3e"
      },
      "source": [
        "train_features = train_data[\"Question\"]\n",
        "test_features = test_data[\"Question\"]\n",
        "train_labels = train_data[\"QCLabel\"]\n",
        "test_labels = test_data[\"QCLabel\"]\n",
        "val_features = val_data[\"Question\"]\n",
        "val_labels = val_data[\"QCLabel\"]"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prM_km_83khD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86272e17-6525-4810-832f-70c395c732eb"
      },
      "source": [
        "train_labels.value_counts()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "celestial_cycles                                                106\n",
              "matter_chemistry_periodic table                                  85\n",
              "matter_chemistry_atomic                                          79\n",
              "matter_CHANGES_CHEMICAL                                          72\n",
              "science_INFERENCE_observation                                    69\n",
              "                                                               ... \n",
              "forces and friction and objects                                   1\n",
              "Life_functions_features and functions_CELLBIO_STRUCT_VACUOLE      1\n",
              "EARTH_GEO_HISTORY                                                 1\n",
              "Life_functions_features and functions_animal_nervous system       1\n",
              "celestial_FEATURES_BLACKHOLE                                      1\n",
              "Name: QCLabel, Length: 416, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfhPstXJ03oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9de0606-6f4f-431d-cccc-01f0b67f68fd"
      },
      "source": [
        "test_labels.value_counts()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "celestial_cycles                                                     26\n",
              "Life_reproduction_DNA inheritance_inheritance                        26\n",
              "Life_functions_features and functions_PLANT_PHOTOSYNTH               22\n",
              "matter_chemistry_atomic                                              21\n",
              "science_INFERENCE_experiment design                                  19\n",
              "                                                                     ..\n",
              "science_INFERENCE_INFERENCE                                           1\n",
              "energy_FORMS_ELEC                                                     1\n",
              "force_newton_first                                                    1\n",
              "LIFE_environment and adaptation_animal adaptations_BEHAV_NESTBLDG     1\n",
              "energy_WAVES_GENERICPROP                                              1\n",
              "Name: QCLabel, Length: 352, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkyM7gqv3khI"
      },
      "source": [
        "\n",
        "question_answer = train_features.values\n",
        "categories = train_labels.values"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFkS_H_83khL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a29b2c-bae4-4743-9b64-bdef2e2cb8ea"
      },
      "source": [
        "question_answer"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['A student is asked to bring something that feels rough to class. Which would be BEST for him to bring? (A) Pillow (B) Marble (C) Sandpaper (D) Trading card',\n",
              "       'Which of the following statements best describes the role of gravity in the formation of stars? (A) Gravity converts solid matter into gases and light energy. (B) Gravity causes gases and dust particles to condense into spheres. (C) Gravity cools gases and liquids until they become one solid mass. (D) Gravity pushes rocks and dust particles outward from a dense center.',\n",
              "       'A polished metal ball looks very shiny and bright on a sunny day. What makes the ball look shiny? (A) The ball makes light. (B) The ball reflects light. (C) The ball absorbs light and then releases it. (D) The ball absorbs light and keeps it inside.',\n",
              "       ...,\n",
              "       'The amount of which greenhouse gas in the air will increase the most if large forests are cut down to be used for building materials without planting new trees in their place? (1) ozone (2) methane (3) water vapor (4) carbon dioxide',\n",
              "       'The visible light spectrum can be subdivided according to (A) the types of waves. (B) the sizes of particles. (C) a range of colors. (D) a type of energy.',\n",
              "       'A scientist crosses a red-flowered plant with a white-flowered plant, and all offspring have red flowers. What will most likely result if these red-flowered offspring are crossed with white-flowered plants? (A) All of the offspring will have red flowers. (B) All of the offspring will have white flowers. (C) The offspring will have either red or white flowers. (D) The offspring will have neither red nor white flowers.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ian7gSDE3khR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dec0275-ff1f-4d9c-b46d-dc30a8bad99b"
      },
      "source": [
        "categories"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['matter_properties of objects_TEXT', 'celestial_FEATURES_STELLAR',\n",
              "       'energy_LIGHT_REFLECT', ...,\n",
              "       'Life_functions_features and functions_PLANT_PHOTOSYNTH',\n",
              "       'energy_LIGHT_electromagnetic spectrum',\n",
              "       'Life_reproduction_DNA inheritance_DOMRECESS'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fepGiggpqOQx"
      },
      "source": [
        "# val_features = test_features.values\n",
        "# val_labels = test_labels.values"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L2y3KLjV5OB"
      },
      "source": [
        "# list(set(label_emb_data))[0]\n",
        "# # list(set(train_data['board_syllabus'].values))[0]\n",
        "# label_emb_data[0]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN1zRXMOXwLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ffed70-cfa2-4b36-e3e6-0600eeb0ee01"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "!pip install inflection\n",
        "\n",
        "from bokeh.io import output_file, output_notebook, show\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.transform import linear_cmap\n",
        "from bokeh.util.hex import hexbin\n",
        "from bokeh.models import HoverTool\n",
        "from bokeh import colors\n",
        "import inflection\n",
        "\n",
        "from nltk.stem import PorterStemmer \n",
        "ps = PorterStemmer()\n",
        "from gzip import open as gopen\n",
        "from pandas.core.common import flatten\n",
        "import gensim.models.poincare as poincare\n",
        "def get_cleaned_taxonomy(taxonomy):\n",
        "  cleaned_taxonomy = []\n",
        "  for value in taxonomy:\n",
        "      value = ' '.join(value.lower().split(\"_\"))\n",
        "      # taxonomy_words = [inflection.singularize(val)  for token in value for val in token.split(\" \") if val.isalpha()]\n",
        "      cleaned_taxonomy.append( value )\n",
        "  return cleaned_taxonomy"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: inflection in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPAl0TNuX6mx"
      },
      "source": [
        "\n",
        "# course_taxonomy\n",
        "\n",
        "label_emb_data = get_cleaned_taxonomy(categories)\n",
        "label_val = get_cleaned_taxonomy(val_labels)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdFQoVFqWQ2m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6794a7ca-6356-4b6b-8acb-dc4cb5d1761f"
      },
      "source": [
        "label_emb_data[0]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'matter properties of objects text'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aedZzkBsqEeK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ede93988-1ff1-4afe-c5e3-c5aceca86adb"
      },
      "source": [
        "label_emb_data[2]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'energy light reflect'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_ocuHxzCy16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1094250e-fb3b-48fb-ae24-13e4a6fc7363"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "wnl = WordNetLemmatizer()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FU-K6GP_1jM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2dbd0e4-74dc-48c0-e96f-1d3efb67bdb5"
      },
      "source": [
        "len(list(set(label_emb_data)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czfB-yOBSjGJ"
      },
      "source": [
        "label_input_ids = []\n",
        "label_attention_masks = []\n",
        "for sent in label_emb_data:\n",
        "\n",
        "    label_encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    label_input_ids.append(label_encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    label_attention_masks.append(label_encoded_dict['attention_mask'])\n",
        "label_input_ids = torch.cat(label_input_ids, dim=0)\n",
        "label_attention_masks = torch.cat(label_attention_masks, dim=0)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT7tK3YTSswa"
      },
      "source": [
        "label_input_ids_val = []\n",
        "label_attention_masks_val = []\n",
        "for sent in label_val:\n",
        "\n",
        "    label_encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    label_input_ids_val.append(label_encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    label_attention_masks_val.append(label_encoded_dict['attention_mask'])\n",
        "label_input_ids_val = torch.cat(label_input_ids_val, dim=0)\n",
        "label_attention_masks_val = torch.cat(label_attention_masks_val, dim=0)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdBbsrO9zp2p"
      },
      "source": [
        "# taxonomy_vectors = []\n",
        "# for label_input_id,label_att_mask in zip(label_input_ids,label_attention_masks):\n",
        "#     label_input_id = label_input_id.to(device)\n",
        "#     label_att_mask = label_att_mask.to(device)\n",
        "#     with torch.no_grad():\n",
        "#       outputs = model_label(label_input_id.reshape(1,-1),label_att_mask.reshape(1,-1))\n",
        "#     taxonomy_vectors.append(outputs[1].cpu().numpy())\n",
        "# taxonomy_vectors = np.vstack(taxonomy_vectors)\n",
        "# taxonomy_vectors.shape\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTlCYX9Q34JG"
      },
      "source": [
        "# taxonomy_vectors_val = []\n",
        "# for feature in poincare_val:\n",
        "#   taxonomy_vectors_val.append(model.embed_sentences([feature]))\n",
        "# taxonomy_vectors_val = np.vstack(taxonomy_vectors_val)\n",
        "# taxonomy_vectors_val.shape"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-DEKAOHv-VD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a4d61d4-7060-4bf7-81b5-1cb3247b480e"
      },
      "source": [
        "test_data"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionID</th>\n",
              "      <th>originalQuestionID</th>\n",
              "      <th>totalPossiblePoint</th>\n",
              "      <th>AnswerKey</th>\n",
              "      <th>isMultipleChoiceQuestion</th>\n",
              "      <th>includesDiagram</th>\n",
              "      <th>examName</th>\n",
              "      <th>grade</th>\n",
              "      <th>year</th>\n",
              "      <th>QCLabel</th>\n",
              "      <th>Question</th>\n",
              "      <th>subject</th>\n",
              "      <th>category</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mercury_409529</td>\n",
              "      <td>409529</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>science_INFERENCE_experiment design</td>\n",
              "      <td>Robert is a fisherman who wants to find a way ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dev</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mercury_7090790</td>\n",
              "      <td>7090790</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>matter_Change of state_EVAPoration</td>\n",
              "      <td>Which of these factors causes water to evapora...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TIMSS_2007_8_pg7</td>\n",
              "      <td>pg7</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>TIMSS</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>matter_chemistry_atomic</td>\n",
              "      <td>Which statement is true about the particles of...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mercury_7014455</td>\n",
              "      <td>7014455</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>energy_LIGHT_GENERICPROP</td>\n",
              "      <td>Which generates waves that are capable of trav...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dev</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NAEP_2000_8_S21+4</td>\n",
              "      <td>S21+4</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NAEP</td>\n",
              "      <td>8</td>\n",
              "      <td>2000</td>\n",
              "      <td>forces and friction</td>\n",
              "      <td>To keep a heavy box sliding across a carpeted ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>Mercury_SC_401827</td>\n",
              "      <td>401827</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>5</td>\n",
              "      <td>2015</td>\n",
              "      <td>matter_properties of material_ELECCOND</td>\n",
              "      <td>Metals that easily transfer electricity are ca...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>MDSA_2010_5_35</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Maryland School Assessment - Science</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>EARTH_human impacts_WHAT_air pollution</td>\n",
              "      <td>Many states require vehicles to be examined an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Mercury_7024483</td>\n",
              "      <td>7024483</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Mercury</td>\n",
              "      <td>8</td>\n",
              "      <td>2015</td>\n",
              "      <td>Life_reproduction_DNA inheritance_inheritance</td>\n",
              "      <td>Which of these is not an inherited trait in hu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>NYSEDREGENTS_2008_4_17</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NYSEDREGENTS</td>\n",
              "      <td>4</td>\n",
              "      <td>2008</td>\n",
              "      <td>Life_functions_FUNCT_animalESS</td>\n",
              "      <td>In order to survive, all animals need (A) heat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test</td>\n",
              "      <td>Easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>MCAS_2001_8_13</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>MCAS</td>\n",
              "      <td>8</td>\n",
              "      <td>2001</td>\n",
              "      <td>EARTH_INNER_PLATE_CONTDRIFT</td>\n",
              "      <td>Scientists claim that the continents of South ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train</td>\n",
              "      <td>Challenge</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  questionID originalQuestionID  ...  category       fold\n",
              "0             Mercury_409529             409529  ...       Dev  Challenge\n",
              "1            Mercury_7090790            7090790  ...      Test  Challenge\n",
              "2           TIMSS_2007_8_pg7                pg7  ...     Train  Challenge\n",
              "3            Mercury_7014455            7014455  ...       Dev       Easy\n",
              "4          NAEP_2000_8_S21+4              S21+4  ...      Test  Challenge\n",
              "...                      ...                ...  ...       ...        ...\n",
              "1395       Mercury_SC_401827             401827  ...      Test       Easy\n",
              "1396          MDSA_2010_5_35                 35  ...     Train  Challenge\n",
              "1397         Mercury_7024483            7024483  ...     Train  Challenge\n",
              "1398  NYSEDREGENTS_2008_4_17                 17  ...      Test       Easy\n",
              "1399          MCAS_2001_8_13                 13  ...     Train  Challenge\n",
              "\n",
              "[1400 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p834oM1Pzzu8"
      },
      "source": [
        "# np.array(poincare_embedding).shape"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_ZeuHc63khU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c47de6f-7b2b-4e05-8ba2-91b071b26ae4"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in question_answer:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', question_answer[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  A student is asked to bring something that feels rough to class. Which would be BEST for him to bring? (A) Pillow (B) Marble (C) Sandpaper (D) Trading card\n",
            "Token IDs: tensor([  101,  1037,  3076,  2003,  2356,  2000,  3288,  2242,  2008,  5683,\n",
            "         5931,  2000,  2465,  1012,  2029,  2052,  2022,  2190,  2005,  2032,\n",
            "         2000,  3288,  1029,  1006,  1037,  1007, 10005,  1006,  1038,  1007,\n",
            "         7720,  1006,  1039,  1007,  5472, 23298,  1006,  1040,  1007,  6202,\n",
            "         4003,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VjkhiN3pAfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dbe9f61-cd10-4141-af8e-161c58522520"
      },
      "source": [
        "input_ids_val = []\n",
        "attention_masks_val = []\n",
        "\n",
        "for sent in val_features:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids_val.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks_val.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
        "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', question_answer[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  A student is asked to bring something that feels rough to class. Which would be BEST for him to bring? (A) Pillow (B) Marble (C) Sandpaper (D) Trading card\n",
            "Token IDs: tensor([  101,  1037,  3076,  2003,  2356,  2000,  3288,  2242,  2008,  5683,\n",
            "         5931,  2000,  2465,  1012,  2029,  2052,  2022,  2190,  2005,  2032,\n",
            "         2000,  3288,  1029,  1006,  1037,  1007, 10005,  1006,  1038,  1007,\n",
            "         7720,  1006,  1039,  1007,  5472, 23298,  1006,  1040,  1007,  6202,\n",
            "         4003,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNDW74Ny3khj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca7d57d-935a-4015-eb90-a555193cab76"
      },
      "source": [
        "num_classes = len(list(set(categories)))\n",
        "num_classes"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmaLk5Ab3khl"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# train_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n",
        "# val_poincare_tensor = torch.tensor(taxonomy_vectors_val,dtype=torch.float)\n",
        "\n",
        "val_dataset = TensorDataset(input_ids_val,attention_masks_val,label_input_ids_val,label_attention_masks_val)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, label_input_ids,label_attention_masks)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_lTinod3kho"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vduf9fOMviK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df8c278b-198c-4c78-a8c6-da67b313f803"
      },
      "source": [
        "# !pip install transformers==2.8.0\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H2wp8WlEi9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb4ce63-f5ad-4358-f585-38212c722a17"
      },
      "source": [
        "set(question_answer).intersection(set(test_features))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN6jdKp0uhO3"
      },
      "source": [
        "\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.nn.modules.loss import HingeEmbeddingLoss\n",
        "from random import randint\n",
        "\n",
        "from tqdm import tqdm\n",
        "import geoopt\n",
        "import time\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.nn.modules.loss import HingeEmbeddingLoss\n",
        "from random import randint\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import time\n",
        "import argparse\n",
        "cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "# Neural Classifierwork\n",
        "class MulticlassClassifier(nn.Module):\n",
        "    def __init__(self,bert_model_path):\n",
        "        super(MulticlassClassifier,self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_path,output_hidden_states=False,output_attentions=False)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc1 = nn.Linear(768, 384)\n",
        "        self.fc2 = nn.Linear(384, 768)\n",
        "\n",
        "    def forward(self,tokens,masks):\n",
        "        _, pooled_output = self.bert(tokens, attention_mask=masks)\n",
        "        x = self.fc1(pooled_output)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "class MyHingeLoss(torch.nn.Module):\n",
        "    def __init__(self, margin):\n",
        "        super(MyHingeLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "    # def forward_val(self, output, target):\n",
        "    #     cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "    #     loss = 0\n",
        "    #     num_compare = 4\n",
        "    #     count = 0\n",
        "    #     for i in range(len(output)):\n",
        "    #         v_image = output[i]\n",
        "    #         t_label = target[i]\n",
        "    #         for j in range(num_compare):\n",
        "    #             if j != i:\n",
        "    #                 count += 1\n",
        "    #                 t_j = target[j]\n",
        "    #                 loss += torch.relu( self.margin - cos(t_label, v_image) + cos(t_j, v_image) )\n",
        "    #     return loss / count\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        loss=0\n",
        "        for i in range(len(output)):\n",
        "            v_image = output[i]\n",
        "            t_label = target[i]\n",
        "            j = randint(0, len(output)-1)\n",
        "            while j == i:\n",
        "                j = randint(0, len(output)-1)\n",
        "            t_j = target[j]\n",
        "            loss+= torch.relu( self.margin - cos(t_label, v_image) + cos(t_j, v_image) )\n",
        "        return loss / len(output)\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHYyjxMDIx2U"
      },
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2tmAMlw3khr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b84bab0-ed69-4239-bb27-30da85194fde"
      },
      "source": [
        "from transformers import BertModel, AdamW, BertConfig\n",
        "\n",
        "# Loads BertModel, the pretrained BERT model with a single \n",
        "model = MulticlassClassifier('bert-base-uncased')\n",
        "model.load_state_dict(torch.load('model_euclidean_dual_bert_1_QC/model_weights'))\n",
        "model_label = MulticlassClassifier('bert-base-uncased')\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model_label.load_state_dict(torch.load('model_euclidean_dual_bert_2_QC/model_weights'))\n",
        "\n",
        "model.cuda()\n",
        "model_label.cuda()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MulticlassClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=768, out_features=384, bias=True)\n",
              "  (fc2): Linear(in_features=384, out_features=768, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4paz_8iTZ9o"
      },
      "source": [
        "# mobius_params = []\n",
        "# bert_params = []\n",
        "\n",
        "# def mobius_params():\n",
        "#   for param in model.named_parameters():\n",
        "#     if 'fc' in param[0]:\n",
        "#       yield param[1]\n",
        "# def bert_params():\n",
        "#   for param in model.named_parameters():\n",
        "#     if 'bert' in param[0]:\n",
        "#       yield param[1]\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awQ2Y9Jb3kht"
      },
      "source": [
        "optimizer_1 = torch.optim.AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "optimizer_2 = torch.optim.AdamW(model_label.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ys-M4-e3khv"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "epochs = 30\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrYqErOD3khx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "991ea605-8296-4327-990c-f0831b9c0d57"
      },
      "source": [
        "len(train_dataloader) "
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "175"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWVSE9LM3kh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2254097-8ead-4c84-aa50-04615f28e9d5"
      },
      "source": [
        "1935 * 32"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61920"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcvxVVi63kh3"
      },
      "source": [
        "scheduler = get_linear_schedule_with_warmup(optimizer_1, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUw3zm6g3kh5"
      },
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Function to calculate the accuracy of our predictions vs labels\n",
        "# def flat_accuracy(preds, labels):\n",
        "#     pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "#     labels_flat = labels.flatten()\n",
        "#     return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta6zfUTa3kh7"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFq9gd5kQSHb"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsInxVoqbsFW"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di68jXK5WaYr"
      },
      "source": [
        "criterion = MyHingeLoss(0.1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LhAy2hZ3kh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de1332cc-0bae-489b-f247-508ccbbb543c"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.metrics import f1_score\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "early_stopping = EarlyStopping(patience=6, verbose=True)\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_label_input_ids = batch[2].to(device)\n",
        "        b_label_att_masks = batch[3].to(device)\n",
        "\n",
        "\n",
        "        model.zero_grad() \n",
        "        model_label.zero_grad()\n",
        "        optimizer_1.zero_grad()       \n",
        "\n",
        "        logits = model(b_input_ids, \n",
        "                             b_input_mask)\n",
        "        label_repr = model_label(b_label_input_ids,b_label_att_masks)\n",
        "        \n",
        "        loss = criterion.forward(logits,label_repr)\n",
        "\n",
        "  \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer_1.step()\n",
        "        optimizer_2.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_f1 = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_label_input_id = batch[2].to(device)\n",
        "        b_label_att_mask = batch[3].to(device)\n",
        "\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "\n",
        "          logits = model(b_input_ids, \n",
        "                              b_input_mask)\n",
        "          label_repr = model_label(b_label_input_id,b_label_att_mask)\n",
        "        loss = criterion(logits,label_repr)\n",
        "\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "        # Move logits and labels to CPU\n",
        "        # logits = logits.detach().cpu().numpy().round()\n",
        "        # label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        # total_eval_f1 += f1_score(label_ids,logits, average='macro')\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    # avg_val_accuracy = total_eval_f1 / len(validation_dataloader)\n",
        "    # print(\"  f1score: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    early_stopping(avg_val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break  \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    output_dir = 'model_euclidean_dual_bert_1_QC/'\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "        os.makedirs(\"model_euclidean_dual_bert_2_QC\")\n",
        "\n",
        "    print(\"Saving model to %s\" % output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n",
        "    torch.save(model_label.state_dict(), os.path.join('model_euclidean_dual_bert_2_QC', 'model_weights'))\n",
        "\n",
        "\n",
        "    !rm -rf \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_dual_bert_1_QC\"\n",
        "    !mv model_euclidean_dual_bert_1_QC \"/content/drive/My Drive/research_lo_content_taxonomy_classification/\"\n",
        "\n",
        "    !rm -rf \"/content/drive/My Drive/research_lo_content_taxonomy_classification/model_euclidean_dual_bert_2_QC\"\n",
        "    !mv model_euclidean_dual_bert_2_QC \"/content/drive/My Drive/research_lo_content_taxonomy_classification/\"\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:00:57.\n",
            "  Batch    80  of    175.    Elapsed: 0:01:55.\n",
            "  Batch   120  of    175.    Elapsed: 0:02:55.\n",
            "  Batch   160  of    175.    Elapsed: 0:03:55.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epcoh took: 0:04:18\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (inf --> 0.033130).  Saving model ...\n",
            "  Validation Loss: 0.03\n",
            "  Validation took: 0:00:14\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 2 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:02.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:02.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:02.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epcoh took: 0:04:25\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.033130 --> 0.025771).  Saving model ...\n",
            "  Validation Loss: 0.03\n",
            "  Validation took: 0:00:14\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 3 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:02.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:02.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:03.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:04:25\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.025771 --> 0.022082).  Saving model ...\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:00:14\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 4 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:02.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:02.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:02.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:02.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:04:25\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 1 out of 6\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:00:12\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 5 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:01.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:01.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:01.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:04:24\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 2 out of 6\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:00:12\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 6 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:01.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:01.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:01.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:04:24\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 3 out of 6\n",
            "  Validation Loss: 0.03\n",
            "  Validation took: 0:00:12\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 7 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:01.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:01.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:01.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:23\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 4 out of 6\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:00:12\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 8 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:01.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:01.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:01.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:23\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 5 out of 6\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:00:12\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 9 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:01.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:01.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:01.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:23\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.022082 --> 0.018127).  Saving model ...\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:00:14\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 10 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:01.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:01.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:00.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:23\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.018127 --> 0.016787).  Saving model ...\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:00:14\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 11 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:01.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:00.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:23\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.016787 --> 0.016063).  Saving model ...\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:00:14\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 12 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:01.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:00.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:23\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.016063 --> 0.016051).  Saving model ...\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:00:14\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 13 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:01.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:01.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:00.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:23\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.016051 --> 0.013700).  Saving model ...\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:14\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 14 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:00.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:22\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 1 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:12\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 15 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    175.    Elapsed: 0:03:59.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:22\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 2 out of 6\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:00:12\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 16 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:00.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:22\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 3 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:12\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 17 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    175.    Elapsed: 0:03:59.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:22\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 4 out of 6\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:00:12\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 18 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    175.    Elapsed: 0:03:59.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:22\n",
            "\n",
            "Running Validation...\n",
            "Validation loss decreased (0.013700 --> 0.012153).  Saving model ...\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:14\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 19 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:00.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:22\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 1 out of 6\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:00:12\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 20 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    175.    Elapsed: 0:03:59.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:22\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 2 out of 6\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:00:12\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 21 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:00.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:23\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 3 out of 6\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:00:12\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 22 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:01.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:01.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:01.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:23\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 4 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:12\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 23 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:01.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:01.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:01.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:24\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 5 out of 6\n",
            "  Validation Loss: 0.01\n",
            "  Validation took: 0:00:12\n",
            "Saving model to model_euclidean_dual_bert_1_QC/\n",
            "\n",
            "======== Epoch 24 / 30 ========\n",
            "Training...\n",
            "  Batch    40  of    175.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    175.    Elapsed: 0:02:01.\n",
            "  Batch   120  of    175.    Elapsed: 0:03:01.\n",
            "  Batch   160  of    175.    Elapsed: 0:04:01.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:04:23\n",
            "\n",
            "Running Validation...\n",
            "EarlyStopping counter: 6 out of 6\n",
            "Early stopping\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:57:29 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RACcsko3kh_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "outputId": "cf070938-aa4e-47d8-9588-4bec005835be"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.09e-02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0:04:18</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.02e-02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0:04:25</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.40e-02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0:04:25</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.30e-02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0:04:25</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.82e-02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0:04:24</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.59e-02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0:04:24</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.38e-02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0:04:23</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.34e-02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0:04:23</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.24e-02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0:04:23</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.19e-02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0:04:23</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>9.85e-03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0:04:23</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>9.70e-03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0:04:23</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.00e-02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0:04:23</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>9.17e-03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0:04:22</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>8.57e-03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0:04:22</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>8.00e-03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0:04:22</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>7.86e-03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0:04:22</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.99e-03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0:04:22</td>\n",
              "      <td>0:00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6.94e-03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0:04:22</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>6.84e-03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0:04:22</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>6.18e-03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0:04:23</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>6.75e-03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0:04:23</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>6.10e-03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0:04:24</td>\n",
              "      <td>0:00:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1           6.09e-02         0.03       0:04:18         0:00:14\n",
              "2           3.02e-02         0.03       0:04:25         0:00:14\n",
              "3           2.40e-02         0.02       0:04:25         0:00:14\n",
              "4           2.30e-02         0.02       0:04:25         0:00:12\n",
              "5           1.82e-02         0.02       0:04:24         0:00:12\n",
              "6           1.59e-02         0.03       0:04:24         0:00:12\n",
              "7           1.38e-02         0.02       0:04:23         0:00:12\n",
              "8           1.34e-02         0.02       0:04:23         0:00:12\n",
              "9           1.24e-02         0.02       0:04:23         0:00:14\n",
              "10          1.19e-02         0.02       0:04:23         0:00:14\n",
              "11          9.85e-03         0.02       0:04:23         0:00:14\n",
              "12          9.70e-03         0.02       0:04:23         0:00:14\n",
              "13          1.00e-02         0.01       0:04:23         0:00:14\n",
              "14          9.17e-03         0.01       0:04:22         0:00:12\n",
              "15          8.57e-03         0.02       0:04:22         0:00:12\n",
              "16          8.00e-03         0.01       0:04:22         0:00:12\n",
              "17          7.86e-03         0.02       0:04:22         0:00:12\n",
              "18          6.99e-03         0.01       0:04:22         0:00:14\n",
              "19          6.94e-03         0.02       0:04:22         0:00:12\n",
              "20          6.84e-03         0.02       0:04:22         0:00:12\n",
              "21          6.18e-03         0.02       0:04:23         0:00:12\n",
              "22          6.75e-03         0.01       0:04:23         0:00:12\n",
              "23          6.10e-03         0.01       0:04:24         0:00:12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5TicdiP3kiC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "f3f3ccfa-7dc0-4ce0-cb4f-119aa337ca34"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbiTDpVv3kiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc574a1-c7e1-4a22-e0c6-210f2bb42d79"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "output_dir = 'model_euclidean_dual_bert_1_QC_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "\n",
        "# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "# model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to model_euclidean_dual_bert_1_QC_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model_euclidean_dual_bert_1_QC_save/vocab.txt',\n",
              " 'model_euclidean_dual_bert_1_QC_save/special_tokens_map.json',\n",
              " 'model_euclidean_dual_bert_1_QC_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U2UQ29a3kiI"
      },
      "source": [
        "# !pip install joblib\n",
        "# import joblib\n",
        "# joblib.dump(LE, \"label_encoder\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F5PxZm9vAOI"
      },
      "source": [
        "import json\n",
        "torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alo20J6S7Kfd"
      },
      "source": [
        "!mv /content/model_euclidean_dual_bert_1_QC_save \"/content/drive/My Drive/research_lo_content_taxonomy_classification\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlb0IpVJO1XQ"
      },
      "source": [
        "# with open(os.path.join(output_dir, 'model_config.json'), 'w') as f:\n",
        "#     json.dump(model.config, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpGY8vSDI6u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e56362f-2dd0-4eec-e60c-9f1e48ac81f5"
      },
      "source": [
        "!zip -r model_euclidean_cos.zip model_euclidean_cos\n",
        "# files.download('model_euclidean_1.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model_euclidean_cos/ (stored 0%)\n",
            "  adding: model_euclidean_cos/model_weights (deflated 7%)\n",
            "  adding: model_euclidean_cos/vocab.txt (deflated 53%)\n",
            "  adding: model_euclidean_cos/special_tokens_map.json (deflated 40%)\n",
            "  adding: model_euclidean_cos/tokenizer_config.json (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvFDCDIxKDOf"
      },
      "source": [
        "# !zip -r label_encoder_categorized_reduced.zip label_encoder\n",
        "# files.download('label_encoder_categorized_reduced.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4178_yLFMWmx"
      },
      "source": [
        "test_features = test_features.values\n",
        "labels = test_labels.values"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZpmBJuIC2nM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f214fc-74b3-4e94-e671-9128ee27fb76"
      },
      "source": [
        "test_features"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"Robert is a fisherman who wants to find a way to catch more fish. He decided to try different sizes of hooks. Robert caught 4 catfish, 3 trout, and 7 perch while using worms for bait. Which is the independent (manipulated) variable in Robert's investigation? (A) type of bait (B) size of hook (C) type of fish caught (D) number of fish caught\",\n",
              "       'Which of these factors causes water to evaporate the fastest? (A) high temperatures (B) high humidity (C) slow winds (D) slow runoff',\n",
              "       'Which statement is true about the particles of a liquid compared to the particles of a gas? (A) Particles of a liquid are a slower and further apart. (B) Particles of a liquid are faster and farther apart. (C) Particles of a liquid are slower and closer together. (D) Particles of a liquid are faster and closer together.',\n",
              "       ...,\n",
              "       'Which of these is not an inherited trait in humans? (A) height (B) hair color (C) skin color (D) intelligence',\n",
              "       'In order to survive, all animals need (A) heat, water, and soil (B) sunlight, soil, and heat (C) sunlight, air, and food (D) food, water, and air',\n",
              "       'Scientists claim that the continents of South America and Africa were once a single landmass. All of the following observations support this claim except (A) the mountains on these continents have similar rocks of the same age. (B) these continents appear to fit together like the pieces of a puzzle. (C) similar fish live in the ocean off the coasts of these continents. (D) the same kinds of fossils have been found on these continents.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRZ54gFokNh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1723ea3-3d56-411f-ad26-dbc729af1f07"
      },
      "source": [
        "labels"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['science_INFERENCE_experiment design',\n",
              "       'matter_Change of state_EVAPoration', 'matter_chemistry_atomic',\n",
              "       ..., 'Life_reproduction_DNA inheritance_inheritance',\n",
              "       'Life_functions_FUNCT_animalESS', 'EARTH_INNER_PLATE_CONTDRIFT'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ohj1x7frQJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d9c154-c200-4410-99b4-a323c85375cb"
      },
      "source": [
        "len(list(set(labels)))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "352"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyXY8hryCwJM"
      },
      "source": [
        "def get_cleaned_taxonomy_lo(taxonomy):\n",
        "  cleaned_taxonomy = []\n",
        "  for value in taxonomy:\n",
        "      value = ' '.join(value.lower().split(\">>\"))\n",
        "      # taxonomy_words = [inflection.singularize(val)  for token in value for val in token.split(\" \") if val.isalpha()]\n",
        "      cleaned_taxonomy.append( value )\n",
        "  return cleaned_taxonomy"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EvElzLjECzdn",
        "outputId": "03b753dc-9d3e-4ec1-e010-6e4a70fe9562"
      },
      "source": [
        "test_labels = list(set(labels))\n",
        "test_set_labels = get_cleaned_taxonomy_lo(test_labels)\n",
        "test_set_labels[0]"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'earth_weather_measurement_precipitation'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ITzz8WXixeR7",
        "outputId": "4ea899e2-13b4-4aec-fede-785dbb8ec5d7"
      },
      "source": [
        "test_labels = list(set(labels))\n",
        "test_set_labels = get_cleaned_taxonomy(test_labels)\n",
        "test_set_labels[0]"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'earth weather measurement precipitation'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vkIBncNp35-l",
        "outputId": "6b44f546-fc12-40cc-f7e6-3618ea066f1f"
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'EARTH_WEATHER_measurement_precipitation'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y73hgz4CxLc8"
      },
      "source": [
        "label_input_ids = []\n",
        "label_attention_masks = []\n",
        "for sent in test_set_labels:\n",
        "\n",
        "    label_encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    label_input_ids.append(label_encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    label_attention_masks.append(label_encoded_dict['attention_mask'])\n",
        "label_input_ids = torch.cat(label_input_ids, dim=0)\n",
        "label_attention_masks = torch.cat(label_attention_masks, dim=0)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7L2Ah2vxLc8",
        "outputId": "a113ec3e-d3be-47e6-d27f-f1421708a332"
      },
      "source": [
        "taxonomy_vectors = []\n",
        "for label_input_id,label_att_mask in zip(label_input_ids,label_attention_masks):\n",
        "    label_input_id = label_input_id.to(device)\n",
        "    label_att_mask = label_att_mask.to(device)\n",
        "    with torch.no_grad():\n",
        "      outputs = model_label(label_input_id.reshape(1,-1),label_att_mask.reshape(1,-1))\n",
        "    taxonomy_vectors.append(outputs.cpu().numpy())\n",
        "taxonomy_vectors = np.vstack(taxonomy_vectors)\n",
        "taxonomy_vectors.shape\n"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(352, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nso39n1N_po_"
      },
      "source": [
        "# model = MulticlassClassifier('bert-base-uncased')\n",
        "# # model.load_state_dict(torch.load('model_euclidean_cos/model_weights'))\n",
        "# model.cuda()"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe4qYkV2C4fX"
      },
      "source": [
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "for sent in test_features:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "# labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "test_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n",
        "\n",
        "# Create the DataLoader.\n",
        "# prediction_data = TensorDataset(test_input_ids, test_attention_masks, test_poincare_tensor)\n",
        "# prediction_sampler = SequentialSampler(prediction_data)\n",
        "# prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNdlve8AJcCO"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "test_poincare_tensor = torch.tensor(taxonomy_vectors,dtype=torch.float)\n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6aMBHkAQZjT"
      },
      "source": [
        "cos = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "def dist_without_grad( u, v):\n",
        "  sqdist = torch.sum((u - v) ** 2, dim=-1)\n",
        "  squnorm = torch.sum(u ** 2, dim=-1)\n",
        "  sqvnorm = torch.sum(v ** 2, dim=-1)\n",
        "  x = 1 + 2 * sqdist / ((1 - squnorm) * (1 - sqvnorm)) + 1e-7\n",
        "  z = torch.sqrt(x ** 2 - 1)\n",
        "  return torch.log(x + z)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idBN7kS5ebZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2852586-241d-4b15-8808-131d91e05c3e"
      },
      "source": [
        "len(labels)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe0otXOPg7z0"
      },
      "source": [
        "test_labels = np.array(test_labels)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHToj9kUTNmm"
      },
      "source": [
        "label_set = np.array(list(set(categories)))"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quvVZFe0TUcO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c5094524-7dab-4314-8f1a-1714fc7224a7"
      },
      "source": [
        "test_set_labels[0]"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'earth weather measurement precipitation'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPCktQT9DVT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d423708a-ea16-425b-caef-22c5e284678c"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(test_input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "input_ids = test_input_ids.to('cuda')\n",
        "attention_masks = test_attention_masks.to('cuda')\n",
        "test_poincare_tensor = test_poincare_tensor.to('cuda')\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "for input_id,attention_mask in zip(input_ids, attention_masks):\n",
        "  with torch.no_grad():\n",
        "    outputs = model(input_id.reshape(1,-1),attention_mask.reshape(1,-1))\n",
        "    \n",
        "  distances = cos(outputs,test_poincare_tensor) #torch.topk(cos(outputs,test_poincare_tensor),20,largest=True)\n",
        "  distances,indices = torch.topk(distances,18,largest=True)\n",
        "  predictions.append(test_labels[indices.cpu().numpy()])\n",
        "print(len(predictions))\n",
        "  # max_distance =100000000000000\n",
        "  # label=None\n",
        "  # for index,test_poincare in enumerate(test_poincare_tensor):\n",
        "\n",
        "  #   distance = distanceTo(test_poincare, outputs)\n",
        "  #   if distance < max_distance:\n",
        "  #     max_distance = distance\n",
        "  #     label = index\n",
        "  # predictions.append(labels[label])\n",
        "    \n",
        "# Predict \n",
        "# for batch in prediction_dataloader:\n",
        "#   # Add batch to GPU\n",
        "#   batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "#   # Unpack the inputs from our dataloader\n",
        "#   b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "#   # Telling the model not to compute or store gradients, saving memory and \n",
        "#   # speeding up prediction\n",
        "#   with torch.no_grad():\n",
        "#       # Forward pass, calculate logit predictions\n",
        "#       outputs = model(b_input_ids,b_input_mask)\n",
        "\n",
        "#   logits = outputs\n",
        "#   for logit in logits:\n",
        "#     max_similarity = 0\n",
        "\n",
        "\n",
        "#   # Move logits and labels to CPU\n",
        "#   logits = logits.detach().cpu().numpy()\n",
        "#   label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "#   # Store predictions and true labels\n",
        "#   predictions.append(logits)\n",
        "#   true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')\n",
        "# predictions"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,400 test sentences...\n",
            "1400\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJCr2Bi89Zw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "036b6721-1275-46f8-fd69-b0e3ced3bafc"
      },
      "source": [
        "!pip install tensorflow==1.13.1"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.13.1 in /usr/local/lib/python3.7/dist-packages (1.13.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.32.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (54.1.2)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5wj2gXYFkrQ"
      },
      "source": [
        "labels=test_data['QCLabel'].values"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfr9QGQkKGpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e1170a6-98b2-4376-fe11-6785cd633252"
      },
      "source": [
        "from sklearn .preprocessing import LabelEncoder\n",
        "LE= LabelEncoder()\n",
        "labels = LE.fit_transform(labels)\n",
        "labels"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([349, 282, 299, ..., 194, 137,  23])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YsAzgxhQPP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8149a68a-b630-433f-b2d8-d3f371fac903"
      },
      "source": [
        "LE.inverse_transform([325])"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['matter_properties of material_REFLECT'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adb4gTNgGKUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ffcec22-aa49-4503-bdcf-9a34aa2e7903"
      },
      "source": [
        "labels"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([349, 282, 299, ..., 194, 137,  23])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZIY_54gHm7M",
        "outputId": "f5f7f27f-3478-4389-c925-fe72e94b377d"
      },
      "source": [
        "np.where(labels==325)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 498,  644, 1102]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O96135r8GhD6",
        "outputId": "2e6d3244-6b7e-430e-a6f8-5797c38e3940"
      },
      "source": [
        "LE.transform([\"matter_properties of material_REFLECT\"])"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([325])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTZJoePzIQ1e",
        "outputId": "37fff349-3ea3-40b4-9021-56729c8542a4"
      },
      "source": [
        "#unseen label proof\n",
        "\n",
        "np.where(test_data[\"QCLabel\"].values==\"matter_properties of material_REFLECT\")"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 498,  644, 1102]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq_ukFUBHW6q",
        "outputId": "f955cd74-30c3-4993-fabe-04aa5efe429c"
      },
      "source": [
        "#unseen label proof\n",
        "\n",
        "LE.inverse_transform([325])"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['matter_properties of material_REFLECT'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1bcG5-w5pud",
        "outputId": "b08cdae3-087a-4bb4-9041-b3a248625f2f"
      },
      "source": [
        "LE.inverse_transform([320])"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['matter_properties of material_FLEX'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwH2zIAW8QR_",
        "outputId": "7e5c2bd0-9bb2-4307-e29c-4d2616b9595c"
      },
      "source": [
        "LE.inverse_transform([331])"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['matter_properties of objects_MASS'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L32RVBejZQ2K",
        "outputId": "7e0e9063-8cd1-4f6d-892c-921b00aa2d8e"
      },
      "source": [
        "LE.inverse_transform([330])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['matter_properties of objects_DENSITY'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "douKqpvtZQ5q",
        "outputId": "be71ef27-1f91-45f3-82aa-20b60c44a887"
      },
      "source": [
        "LE.inverse_transform([265])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['energy_thermal conductivity_RADIATION'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pZvFAZ0ZQ-K",
        "outputId": "c83696ba-6437-46a1-be89-9f9bf1597128"
      },
      "source": [
        "LE.inverse_transform([245])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['energy_LIGHT_GENERICPROP'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbohQzAhlYRN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azkCfK-bCoXd"
      },
      "source": [
        "final_predictions = []\n",
        "for prediction in predictions:\n",
        "  final_predictions.append(LE.transform(prediction))\n"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buXWtwdNHSYF",
        "outputId": "3e0ccfa5-5a45-4162-a61d-b9e2035fb8fa"
      },
      "source": [
        "#unseen label proof\n",
        "final_predictions[1102]\n"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([331, 330, 243, 332, 247, 271, 286, 329, 244, 273, 272, 246, 334,\n",
              "       321, 318, 248, 302, 325])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm6Zd6Q05cOO",
        "outputId": "ca4c90bd-6be3-4300-8aa1-56023d432d2e"
      },
      "source": [
        "final_predictions[498]\n"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([297,  12,  10, 294, 318, 301, 275, 321, 330,  11, 331, 280, 300,\n",
              "       322, 295, 284, 296, 334])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exJ_nGI95fPl",
        "outputId": "d69d6b95-56d8-47e1-8c5e-75aae27b69d8"
      },
      "source": [
        "final_predictions[644]\n"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([265, 245, 264, 248, 247, 243, 254, 234, 252, 250, 255, 236, 246,\n",
              "       235, 244, 253, 231, 271])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQrlczKxMwzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42570f7-bc1e-4559-95af-ac8afb7aedc7"
      },
      "source": [
        "final_predictions[-3]"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([192, 195, 194, 189, 190, 193, 156, 188, 191,  87,  91, 146, 145,\n",
              "       335, 111, 114, 181, 109])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is-KTAENfB6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ff1983-a5a3-4f9e-d841-d0535639bab6"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 20\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, k=20)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, k=20)\n",
        "\n",
        "# tmp_rank = tf.nn.top_k(y_pred, 19)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    # print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",s|ess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    # print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1400, 18) (1400,)\n",
            "update_recall:  0.77\n",
            "recall 0.77\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1078.0, 322.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI1jhndp6cEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ec3a38-f649-4ecc-c572-78de691e829e"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 15)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 15)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 15)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1400, 15) (1400,)\n",
            "precision 0.04880952380952381\n",
            "update_recall:  0.7321428571428571\n",
            "recall 0.7321428571428571\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1025.0, 375.0, 1025.0, 19975.0]\n",
            "TMP_RANK:  TopKV2(values=array([[350, 349, 348, ..., 338, 337, 336],\n",
            "       [282,  72,  66, ...,  44,  31,  30],\n",
            "       [286, 273, 272, ..., 244, 243,  79],\n",
            "       ...,\n",
            "       [335, 195, 194, ..., 111,  91,  87],\n",
            "       [137, 135, 134, ..., 120, 118,  99],\n",
            "       [351,  26,  25, ...,   6,   2,   1]]), indices=array([[ 0,  2,  3, ..., 14,  7,  6],\n",
            "       [12,  8, 11, ..., 14,  5, 10],\n",
            "       [ 5,  2,  0, ...,  1, 10, 11],\n",
            "       ...,\n",
            "       [13,  1,  2, ..., 14, 10,  9],\n",
            "       [ 5,  4,  0, ...,  6,  1,  2],\n",
            "       [ 6,  9, 14, ...,  0,  4,  8]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaA9z5n3mZz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f61aff25-ba2b-4d9d-8c92-c0b99d1d9f4c"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 10)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 10)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 10)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(y_pred))"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1400, 10) (1400,)\n",
            "precision 0.06185714285714286\n",
            "update_recall:  0.6185714285714285\n",
            "recall 0.6185714285714285\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 866.0, 534.0, 866.0, 13134.0]\n",
            "TMP_RANK:  [[350 346 349 ... 337 345 344]\n",
            " [ 45  55  63 ...  48  72  57]\n",
            " [272 244 273 ... 247 268 267]\n",
            " ...\n",
            " [192 195 194 ... 188 191  87]\n",
            " [134 118  99 ... 133 132 131]\n",
            " [  6   7   8 ...  15   1  26]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz5onV-AU4Kt",
        "outputId": "31ed61c1-bda7-4031-aa2e-53f37b332bbe"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 10)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 10)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 10)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1400, 10) (1400,)\n",
            "precision 0.061785714285714284\n",
            "update_recall:  0.6178571428571429\n",
            "recall 0.6178571428571429\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 865.0, 535.0, 865.0, 13135.0]\n",
            "TMP_RANK:  [[350 346 349 ... 337 345 344]\n",
            " [ 45  55  63 ...  48  72  57]\n",
            " [272 244 273 ... 247 268 267]\n",
            " ...\n",
            " [192 195 194 ... 188 191  87]\n",
            " [134 118  99 ... 133 132 131]\n",
            " [  6   7   8 ...  15   1  26]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkKaMSEJnJUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ccaa4c-2186-4568-807a-cbd7023d1330"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 5)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 5)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 5)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1400, 5) (1400,)\n",
            "precision 0.08457142857142858\n",
            "update_recall:  0.4228571428571429\n",
            "recall 0.4228571428571429\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 592.0, 808.0, 592.0, 6408.0]\n",
            "TMP_RANK:  TopKV2(values=array([[350, 349, 348, 346, 343],\n",
            "       [ 63,  60,  58,  55,  45],\n",
            "       [273, 272, 271, 246, 244],\n",
            "       ...,\n",
            "       [195, 194, 192, 190, 189],\n",
            "       [135, 134, 121, 118,  99],\n",
            "       [  9,   8,   7,   6,   2]]), indices=array([[0, 2, 3, 1, 4],\n",
            "       [2, 4, 3, 1, 0],\n",
            "       [2, 0, 4, 3, 1],\n",
            "       ...,\n",
            "       [1, 2, 0, 4, 3],\n",
            "       [4, 0, 3, 1, 2],\n",
            "       [3, 2, 1, 0, 4]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFQcbbahY09A",
        "outputId": "78c54a84-8d8a-424d-dc68-84593926a16e"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 5)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 5)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 5)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1400, 5) (1400,)\n",
            "precision 0.08442857142857142\n",
            "update_recall:  0.42214285714285715\n",
            "recall 0.42214285714285715\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 591.0, 809.0, 591.0, 6409.0]\n",
            "TMP_RANK:  TopKV2(values=array([[350, 349, 348, 346, 343],\n",
            "       [ 63,  60,  58,  55,  45],\n",
            "       [273, 272, 271, 246, 244],\n",
            "       ...,\n",
            "       [195, 194, 192, 190, 189],\n",
            "       [135, 134, 121, 118,  99],\n",
            "       [  9,   8,   7,   6,   2]]), indices=array([[0, 2, 3, 1, 4],\n",
            "       [2, 4, 3, 1, 0],\n",
            "       [2, 0, 4, 3, 1],\n",
            "       ...,\n",
            "       [1, 2, 0, 4, 3],\n",
            "       [4, 0, 3, 1, 2],\n",
            "       [3, 2, 1, 0, 4]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPqYvRNIrRg1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d536a5-30cd-444b-878e-19720b899dc7"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 1)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 1)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 1)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4784, 1) (4784,)\n",
            "precision 0.4280936454849498\n",
            "update_recall:  0.4280936454849498\n",
            "recall 0.4280936454849498\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2048.0, 2736.0, 2048.0, 2736.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 66],\n",
            "       [176],\n",
            "       [116],\n",
            "       ...,\n",
            "       [ 49],\n",
            "       [  8],\n",
            "       [152]]), indices=array([[0],\n",
            "       [0],\n",
            "       [0],\n",
            "       ...,\n",
            "       [0],\n",
            "       [0],\n",
            "       [0]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUzf5IbMDfHp"
      },
      "source": [
        "#### LO classification o/p"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnSjuzMDDhwe",
        "outputId": "46fd1d21-5ac8-47c1-90a5-bda36359b1fd"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 1)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 1)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 1)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(417, 1) (417,)\n",
            "precision 0.539568345323741\n",
            "update_recall:  0.539568345323741\n",
            "recall 0.539568345323741\n",
            "STREAM_VARS:  [225.0, 192.0, 225.0, 192.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 5],\n",
            "       [ 1],\n",
            "       [21],\n",
            "       [21],\n",
            "       [39],\n",
            "       [28],\n",
            "       [28],\n",
            "       [21],\n",
            "       [ 1],\n",
            "       [ 5],\n",
            "       [ 1],\n",
            "       [28],\n",
            "       [ 0],\n",
            "       [ 5],\n",
            "       [ 5],\n",
            "       [ 4],\n",
            "       [ 5],\n",
            "       [ 0],\n",
            "       [28],\n",
            "       [27],\n",
            "       [29],\n",
            "       [27],\n",
            "       [29],\n",
            "       [27],\n",
            "       [29],\n",
            "       [29],\n",
            "       [27],\n",
            "       [29],\n",
            "       [ 6],\n",
            "       [27],\n",
            "       [21],\n",
            "       [34],\n",
            "       [29],\n",
            "       [29],\n",
            "       [ 0],\n",
            "       [ 1],\n",
            "       [34],\n",
            "       [ 5],\n",
            "       [ 2],\n",
            "       [ 7],\n",
            "       [ 0],\n",
            "       [ 0],\n",
            "       [41],\n",
            "       [41],\n",
            "       [34],\n",
            "       [41],\n",
            "       [ 9],\n",
            "       [22],\n",
            "       [30],\n",
            "       [30],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [22],\n",
            "       [11],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [ 3],\n",
            "       [ 9],\n",
            "       [ 9],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [11],\n",
            "       [11],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [17],\n",
            "       [11],\n",
            "       [36],\n",
            "       [17],\n",
            "       [17],\n",
            "       [17],\n",
            "       [23],\n",
            "       [23],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [23],\n",
            "       [25],\n",
            "       [25],\n",
            "       [23],\n",
            "       [25],\n",
            "       [25],\n",
            "       [25],\n",
            "       [23],\n",
            "       [23],\n",
            "       [23],\n",
            "       [23],\n",
            "       [23],\n",
            "       [25],\n",
            "       [23],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [12],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [12],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [26],\n",
            "       [12],\n",
            "       [26],\n",
            "       [26],\n",
            "       [ 4],\n",
            "       [16],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [33],\n",
            "       [ 8],\n",
            "       [35],\n",
            "       [35],\n",
            "       [42],\n",
            "       [28],\n",
            "       [28],\n",
            "       [47],\n",
            "       [47],\n",
            "       [28],\n",
            "       [28],\n",
            "       [28],\n",
            "       [28],\n",
            "       [28],\n",
            "       [35],\n",
            "       [28],\n",
            "       [28],\n",
            "       [39],\n",
            "       [21],\n",
            "       [21],\n",
            "       [21],\n",
            "       [28],\n",
            "       [21],\n",
            "       [21],\n",
            "       [28],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [ 1],\n",
            "       [41],\n",
            "       [41],\n",
            "       [41],\n",
            "       [ 1],\n",
            "       [41],\n",
            "       [ 1],\n",
            "       [41],\n",
            "       [ 1],\n",
            "       [41],\n",
            "       [41],\n",
            "       [41],\n",
            "       [41],\n",
            "       [41],\n",
            "       [41],\n",
            "       [41],\n",
            "       [22],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [45],\n",
            "       [44],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [44],\n",
            "       [11],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [ 9],\n",
            "       [45],\n",
            "       [ 9],\n",
            "       [11],\n",
            "       [11],\n",
            "       [11],\n",
            "       [11],\n",
            "       [11],\n",
            "       [11],\n",
            "       [31],\n",
            "       [31],\n",
            "       [31],\n",
            "       [31],\n",
            "       [31],\n",
            "       [13],\n",
            "       [13],\n",
            "       [15],\n",
            "       [13],\n",
            "       [13],\n",
            "       [47],\n",
            "       [13],\n",
            "       [13],\n",
            "       [13],\n",
            "       [13],\n",
            "       [47],\n",
            "       [14],\n",
            "       [13],\n",
            "       [13],\n",
            "       [14],\n",
            "       [16],\n",
            "       [47],\n",
            "       [14],\n",
            "       [47],\n",
            "       [13],\n",
            "       [47],\n",
            "       [47],\n",
            "       [15],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [31],\n",
            "       [25],\n",
            "       [38],\n",
            "       [31],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [46],\n",
            "       [ 8],\n",
            "       [35],\n",
            "       [35],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [42],\n",
            "       [20],\n",
            "       [10],\n",
            "       [10],\n",
            "       [10],\n",
            "       [20],\n",
            "       [20],\n",
            "       [10],\n",
            "       [20],\n",
            "       [20],\n",
            "       [20],\n",
            "       [ 8],\n",
            "       [20],\n",
            "       [20],\n",
            "       [20],\n",
            "       [20],\n",
            "       [10],\n",
            "       [20],\n",
            "       [10],\n",
            "       [10],\n",
            "       [ 8],\n",
            "       [20],\n",
            "       [20],\n",
            "       [20],\n",
            "       [20],\n",
            "       [30],\n",
            "       [ 8],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [30],\n",
            "       [ 8],\n",
            "       [46],\n",
            "       [30],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [21],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [43],\n",
            "       [43],\n",
            "       [43],\n",
            "       [35],\n",
            "       [27],\n",
            "       [27],\n",
            "       [ 4],\n",
            "       [29],\n",
            "       [27],\n",
            "       [27],\n",
            "       [ 0],\n",
            "       [27],\n",
            "       [27],\n",
            "       [39],\n",
            "       [39],\n",
            "       [39],\n",
            "       [ 6],\n",
            "       [ 6],\n",
            "       [42],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 4],\n",
            "       [ 7],\n",
            "       [ 7],\n",
            "       [ 6],\n",
            "       [ 7],\n",
            "       [35],\n",
            "       [ 7],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [ 8],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [44],\n",
            "       [44],\n",
            "       [44],\n",
            "       [ 3],\n",
            "       [ 3],\n",
            "       [44],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [36],\n",
            "       [15],\n",
            "       [15],\n",
            "       [13],\n",
            "       [13],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [15],\n",
            "       [38],\n",
            "       [15],\n",
            "       [31],\n",
            "       [38],\n",
            "       [38],\n",
            "       [38],\n",
            "       [15],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [ 4],\n",
            "       [39],\n",
            "       [47],\n",
            "       [26],\n",
            "       [12],\n",
            "       [37],\n",
            "       [47],\n",
            "       [37],\n",
            "       [37],\n",
            "       [23],\n",
            "       [23],\n",
            "       [23],\n",
            "       [25],\n",
            "       [23],\n",
            "       [25],\n",
            "       [23],\n",
            "       [25],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [40],\n",
            "       [16],\n",
            "       [16],\n",
            "       [40],\n",
            "       [16],\n",
            "       [16],\n",
            "       [35],\n",
            "       [35],\n",
            "       [35],\n",
            "       [35],\n",
            "       [35],\n",
            "       [35]]), indices=array([[0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXaBO4GEDhy_",
        "outputId": "0de8f139-14f7-4868-974b-39412133ac50"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 2)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 2)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 2)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(417, 2) (417,)\n",
            "precision 0.39448441247002397\n",
            "update_recall:  0.7889688249400479\n",
            "recall 0.7889688249400479\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 329.0, 88.0, 329.0, 505.0]\n",
            "TMP_RANK:  TopKV2(values=array([[ 5,  1],\n",
            "       [41,  1],\n",
            "       [21,  5],\n",
            "       [21,  5],\n",
            "       [39, 28],\n",
            "       [28,  5],\n",
            "       [28,  1],\n",
            "       [21,  5],\n",
            "       [41,  1],\n",
            "       [ 5,  0],\n",
            "       [ 5,  1],\n",
            "       [28,  7],\n",
            "       [ 5,  0],\n",
            "       [ 5,  0],\n",
            "       [29,  5],\n",
            "       [29,  4],\n",
            "       [21,  5],\n",
            "       [ 5,  0],\n",
            "       [28, 21],\n",
            "       [28, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [39,  6],\n",
            "       [29, 27],\n",
            "       [21,  4],\n",
            "       [41, 34],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [27,  0],\n",
            "       [41,  1],\n",
            "       [41, 34],\n",
            "       [ 5,  2],\n",
            "       [ 5,  2],\n",
            "       [ 7,  6],\n",
            "       [ 2,  0],\n",
            "       [ 5,  0],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41, 34],\n",
            "       [41, 34],\n",
            "       [46,  9],\n",
            "       [46, 22],\n",
            "       [30, 22],\n",
            "       [46, 30],\n",
            "       [46, 22],\n",
            "       [22,  3],\n",
            "       [45, 22],\n",
            "       [45, 22],\n",
            "       [45, 22],\n",
            "       [45, 22],\n",
            "       [22, 11],\n",
            "       [45,  9],\n",
            "       [45,  9],\n",
            "       [45,  9],\n",
            "       [45,  9],\n",
            "       [44,  3],\n",
            "       [46,  9],\n",
            "       [45,  9],\n",
            "       [36, 11],\n",
            "       [36, 18],\n",
            "       [36, 11],\n",
            "       [36, 18],\n",
            "       [33, 11],\n",
            "       [36, 11],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [46, 36],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [17, 11],\n",
            "       [17, 11],\n",
            "       [36, 18],\n",
            "       [17, 11],\n",
            "       [17, 11],\n",
            "       [17, 11],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [25, 23],\n",
            "       [25, 23],\n",
            "       [25, 23],\n",
            "       [24, 23],\n",
            "       [25, 23],\n",
            "       [25, 23],\n",
            "       [24, 23],\n",
            "       [25, 23],\n",
            "       [25, 23],\n",
            "       [25, 23],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [25, 23],\n",
            "       [24, 23],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [12,  4],\n",
            "       [12,  4],\n",
            "       [26, 12],\n",
            "       [12,  4],\n",
            "       [26, 12],\n",
            "       [37, 26],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [12,  4],\n",
            "       [40, 16],\n",
            "       [32,  8],\n",
            "       [32,  8],\n",
            "       [33,  8],\n",
            "       [42,  8],\n",
            "       [42, 35],\n",
            "       [35,  8],\n",
            "       [42, 35],\n",
            "       [28,  7],\n",
            "       [28, 16],\n",
            "       [47, 14],\n",
            "       [47, 16],\n",
            "       [39, 28],\n",
            "       [35, 28],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [28, 16],\n",
            "       [35, 32],\n",
            "       [28,  7],\n",
            "       [39, 28],\n",
            "       [47, 39],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [28, 21],\n",
            "       [41,  1],\n",
            "       [29,  1],\n",
            "       [29,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41, 34],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [41,  1],\n",
            "       [45, 22],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [45,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [11,  3],\n",
            "       [45,  3],\n",
            "       [45,  3],\n",
            "       [45,  3],\n",
            "       [45,  3],\n",
            "       [45,  3],\n",
            "       [44,  3],\n",
            "       [45,  9],\n",
            "       [45,  9],\n",
            "       [45,  9],\n",
            "       [45, 11],\n",
            "       [17, 11],\n",
            "       [33, 11],\n",
            "       [32, 11],\n",
            "       [11,  8],\n",
            "       [11,  8],\n",
            "       [31, 13],\n",
            "       [31, 13],\n",
            "       [31, 13],\n",
            "       [31, 13],\n",
            "       [31, 13],\n",
            "       [47, 13],\n",
            "       [31, 13],\n",
            "       [15, 14],\n",
            "       [47, 13],\n",
            "       [31, 13],\n",
            "       [47, 14],\n",
            "       [47, 13],\n",
            "       [15, 13],\n",
            "       [47, 13],\n",
            "       [16, 13],\n",
            "       [47, 14],\n",
            "       [15, 14],\n",
            "       [47, 13],\n",
            "       [16, 13],\n",
            "       [47, 14],\n",
            "       [47, 16],\n",
            "       [47, 14],\n",
            "       [47, 14],\n",
            "       [47, 39],\n",
            "       [47, 13],\n",
            "       [47, 12],\n",
            "       [47, 39],\n",
            "       [38, 15],\n",
            "       [38, 15],\n",
            "       [38, 15],\n",
            "       [38, 15],\n",
            "       [38, 15],\n",
            "       [31, 13],\n",
            "       [25, 23],\n",
            "       [38, 16],\n",
            "       [38, 31],\n",
            "       [38, 15],\n",
            "       [38, 15],\n",
            "       [38, 15],\n",
            "       [38, 15],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [32,  8],\n",
            "       [42, 35],\n",
            "       [35, 32],\n",
            "       [33,  8],\n",
            "       [32,  8],\n",
            "       [42,  8],\n",
            "       [42,  8],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [33,  8],\n",
            "       [20, 10],\n",
            "       [30, 20],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [32,  8],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [20, 10],\n",
            "       [35, 30],\n",
            "       [33,  8],\n",
            "       [35, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [35,  8],\n",
            "       [46, 30],\n",
            "       [46, 30],\n",
            "       [30,  8],\n",
            "       [32,  8],\n",
            "       [32,  8],\n",
            "       [43, 21],\n",
            "       [39,  6],\n",
            "       [43,  6],\n",
            "       [43,  6],\n",
            "       [43,  6],\n",
            "       [43, 10],\n",
            "       [35,  7],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [27,  4],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [29, 27],\n",
            "       [ 7,  0],\n",
            "       [29, 27],\n",
            "       [27,  6],\n",
            "       [39,  6],\n",
            "       [39,  6],\n",
            "       [39,  6],\n",
            "       [ 7,  6],\n",
            "       [39,  6],\n",
            "       [42,  6],\n",
            "       [ 7,  6],\n",
            "       [35,  7],\n",
            "       [39,  7],\n",
            "       [ 7,  6],\n",
            "       [39,  4],\n",
            "       [ 7,  6],\n",
            "       [39,  7],\n",
            "       [ 7,  6],\n",
            "       [ 7,  6],\n",
            "       [35,  7],\n",
            "       [ 7,  6],\n",
            "       [32,  8],\n",
            "       [32,  8],\n",
            "       [42,  8],\n",
            "       [42,  8],\n",
            "       [42,  8],\n",
            "       [22,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [44,  3],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [36, 18],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [14, 13],\n",
            "       [31, 13],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [15, 14],\n",
            "       [38, 15],\n",
            "       [38, 15],\n",
            "       [38, 15],\n",
            "       [38, 15],\n",
            "       [38, 31],\n",
            "       [38, 15],\n",
            "       [38, 15],\n",
            "       [38, 15],\n",
            "       [15, 14],\n",
            "       [39,  4],\n",
            "       [27,  4],\n",
            "       [12,  4],\n",
            "       [12,  4],\n",
            "       [39, 37],\n",
            "       [47, 37],\n",
            "       [26, 12],\n",
            "       [26, 12],\n",
            "       [37, 12],\n",
            "       [47, 37],\n",
            "       [39, 37],\n",
            "       [39, 37],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [24, 23],\n",
            "       [25, 23],\n",
            "       [24, 23],\n",
            "       [25, 23],\n",
            "       [24, 23],\n",
            "       [25, 23],\n",
            "       [40, 16],\n",
            "       [40, 23],\n",
            "       [40, 31],\n",
            "       [40, 23],\n",
            "       [40, 31],\n",
            "       [40, 31],\n",
            "       [40, 16],\n",
            "       [40, 16],\n",
            "       [40, 16],\n",
            "       [40, 16],\n",
            "       [38, 16],\n",
            "       [42, 35],\n",
            "       [42, 35],\n",
            "       [35,  7],\n",
            "       [42, 35],\n",
            "       [42, 35],\n",
            "       [42, 35]]), indices=array([[0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [0, 1],\n",
            "       [1, 0],\n",
            "       [1, 0],\n",
            "       [1, 0]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVAO6-ddDh1z",
        "outputId": "6b25b0ed-4edc-4a6d-ac26-b93e1c0d345c"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 3)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 3)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred,3)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(417, 3) (417,)\n",
            "precision 0.28457234212629895\n",
            "update_recall:  0.8537170263788969\n",
            "recall 0.8537170263788969\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 356.0, 61.0, 356.0, 895.0]\n",
            "TMP_RANK:  TopKV2(values=array([[41,  5,  1],\n",
            "       [41,  5,  1],\n",
            "       [29, 21,  5],\n",
            "       ...,\n",
            "       [42, 35,  7],\n",
            "       [42, 35,  8],\n",
            "       [42, 35,  8]]), indices=array([[2, 0, 1],\n",
            "       [1, 2, 0],\n",
            "       [2, 0, 1],\n",
            "       ...,\n",
            "       [1, 0, 2],\n",
            "       [1, 0, 2],\n",
            "       [1, 0, 2]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLX7Wx9CDh4r",
        "outputId": "387a62d2-3bb5-43cf-91d0-ac4dba409e8f"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 4)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 4)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 4)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(417, 4) (417,)\n",
            "precision 0.23081534772182255\n",
            "update_recall:  0.9232613908872902\n",
            "recall 0.9232613908872902\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 385.0, 32.0, 385.0, 1283.0]\n",
            "TMP_RANK:  TopKV2(values=array([[44, 41,  5,  1],\n",
            "       [41, 28,  5,  1],\n",
            "       [29, 27, 21,  5],\n",
            "       ...,\n",
            "       [42, 35,  8,  7],\n",
            "       [42, 35, 32,  8],\n",
            "       [42, 35, 32,  8]]), indices=array([[3, 2, 0, 1],\n",
            "       [1, 3, 2, 0],\n",
            "       [2, 3, 0, 1],\n",
            "       ...,\n",
            "       [1, 0, 3, 2],\n",
            "       [1, 0, 3, 2],\n",
            "       [1, 0, 3, 2]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV492QBBDh7l",
        "outputId": "70f2ae37-41e8-4453-b486-a6d7b82a6983"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_true = np.array(labels)\n",
        "y_true = tf.identity(y_true)\n",
        "y_pred = np.array(final_predictions)\n",
        "y_pred = tf.identity(y_pred)\n",
        "print(y_pred.shape,y_true.shape)\n",
        "k = 8\n",
        "recall, update_recall = tf.compat.v1.metrics.recall_at_top_k(y_true, y_pred, 5)\n",
        "precision, update_precision = tf.compat.v1.metrics.precision_at_top_k(y_true, y_pred, 5)\n",
        "\n",
        "tmp_rank = tf.nn.top_k(y_pred, 5)\n",
        "stream_vars = [i for i in tf.local_variables()]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    print(\"precision\",sess.run(update_precision))\n",
        "    # print(\"precision\",sess.run(precision))\n",
        "\n",
        "    print(\"update_recall: \",sess.run(update_recall ))\n",
        "    print(\"recall\",sess.run(recall))\n",
        "\n",
        "    print(\"STREAM_VARS: \",(sess.run(stream_vars)))\n",
        "    print(\"TMP_RANK: \",sess.run(tmp_rank))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(417, 5) (417,)\n",
            "precision 0.1884892086330935\n",
            "update_recall:  0.9424460431654677\n",
            "recall 0.9424460431654677\n",
            "STREAM_VARS:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 393.0, 24.0, 393.0, 1692.0]\n",
            "TMP_RANK:  TopKV2(values=array([[44, 41, 34,  5,  1],\n",
            "       [41, 28, 21,  5,  1],\n",
            "       [29, 28, 27, 21,  5],\n",
            "       ...,\n",
            "       [42, 35, 32,  8,  7],\n",
            "       [42, 35, 32,  8,  7],\n",
            "       [42, 35, 32,  8,  7]]), indices=array([[3, 2, 4, 0, 1],\n",
            "       [1, 3, 4, 2, 0],\n",
            "       [2, 4, 3, 0, 1],\n",
            "       ...,\n",
            "       [1, 0, 4, 3, 2],\n",
            "       [1, 0, 3, 2, 4],\n",
            "       [1, 0, 3, 2, 4]], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs0D9T8SDh_t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmgmk6m2DiFV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGbi4DEZkwhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da4cea1-95bb-4a08-ca59-ccd817ede6b5"
      },
      "source": [
        "y_true = np.array(labels)\n",
        "final_predictions = np.array(final_predictions).squeeze()\n",
        "final_predictions.shape\n",
        "len(final_predictions[final_predictions==y_true])/len(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43415551839464883"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN1UA_4uBu_S"
      },
      "source": [
        "categories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdD0JiYgEX4k"
      },
      "source": [
        "!cp /content/model_euclidean_cos.zip \"/content/drive/My Drive/research_lo_content_taxonomy_classification\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_WchmXtDspr"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (final_data.label.sum(), len(final_data.label), (final_data.label.sum() / len(final_data.label) * 100.0)))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5BoY2hKGb7_"
      },
      "source": [
        "pred =  np.argmax(predictions[0],axis=1).flatten()\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPuK0-vzGp3R"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  # pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(np.array(labels[i]), np.array(predictions[i])   )             \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_vxvq7rHlgr"
      },
      "source": [
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v48rDl4JHmhv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df36f340-8ae9-41d6-d481-61b7bc086b3c"
      },
      "source": [
        "flat_predictions = np.array(predictions)\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.array(labels)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI8-HrJ6MSEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6320849-0f91-41bf-dd5d-e67a37d860d9"
      },
      "source": [
        "list_bool = (flat_true_labels==flat_predictions)\n",
        "print(list_bool)\n",
        "print(len([i for i, val in enumerate(list_bool) if val]))\n",
        "len(flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False False False ... False False False]\n",
            "68\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drJC0xYkHr_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a888f5-f796-4afa-d2bb-d386f0538f5a"
      },
      "source": [
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r6f8jW4BN3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "071a5587-f337-437a-94ff-4f47b7997a8d"
      },
      "source": [
        "len(flat_predictions[flat_predictions==flat_true_labels])/len(flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlA88cTuvlNA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd4b4d4b-023e-4323-cbd1-59c034cf32ce"
      },
      "source": [
        "flat_predictions[:40]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['social science>>civics : social and political life - ii>>how the state government works',\n",
              "       'physical science>>physical science (chemistry)>>synthetic fibres and plastics>>plastics',\n",
              "       'science>>physical and chemical changes',\n",
              "       'social science>>civics : social and political life - ii>>how the state government works',\n",
              "       'computer science[c++]>>arrays',\n",
              "       'computer science[c++]>>standard library functions',\n",
              "       'computer science[c++]>>inheritance: extending classes',\n",
              "       'computer science[c++]>>inheritance: extending classes',\n",
              "       'science>>reproduction in animals',\n",
              "       'social science>>history : our pasts - iii>>weavers, iron smelter & factory owners',\n",
              "       'social science>>civics : social and political life-i>>key elements of a democratic government',\n",
              "       'science>>materials : metals and non-metals',\n",
              "       'physics>>physics : part - i>>physical world',\n",
              "       'computer science[c++]>>inheritance: extending classes',\n",
              "       'science>>sources of energy',\n",
              "       'science>>materials : metals and non-metals',\n",
              "       'science>>human eye and colourful world',\n",
              "       'science>>human eye and colourful world',\n",
              "       'social science>>civics : social and political life>>judiciary',\n",
              "       'social science>>history : our pasts - i>>vital villages, thriving towns',\n",
              "       'computer science[c++]>>standard library functions',\n",
              "       'science>>the living organisms — characteristics and habitats',\n",
              "       'chemistry>>chemistry : part i>>d and f- block elements',\n",
              "       'social science>>civics : social and political life>>confronting marginalisation',\n",
              "       'science>>how do organisms reproduce?',\n",
              "       'science>>weather, climate and adaptations of animals to climate',\n",
              "       'social science>>political science : democratic politics - i>>what is democracy? why democracy?',\n",
              "       'science>>is matter around us pure',\n",
              "       'social science>>history : our pasts - ii>>the mughal empire',\n",
              "       'science>>sources of energy',\n",
              "       'computer science[c++]>>inheritance: extending classes',\n",
              "       'science>>weather, climate and adaptations of animals to climate',\n",
              "       'physics>>physics : part - i>>laws of motion',\n",
              "       'physics>>physics : part - ii>>mechanical properties of fluids',\n",
              "       'computer science[c++]>>arrays',\n",
              "       'social science>>geography : our environment>>human environment-settlement, transport and communication',\n",
              "       'social science>>civics : social and political life>>confronting marginalisation',\n",
              "       'social science>>history : our pasts - ii>>the mughal empire',\n",
              "       'chemistry>>chemistry : part ii>>the s-block elements',\n",
              "       'science>>improvement in food resources'], dtype='<U102')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa48dokzvnq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a7efcd3-1b36-4ade-d198-d11d37163e0a"
      },
      "source": [
        "flat_true_labels[:40]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['social science>>civics : social and political life - ii>>how the state government works',\n",
              "       'science>>electricity and circuits', 'science>>changes around us',\n",
              "       'social science>>civics : social and political life - ii>>understanding advertising',\n",
              "       'computer science[c++]>>programming methodology',\n",
              "       'computer science[c++]>>structured query language',\n",
              "       'computer science[c++]>>object oriented programming',\n",
              "       'computer science[c++]>>general oop concepts',\n",
              "       'science>>how do organisms reproduce?',\n",
              "       'social science>>history : our pasts - iii>>ruling the countryside',\n",
              "       'social science>>civics : social and political life>>the indian constitution',\n",
              "       'physical science>>physical science (chemistry)>>metals and non-metals>>metals',\n",
              "       'physics>>physics : part - i>>motion in straight line',\n",
              "       'computer science[c++]>>structured query language',\n",
              "       'physics>>physics : part - i>>laws of motion',\n",
              "       'social science>>civics : social and political life - ii>>role of the government in health',\n",
              "       'science>>friction',\n",
              "       'physical science>>physical science (physics)>>friction>>friction',\n",
              "       'social science>>history : our pasts - iii>>india after independence',\n",
              "       'social science>>history : our pasts - i>>new questions and ideas',\n",
              "       'computer science[c++]>>c++ revision tour',\n",
              "       'science>>getting to know plants',\n",
              "       'chemistry>>chemistry : part i>>chemical bonding and molecular structure',\n",
              "       'social science>>civics : social and political life>>public facilities',\n",
              "       'science>>getting to know plants',\n",
              "       'science>>forests: our lifeline',\n",
              "       'social science>>political science : democratic politics - i>>democracy in the contemporary world',\n",
              "       'science>>atoms and molecules',\n",
              "       'social science>>history : our pasts - ii>>the mughal empire',\n",
              "       'physics>>sources of energy>>sources of energy',\n",
              "       'computer science[c++]>>classes and objects',\n",
              "       'science>>forests: our lifeline',\n",
              "       'physics>>physics : part - i>>system of particles and rotational motion',\n",
              "       'science>>gravitation', 'computer science[c++]>>boolean algebra',\n",
              "       'social science>>geography : our environment>>air',\n",
              "       'social science>>disaster management - together, towards a safer india-ii>>specific hazards and mitigation',\n",
              "       'social science>>the mughal empire>>the mughal empire',\n",
              "       'chemistry>>chemistry : part i>>classification of elements and periodicity in properties',\n",
              "       'science>>getting to know plants'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlDkbovu0rg5"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av3GeuiBHock",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "b26059ca-4c1e-4b2e-ff53-d01a08318bb7"
      },
      "source": [
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-bccf3861f92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_true_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'flat_true_labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKxxgz1AFAkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120ff3ec-6c34-465d-8f16-c33b8ab205c1"
      },
      "source": [
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.1922086736219466, 0.2357500283089443, 0.18486435529602976, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it0TjEdVE-eH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b005a06b-cbc2-4f70-cb8a-1034bb84ffef"
      },
      "source": [
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2265830482911008, 0.26238738738738737, 0.21514243361084723, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPts-dvGHsZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e8016f-dfbf-4e77-e838-705ea6331bd7"
      },
      "source": [
        "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2265830482911008, 0.26238738738738737, 0.21514243361084723, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bq9ymZTM3_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c0d0fe3a-4aa7-4e88-813b-d5a6b124cfe0"
      },
      "source": [
        "import sys\n",
        "!test -d bertviz_repo && echo \"FYI: bertviz_repo directory already exists, to pull latest version uncomment this line: !rm -r bertviz_repo\"\n",
        "# !rm -r bertviz_repo # Uncomment if you need a clean pull from repo\n",
        "!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n",
        "if not 'bertviz_repo' in sys.path:\n",
        "  sys.path += ['bertviz_repo']\n",
        "!pip install regex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bertviz_repo'...\n",
            "remote: Enumerating objects: 1074, done.\u001b[K\n",
            "remote: Total 1074 (delta 0), reused 0 (delta 0), pack-reused 1074\u001b[K\n",
            "Receiving objects: 100% (1074/1074), 99.41 MiB | 27.17 MiB/s, done.\n",
            "Resolving deltas: 100% (687/687), done.\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (2019.12.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yCzNQ6ZBYtI"
      },
      "source": [
        "!7z x model_save.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kbAQwaydsyl"
      },
      "source": [
        "!pip install transformers==3.0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV9m2pTXybLf"
      },
      "source": [
        "!pip list | grep transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPpDi44ySCjH"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import BertTokenizer\n",
        "smodel = BertForSequenceClassification.from_pretrained('/content/model_save_categorized_reduced_oct', num_labels = 335,  cache_dir=None, \n",
        "    output_attentions = True, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True)\n",
        "tokenizer = BertTokenizer.from_pretrained('model_save_categorized_reduced_oct', do_lower_case=True)\n",
        "# model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr9EyWoVSZk-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "e20c3b84-d6e8-4312-9d4d-d08eb3fe6f67"
      },
      "source": [
        "from bertviz.transformers_neuron_view import BertModel, BertTokenizer\n",
        "from bertviz.neuron_view import show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-d03fb6cb4ce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers_neuron_view\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbertviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuron_view\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bertviz_repo/bertviz/transformers_neuron_view/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1.1.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBasicTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWordpieceTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIGPTTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_transfo_xl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTransfoXLTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransfoXLCorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_gpt2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bertviz_repo/bertviz/transformers_neuron_view/tokenization_bert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bertviz_repo/bertviz/transformers_neuron_view/tokenization_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bertviz_repo/bertviz/transformers_neuron_view/file_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClientError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'boto3'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtPPmu9rcGRV"
      },
      "source": [
        "def call_html():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
        "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEq2YAbed5Fl"
      },
      "source": [
        "\n",
        "def show_head_view(model, tokenizer, sentence_a, sentence_b=None):\n",
        "    inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
        "    input_ids = inputs['input_ids']\n",
        "    if sentence_b:\n",
        "        token_type_ids = inputs['token_type_ids']\n",
        "        attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
        "        sentence_b_start = token_type_ids[0].tolist().index(1)\n",
        "    else:\n",
        "        attention = model(input_ids)[-1]\n",
        "        sentence_b_start = None\n",
        "    input_id_list = input_ids[0].tolist() # Batch index 0\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)    \n",
        "    head_view(attention, tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oUiRZRdcIFC"
      },
      "source": [
        "sentence_a = \"The cat sat on the mat\"\n",
        "sentence_b = \"The cat lay on the rug\"\n",
        "\n",
        "model_type = 'bert'\n",
        "model_version = 'bert-base-uncased'\n",
        "model.to('cpu')\n",
        "show_head_view(model, tokenizer, sentence_a, sentence_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2x-6JL3cNPz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}